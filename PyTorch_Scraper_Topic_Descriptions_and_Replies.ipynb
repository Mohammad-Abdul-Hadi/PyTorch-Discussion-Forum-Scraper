{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_Scraper.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV9siJvBvoDQ",
        "outputId": "bf90a4c2-17ca-4961-fe6d-a48ace88ea4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install pyqt5\n",
        "!pip install webdriver_manager\n",
        "!pip install PyQtWebEngine"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyqt5 in /usr/local/lib/python3.6/dist-packages (5.15.1)\n",
            "Requirement already satisfied: PyQt5-sip<13,>=12.8 in /usr/local/lib/python3.6/dist-packages (from pyqt5) (12.8.1)\n",
            "Requirement already satisfied: webdriver_manager in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: crayons in /usr/local/lib/python3.6/dist-packages (from webdriver_manager) (0.4.0)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.6/dist-packages (from webdriver_manager) (5.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from webdriver_manager) (2.23.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from crayons->webdriver_manager) (0.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->webdriver_manager) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->webdriver_manager) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->webdriver_manager) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->webdriver_manager) (1.24.3)\n",
            "Requirement already satisfied: PyQtWebEngine in /usr/local/lib/python3.6/dist-packages (5.15.1)\n",
            "Requirement already satisfied: PyQt5>=5.15 in /usr/local/lib/python3.6/dist-packages (from PyQtWebEngine) (5.15.1)\n",
            "Requirement already satisfied: PyQt5-sip<13,>=12.8 in /usr/local/lib/python3.6/dist-packages (from PyQtWebEngine) (12.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQFs7vulsydQ"
      },
      "source": [
        "import math, shutil, sys, os, csv, time, pprint, json, csv, requests\n",
        "import urllib.request\n",
        "import pandas as pd  \n",
        "from PyQt5.QtWidgets import QApplication\n",
        "from PyQt5.QtCore import QUrl\n",
        "from PyQt5.QtWebEngineWidgets import QWebEnginePage\n",
        "from urllib.request import urlopen as uReq\n",
        "from bs4 import BeautifulSoup as soup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmI6XN4GVr58",
        "outputId": "e7e7f2d3-f1db-4f07-d7e5-387d91e309bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# install chromium, its driver, and selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium\n",
        "# set options to be headless, ..\n",
        "from selenium import webdriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Get:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [306 kB]\n",
            "Get:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:14 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [47.9 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,115 kB]\n",
            "Get:16 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,879 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [33.9 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,434 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [126 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,406 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [907 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [146 kB]\n",
            "Get:24 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [907 kB]\n",
            "Fetched 8,581 kB in 5s (1,571 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension adobe-flashplugin\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 53 not upgraded.\n",
            "Need to get 79.2 MB of archives.\n",
            "After this operation, 268 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 85.0.4183.83-0ubuntu0.18.04.2 [1,118 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 85.0.4183.83-0ubuntu0.18.04.2 [70.3 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 85.0.4183.83-0ubuntu0.18.04.2 [3,431 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 85.0.4183.83-0ubuntu0.18.04.2 [4,412 kB]\n",
            "Fetched 79.2 MB in 9s (8,944 kB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 144676 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_85.0.4183.83-0ubuntu0.18.04.2_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (85.0.4183.83-0ubuntu0.18.04.2) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_85.0.4183.83-0ubuntu0.18.04.2_amd64.deb ...\n",
            "Unpacking chromium-browser (85.0.4183.83-0ubuntu0.18.04.2) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_85.0.4183.83-0ubuntu0.18.04.2_all.deb ...\n",
            "Unpacking chromium-browser-l10n (85.0.4183.83-0ubuntu0.18.04.2) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_85.0.4183.83-0ubuntu0.18.04.2_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (85.0.4183.83-0ubuntu0.18.04.2) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (85.0.4183.83-0ubuntu0.18.04.2) ...\n",
            "Setting up chromium-browser (85.0.4183.83-0ubuntu0.18.04.2) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (85.0.4183.83-0ubuntu0.18.04.2) ...\n",
            "Setting up chromium-browser-l10n (85.0.4183.83-0ubuntu0.18.04.2) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxa8IyP1s7-U"
      },
      "source": [
        "def get_keys(dict): \n",
        "    list = [] \n",
        "    for key in dict.keys(): \n",
        "        list.append(key)       \n",
        "    return list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdK1kntEYFS8"
      },
      "source": [
        "def create_list(d, keys):\n",
        "    keys_d = get_keys(d)\n",
        "\n",
        "    if set(keys_d) == set(keys):\n",
        "        return list(d.values())\n",
        "    else:\n",
        "        dictionary = {}\n",
        "        for key in keys:\n",
        "            dictionary[key] = d[key] if key in d else None\n",
        "        return list(dictionary.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXatBwmgwUCF"
      },
      "source": [
        "categories = {'uncategorized': [1, 21654], 'vision': [5,5825], 'autograd': [7,3036], 'nlp': [8,1282], 'c': [11,1073], 'distributed': [12,560], 'jit': [13,374], 'reinforcement-learning': [6,333], 'deployment': [14,227], 'quantization': [17,203], 'mobile': [18,124], 'audio': [9,109], 'glow': [10,68], 'site-feedback': [3,64], 'ignite': [15,34], 'memory-format': [23,23], 'mixed-precision': [27,15], 'complex': [22,14], 'windows': [26,13], 'captum': [21,10], 'xla': [25,7], 'hackathon': [16,6], 'jobs': [24,2], 'tensorboard': [28,0]}\n",
        "# cats = get_keys(categories)\n",
        "# categories[cats[0]]\n",
        "# categories['tensorboard'][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLMHVF8kwmzN"
      },
      "source": [
        "# FETCH TITLES AND META-DATA\n",
        "cats = get_keys(categories)\n",
        "topics_per_page = 30\n",
        "\n",
        "for cat in cats:\n",
        "    topics_info = []\n",
        "    keys = []\n",
        "    num_pages = categories[cat][1]/topics_per_page\n",
        "    for i in range(0, math.ceil(num_pages)): \n",
        "        time.sleep(0.5)\n",
        "        my_url = 'https://discuss.pytorch.org/c/' + cat + '/' + str(categories[cat][0]) + '.json?page='+ str(i)\n",
        "        # my_url\n",
        "\n",
        "        uClient = uReq(my_url)\n",
        "        page_html = uClient.read()\n",
        "        uClient.close()\n",
        "        print(my_url+' fetched...')\n",
        "\n",
        "        encoding = 'utf-8'\n",
        "        filename = '/'+cat+'/'+cat+'_'+str(i)+'.json'\n",
        "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "        f = open(filename, \"w\")\n",
        "        f.write(page_html.decode(encoding))\n",
        "        f.close()\n",
        "        print(filename+ ' file created')\n",
        "\n",
        "        with open(filename) as json_file: \n",
        "            lst = []    \n",
        "            dict = json.load(json_file) \n",
        "            # str(dict['users'])\n",
        "            # str(dict['topic_list'])\n",
        "            topic_list = dict['topic_list']\n",
        "            topics = topic_list['topics'] # list of dictionary\n",
        "            print('topics have been fetched from '+ filename)\n",
        "\n",
        "            if i == 0:\n",
        "                keys = get_keys(topics[0])\n",
        "            \n",
        "            for d in topics:\n",
        "                row = create_list(d, keys)\n",
        "                topics_info.append(row)\n",
        "            print('Values/Rows added for ' + str(i) + '-th page')\n",
        "\n",
        "    # print(topics_info)\n",
        "    df = pd.DataFrame(topics_info)\n",
        "    df.columns = keys\n",
        "    csv_data = df.to_csv(index=False)\n",
        "    df.to_csv('topics_info_'+cat+'.csv', index=False)\n",
        "    print('CSV file created. End of '+cat+ ' category\\n\\n')\n",
        "\n",
        "    time.sleep(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hn8B2hNRGvH",
        "outputId": "eaa927bf-6065-4bb8-b6f5-3637af9162d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa6fuiFVSd5k"
      },
      "source": [
        "for cat in cats:\n",
        "    shutil.move(\"/content/topics_info_\"+cat+\".csv\", \"/content/drive/My Drive/AREA_51.2/Research/PyTorch Discussion Forum Data/Titles\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvFiIKQzfgv-",
        "outputId": "1de897c9-c790-49d9-a7e5-f24f5d8f5d3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Fetch Description if all titles\n",
        "\n",
        "keys = ['id', 'title', 'created_at', 'reply_count', 'views', 'description', 'creator_link', 'creator_name', 'creator_alias', 'post_date', 'post_likes', 'replies', 'repliers_links', 'reply_dates', 'reply_likes']\n",
        "cats = get_keys(categories) # commented for debugging \n",
        "# cats = ['site-feedback'] # added for debugging \n",
        "\n",
        "for cat in cats:\n",
        "    csv_list = []\n",
        "    filename = \"/content/drive/My Drive/AREA_51.2/Research/PyTorch Discussion Forum Data/Titles/topics_info_\"+cat+\".csv\"\n",
        "    if categories[cat][1] != 0:\n",
        "        data = pd.read_csv(filename)\n",
        "        for i in range(0, data.shape[0]):\n",
        "            time.sleep(0.5)\n",
        "            temp_lst = []\n",
        "            topic_url = \"https://discuss.pytorch.org/t/\"+data.at[i,'slug']+\"/\"+str(data.at[i,'id'])\n",
        "\n",
        "            while True:\n",
        "                try:\n",
        "                    uClient = uReq(topic_url)\n",
        "                    page_html = uClient.read()\n",
        "                    if uClient.getcode() == 200:\n",
        "                        uClient.close()\n",
        "                        break\n",
        "                except Exception as inst:\n",
        "                    print(inst)\n",
        "            \n",
        "            page_soup = soup(page_html, \"html.parser\")\n",
        "            \n",
        "            temp_lst.append(data.at[i,'id'])\n",
        "            temp_lst.append(data.at[i,'fancy_title'])\n",
        "            temp_lst.append(data.at[i,'created_at'])\n",
        "            temp_lst.append(data.at[i,'reply_count'])\n",
        "            temp_lst.append(data.at[i,'views'])\n",
        "\n",
        "            all_posts = page_soup.findAll(\"div\",{\"class\":\"post\"}) # commented for debugging\n",
        "            temp_lst.append(str(all_posts[0]).replace(\"\\n\", \"<NewLine>\")) # description # commented for debugging\n",
        "\n",
        "            all_creators = page_soup.findAll(\"span\",{\"class\":\"creator\"})\n",
        "            temp_lst.append(all_creators[0].a['href']) # creator_link\n",
        "            temp_lst.append(\" \".join(all_creators[0].text.split()[1:])) # creator_name\n",
        "            temp_lst.append(all_creators[0].span.text) # creator_alias\n",
        "\n",
        "            all_reply_dates = page_soup.findAll(\"span\",{\"class\":\"crawler-post-infos\"})\n",
        "            temp_lst.append(all_reply_dates[0].time.text.strip()) # post_date\n",
        "\n",
        "            all_reply_likes = page_soup.findAll(\"span\",{\"class\":\"post-likes\"})\n",
        "            temp_lst.append(all_reply_likes[0].text) # post_like\n",
        "\n",
        "            replies = \"\"\n",
        "            for p in range(1, len(all_posts)):\n",
        "                replies += \"REPLY \"+str(p)+\": \"+ str(all_posts[p]).replace(\"\\n\", \"<NewLine>\")+\"; <NewLine> \"\n",
        "            temp_lst.append(replies)\n",
        "\n",
        "            repliers_links = \"\"\n",
        "            for c in range(1, len(all_creators)):\n",
        "                repliers_links += \"REPLIER \"+str(c)+\": \"+all_creators[c].a['href']+\"; <NewLine> \"\n",
        "            temp_lst.append(repliers_links)\n",
        "\n",
        "            reply_dates = \"\"\n",
        "            for d in range(1, len(all_reply_dates)):\n",
        "                reply_dates += \"REPLY_DATE \"+str(d)+\": \"+all_reply_dates[d].time.text.strip()+\"; <NewLine> \"\n",
        "            temp_lst.append(reply_dates)\n",
        "\n",
        "            reply_likes = \"\"\n",
        "            for l in range(1, len(all_reply_likes)):\n",
        "                reply_likes += \"REPLY \"+str(l)+\" LIKES: \"+all_reply_likes[l].text+\"; <NewLine> \"\n",
        "            temp_lst.append(reply_likes)        \n",
        "            \n",
        "            # print(description, \"\\n\\n\", replies, \"\\n\\n\", creator_link, creator_alias, creator_name, \"\\n\\n\", repliers_links, \"\\n\\n\", post_date, \"\\n\\n\", reply_dates, \"\\n\\n\", post_like, \"\\n\\n\", reply_likes)\n",
        "            \n",
        "            csv_list.append(temp_lst)\n",
        "            if i%50 == 0:\n",
        "                print(\"Topic Details for # \"+str(i)+\" from Category \"+cat+\" has been added to csv_list\\t\"+str(data.shape[0]-i)+\" number of topics left\\t Estimated Remaining time for this category: \"+str(int(((data.shape[0]-i)*0.6)/60)) + \" minutes\")\n",
        "    \n",
        "    if categories[cat][1] != 0:\n",
        "        df = pd.DataFrame(csv_list)\n",
        "        df.columns = keys\n",
        "        df.to_csv('topics_details_'+cat+'.csv', index=False)\n",
        "        print('\\nCSV file created. End of '+cat+ ' category\\n\\n')\n",
        "    else:\n",
        "        print('No Topic exists in '+cat+' category')\n",
        "    time.sleep(10)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic Details for # 0 from Category c has been added to csv_list\t1078 number of topics left\t Estimated Remaining time for this category: 10 minutes\n",
            "Topic Details for # 50 from Category c has been added to csv_list\t1028 number of topics left\t Estimated Remaining time for this category: 10 minutes\n",
            "Topic Details for # 100 from Category c has been added to csv_list\t978 number of topics left\t Estimated Remaining time for this category: 9 minutes\n",
            "Topic Details for # 150 from Category c has been added to csv_list\t928 number of topics left\t Estimated Remaining time for this category: 9 minutes\n",
            "Topic Details for # 200 from Category c has been added to csv_list\t878 number of topics left\t Estimated Remaining time for this category: 8 minutes\n",
            "Topic Details for # 250 from Category c has been added to csv_list\t828 number of topics left\t Estimated Remaining time for this category: 8 minutes\n",
            "Topic Details for # 300 from Category c has been added to csv_list\t778 number of topics left\t Estimated Remaining time for this category: 7 minutes\n",
            "Topic Details for # 350 from Category c has been added to csv_list\t728 number of topics left\t Estimated Remaining time for this category: 7 minutes\n",
            "Topic Details for # 400 from Category c has been added to csv_list\t678 number of topics left\t Estimated Remaining time for this category: 6 minutes\n",
            "Topic Details for # 450 from Category c has been added to csv_list\t628 number of topics left\t Estimated Remaining time for this category: 6 minutes\n",
            "Topic Details for # 500 from Category c has been added to csv_list\t578 number of topics left\t Estimated Remaining time for this category: 5 minutes\n",
            "Topic Details for # 550 from Category c has been added to csv_list\t528 number of topics left\t Estimated Remaining time for this category: 5 minutes\n",
            "Topic Details for # 600 from Category c has been added to csv_list\t478 number of topics left\t Estimated Remaining time for this category: 4 minutes\n",
            "Topic Details for # 650 from Category c has been added to csv_list\t428 number of topics left\t Estimated Remaining time for this category: 4 minutes\n",
            "Topic Details for # 700 from Category c has been added to csv_list\t378 number of topics left\t Estimated Remaining time for this category: 3 minutes\n",
            "Topic Details for # 750 from Category c has been added to csv_list\t328 number of topics left\t Estimated Remaining time for this category: 3 minutes\n",
            "Topic Details for # 800 from Category c has been added to csv_list\t278 number of topics left\t Estimated Remaining time for this category: 2 minutes\n",
            "Topic Details for # 850 from Category c has been added to csv_list\t228 number of topics left\t Estimated Remaining time for this category: 2 minutes\n",
            "Topic Details for # 900 from Category c has been added to csv_list\t178 number of topics left\t Estimated Remaining time for this category: 1 minutes\n",
            "Topic Details for # 950 from Category c has been added to csv_list\t128 number of topics left\t Estimated Remaining time for this category: 1 minutes\n",
            "Topic Details for # 1000 from Category c has been added to csv_list\t78 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "Topic Details for # 1050 from Category c has been added to csv_list\t28 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "\n",
            "CSV file created. End of c category\n",
            "\n",
            "\n",
            "Topic Details for # 0 from Category distributed has been added to csv_list\t570 number of topics left\t Estimated Remaining time for this category: 5 minutes\n",
            "Topic Details for # 50 from Category distributed has been added to csv_list\t520 number of topics left\t Estimated Remaining time for this category: 5 minutes\n",
            "Topic Details for # 100 from Category distributed has been added to csv_list\t470 number of topics left\t Estimated Remaining time for this category: 4 minutes\n",
            "Topic Details for # 150 from Category distributed has been added to csv_list\t420 number of topics left\t Estimated Remaining time for this category: 4 minutes\n",
            "Topic Details for # 200 from Category distributed has been added to csv_list\t370 number of topics left\t Estimated Remaining time for this category: 3 minutes\n",
            "Topic Details for # 250 from Category distributed has been added to csv_list\t320 number of topics left\t Estimated Remaining time for this category: 3 minutes\n",
            "Topic Details for # 300 from Category distributed has been added to csv_list\t270 number of topics left\t Estimated Remaining time for this category: 2 minutes\n",
            "Topic Details for # 350 from Category distributed has been added to csv_list\t220 number of topics left\t Estimated Remaining time for this category: 2 minutes\n",
            "Topic Details for # 400 from Category distributed has been added to csv_list\t170 number of topics left\t Estimated Remaining time for this category: 1 minutes\n",
            "Topic Details for # 450 from Category distributed has been added to csv_list\t120 number of topics left\t Estimated Remaining time for this category: 1 minutes\n",
            "Topic Details for # 500 from Category distributed has been added to csv_list\t70 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "Topic Details for # 550 from Category distributed has been added to csv_list\t20 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "\n",
            "CSV file created. End of distributed category\n",
            "\n",
            "\n",
            "Topic Details for # 0 from Category jit has been added to csv_list\t376 number of topics left\t Estimated Remaining time for this category: 3 minutes\n",
            "Topic Details for # 50 from Category jit has been added to csv_list\t326 number of topics left\t Estimated Remaining time for this category: 3 minutes\n",
            "Topic Details for # 100 from Category jit has been added to csv_list\t276 number of topics left\t Estimated Remaining time for this category: 2 minutes\n",
            "Topic Details for # 150 from Category jit has been added to csv_list\t226 number of topics left\t Estimated Remaining time for this category: 2 minutes\n",
            "Topic Details for # 200 from Category jit has been added to csv_list\t176 number of topics left\t Estimated Remaining time for this category: 1 minutes\n",
            "Topic Details for # 250 from Category jit has been added to csv_list\t126 number of topics left\t Estimated Remaining time for this category: 1 minutes\n",
            "Topic Details for # 300 from Category jit has been added to csv_list\t76 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "Topic Details for # 350 from Category jit has been added to csv_list\t26 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "\n",
            "CSV file created. End of jit category\n",
            "\n",
            "\n",
            "Topic Details for # 0 from Category reinforcement-learning has been added to csv_list\t335 number of topics left\t Estimated Remaining time for this category: 3 minutes\n",
            "Topic Details for # 50 from Category reinforcement-learning has been added to csv_list\t285 number of topics left\t Estimated Remaining time for this category: 2 minutes\n",
            "Topic Details for # 100 from Category reinforcement-learning has been added to csv_list\t235 number of topics left\t Estimated Remaining time for this category: 2 minutes\n",
            "Topic Details for # 150 from Category reinforcement-learning has been added to csv_list\t185 number of topics left\t Estimated Remaining time for this category: 1 minutes\n",
            "Topic Details for # 200 from Category reinforcement-learning has been added to csv_list\t135 number of topics left\t Estimated Remaining time for this category: 1 minutes\n",
            "Topic Details for # 250 from Category reinforcement-learning has been added to csv_list\t85 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "Topic Details for # 300 from Category reinforcement-learning has been added to csv_list\t35 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "\n",
            "CSV file created. End of reinforcement-learning category\n",
            "\n",
            "\n",
            "Topic Details for # 0 from Category deployment has been added to csv_list\t228 number of topics left\t Estimated Remaining time for this category: 2 minutes\n",
            "Topic Details for # 50 from Category deployment has been added to csv_list\t178 number of topics left\t Estimated Remaining time for this category: 1 minutes\n",
            "Topic Details for # 100 from Category deployment has been added to csv_list\t128 number of topics left\t Estimated Remaining time for this category: 1 minutes\n",
            "Topic Details for # 150 from Category deployment has been added to csv_list\t78 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "Topic Details for # 200 from Category deployment has been added to csv_list\t28 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "\n",
            "CSV file created. End of deployment category\n",
            "\n",
            "\n",
            "Topic Details for # 0 from Category quantization has been added to csv_list\t204 number of topics left\t Estimated Remaining time for this category: 2 minutes\n",
            "Topic Details for # 50 from Category quantization has been added to csv_list\t154 number of topics left\t Estimated Remaining time for this category: 1 minutes\n",
            "Topic Details for # 100 from Category quantization has been added to csv_list\t104 number of topics left\t Estimated Remaining time for this category: 1 minutes\n",
            "Topic Details for # 150 from Category quantization has been added to csv_list\t54 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "Topic Details for # 200 from Category quantization has been added to csv_list\t4 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "\n",
            "CSV file created. End of quantization category\n",
            "\n",
            "\n",
            "Topic Details for # 0 from Category mobile has been added to csv_list\t125 number of topics left\t Estimated Remaining time for this category: 1 minutes\n",
            "Topic Details for # 50 from Category mobile has been added to csv_list\t75 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "Topic Details for # 100 from Category mobile has been added to csv_list\t25 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "\n",
            "CSV file created. End of mobile category\n",
            "\n",
            "\n",
            "Topic Details for # 0 from Category audio has been added to csv_list\t111 number of topics left\t Estimated Remaining time for this category: 1 minutes\n",
            "Topic Details for # 50 from Category audio has been added to csv_list\t61 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "Topic Details for # 100 from Category audio has been added to csv_list\t11 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "\n",
            "CSV file created. End of audio category\n",
            "\n",
            "\n",
            "Topic Details for # 0 from Category glow has been added to csv_list\t69 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "Topic Details for # 50 from Category glow has been added to csv_list\t19 number of topics left\t Estimated Remaining time for this category: 0 minutes\n",
            "\n",
            "CSV file created. End of glow category\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohm94bX_ll5n"
      },
      "source": [
        "# Run this in the console to prevent Google Colab from disconnecting\n",
        "function ClickConnect(){\n",
        "    console.log(\"Working\"); \n",
        "    document.querySelector(\"colab-toolbar-button\").click() \n",
        "}setInterval(ClickConnect,3600000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}