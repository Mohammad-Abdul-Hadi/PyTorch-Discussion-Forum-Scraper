id,title,fancy_title,slug,posts_count,reply_count,highest_post_number,image_url,created_at,last_posted_at,bumped,bumped_at,archetype,unseen,pinned,unpinned,excerpt,visible,closed,archived,bookmarked,liked,views,like_count,has_summary,last_poster_username,category_id,pinned_globally,featured_link,has_accepted_answer,posters
57360,About the quantization category,About the quantization category,about-the-quantization-category,1,0,1,,2019-10-02T21:54:28.644Z,,True,2019-10-02T21:55:42.335Z,regular,False,True,,"This category is for questions, discussion and issues related to PyTorchâ€™s quantization feature. 
For more information, see: https://github.com/pytorch/pytorch/issues/18318",True,False,False,,,318,0,False,smth,17,False,,False,"[{'extras': 'latest single', 'description': 'Original Poster, Most Recent Poster', 'user_id': 1, 'primary_group_id': None}]"
96590,Is there a way to quantize conv_transpose2d layer?,Is there a way to quantize conv_transpose2d layer?,is-there-a-way-to-quantize-conv-transpose2d-layer,6,4,6,,2020-09-17T07:32:45.932Z,2020-09-27T08:54:52.428Z,True,2020-09-27T08:54:52.428Z,regular,False,False,,,True,False,False,,,97,1,False,ruka,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 36788, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31938, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 18122, 'primary_group_id': None}]"
95589,Is there any way I could get bit value of my weight,Is there any way I could get bit value of my weight,is-there-any-way-i-could-get-bit-value-of-my-weight,3,1,3,,2020-09-08T17:50:00.181Z,2020-09-26T07:53:35.115Z,True,2020-09-26T07:53:35.115Z,regular,False,False,,,True,False,False,,,50,0,False,111179,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 36450, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 24032, 'primary_group_id': None}]"
97459,Best practice or suggestion for QAT?,Best practice or suggestion for QAT?,best-practice-or-suggestion-for-qat,3,1,3,,2020-09-25T07:39:51.315Z,2020-09-26T01:54:45.478Z,True,2020-09-26T01:54:45.478Z,regular,False,False,,,True,False,False,,,35,0,False,eleflea,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 29060, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31938, 'primary_group_id': None}]"
97177,PyTorch quantization resnet50 model,PyTorch quantization resnet50 model,pytorch-quantization-resnet50-model,4,1,4,,2020-09-22T22:03:30.509Z,2020-09-24T17:16:16.762Z,True,2020-09-24T17:16:16.762Z,regular,False,False,,,True,False,False,,,48,0,False,samhithaaaa,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 36728, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31938, 'primary_group_id': None}]"
97325,How to extract the quantized weight of quantized NN model,How to extract the quantized weight of quantized NN model,how-to-extract-the-quantized-weight-of-quantized-nn-model,2,0,2,,2020-09-24T04:29:46.744Z,2020-09-24T15:53:28.405Z,True,2020-09-24T15:53:28.405Z,regular,False,False,,,True,False,False,,,26,0,False,Vasiliy_Kuznetsov,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 24032, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 31938, 'primary_group_id': None}]"
97368,How pytorch simulates bias during quantization aware training,How pytorch simulates bias during quantization aware training,how-pytorch-simulates-bias-during-quantization-aware-training,1,0,1,,2020-09-24T12:57:47.119Z,2020-09-24T12:57:47.215Z,True,2020-09-24T12:57:47.215Z,regular,False,False,,,True,False,False,,,24,0,False,Jonson,17,False,,False,"[{'extras': 'latest single', 'description': 'Original Poster, Most Recent Poster', 'user_id': 8928, 'primary_group_id': None}]"
97016,Qnnpack vs. fbgemm,Qnnpack vs. fbgemm,qnnpack-vs-fbgemm,5,3,6,,2020-09-21T15:07:04.265Z,2020-09-23T16:00:19.337Z,True,2020-09-23T16:00:19.337Z,regular,False,False,,,True,False,False,,,84,0,False,Vasiliy_Kuznetsov,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 35961, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 31938, 'primary_group_id': None}]"
97170,PyTorch Quantization,PyTorch Quantization,pytorch-quantization,1,0,1,,2020-09-22T20:58:17.189Z,2020-09-22T20:58:17.279Z,True,2020-09-22T20:58:17.279Z,regular,False,False,,,True,False,False,,,25,0,False,samhithaaaa,17,False,,False,"[{'extras': 'latest single', 'description': 'Original Poster, Most Recent Poster', 'user_id': 36728, 'primary_group_id': None}]"
96488,How does pytorch determine which backend a function supports,How does pytorch determine which backend a function supports,how-does-pytorch-determine-which-backend-a-function-supports,3,1,3,,2020-09-16T11:31:08.960Z,2020-09-21T22:43:40.809Z,True,2020-09-21T22:43:40.809Z,regular,False,False,,,True,False,False,,,50,0,False,Ofir_Zafrir,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 36754, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 616, 'primary_group_id': None}]"
85902,"How to avoid Quantization warning: ""Must run observer before calling calculate_qparams.""?",How to avoid Quantization warning: &ldquo;Must run observer before calling calculate_qparams.&rdquo;?,how-to-avoid-quantization-warning-must-run-observer-before-calling-calculate-qparams,8,5,8,,2020-06-18T10:56:23.331Z,2020-09-21T19:42:25.982Z,True,2020-09-21T19:42:25.982Z,regular,False,False,,,True,False,False,,,333,3,False,Ashar_Ali,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 32246, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 33196, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31330, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 36943, 'primary_group_id': None}]"
82405,Am I correct in concluding that resnet that comes with pytorch can't be quantized by pytorch?,Am I correct in concluding that resnet that comes with pytorch can&rsquo;t be quantized by pytorch?,am-i-correct-in-concluding-that-resnet-that-comes-with-pytorch-cant-be-quantized-by-pytorch,7,2,8,,2020-05-22T01:00:41.404Z,2020-09-18T17:02:01.652Z,True,2020-09-18T17:02:01.652Z,regular,False,False,,,True,False,False,,,308,0,False,Vasiliy_Kuznetsov,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 30735, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 36728, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 32757, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 31938, 'primary_group_id': None}]"
96553,"torch.nn.MaxPool2d does not need ""input"" argument run but quantized function torch.nn.quantized.functional.max_pool2d must have it",torch.nn.MaxPool2d does not need &ldquo;input&rdquo; argument run but quantized function torch.nn.quantized.functional.max_pool2d must have it,torch-nn-maxpool2d-does-not-need-input-argument-run-but-quantized-function-torch-nn-quantized-functional-max-pool2d-must-have-it,2,0,2,,2020-09-16T21:30:31.619Z,2020-09-18T14:11:01.631Z,True,2020-09-18T14:11:01.631Z,regular,False,False,,,True,False,False,,,37,0,False,parth15041995,17,False,,True,"[{'extras': 'latest single', 'description': 'Original Poster, Most Recent Poster', 'user_id': 34592, 'primary_group_id': None}]"
91555,The results of torch.profiler() and time.time() do not match,The results of torch.profiler() and time.time() do not match,the-results-of-torch-profiler-and-time-time-do-not-match,8,6,8,https://discuss.pytorch.org/uploads/default/optimized/3X/4/0/40a4db2e2ec2e62afd8f78374c15f66b637dab22_2_1024x86.png,2020-08-04T03:40:26.989Z,2020-09-18T03:45:08.002Z,True,2020-09-18T03:45:08.002Z,regular,False,False,,,True,False,False,,,118,3,False,dujiangsu,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 30681, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 3534, 'primary_group_id': None}]"
96496,"Why program exit after the backward funtion ,please help","Why program exit after the backward funtion ,please help",why-program-exit-after-the-backward-funtion-please-help,2,0,2,https://discuss.pytorch.org/uploads/default/optimized/3X/c/3/c3d9b63d76ab248b6f14d3f75b004751d833fad2_2_1024x393.png,2020-09-16T12:11:21.651Z,2020-09-16T12:22:58.674Z,True,2020-09-16T12:22:58.674Z,regular,False,False,,,True,False,False,,,24,0,False,Disp41r_QAQ,17,False,,False,"[{'extras': 'latest single', 'description': 'Original Poster, Most Recent Poster', 'user_id': 36758, 'primary_group_id': None}]"
96260,Bfloat16 + transformers,Bfloat16 + transformers,bfloat16-transformers,1,0,1,,2020-09-14T19:03:35.209Z,2020-09-14T19:03:35.287Z,True,2020-09-15T04:11:44.885Z,regular,False,False,,,True,False,False,,,68,0,False,Sam_Shleifer,17,False,,False,"[{'extras': 'latest single', 'description': 'Original Poster, Most Recent Poster', 'user_id': 27445, 'primary_group_id': None}]"
58580,PyTorch 1.3 wheels for Raspberry Pi (Python 3.7),PyTorch 1.3 wheels for Raspberry Pi (Python 3.7),pytorch-1-3-wheels-for-raspberry-pi-python-3-7,14,6,14,,2019-10-18T14:59:24.512Z,2020-09-14T20:28:41.921Z,True,2020-09-14T20:28:41.921Z,regular,False,False,,,True,False,False,,,2838,10,False,suhridh,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 16109, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 14570, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 29851, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 35977, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 36680, 'primary_group_id': None}]"
94165,Object Detection Quantization in PyTorch,Object Detection Quantization in PyTorch,object-detection-quantization-in-pytorch,4,2,4,,2020-08-26T10:05:39.152Z,2020-09-12T00:05:55.713Z,True,2020-09-12T00:05:55.713Z,regular,False,False,,,True,False,False,,,107,3,False,supriyar,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 22068, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 19099, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 24320, 'primary_group_id': None}]"
74439,Got slow speed on quantized model with fbgemm on X86,Got slow speed on quantized model with fbgemm on X86,got-slow-speed-on-quantized-model-with-fbgemm-on-x86,7,2,7,,2020-03-26T11:23:21.741Z,2020-09-11T01:28:30.745Z,True,2020-09-11T01:28:30.745Z,regular,False,False,,,True,False,False,,,330,1,False,kekepa15,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 11431, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 19099, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 36541, 'primary_group_id': None}]"
95734,How to ensure the repeatability of the results of the Pytorch model across devicesï¼Ÿ,How to ensure the repeatability of the results of the Pytorch model across devicesï¼Ÿ,how-to-ensure-the-repeatability-of-the-results-of-the-pytorch-model-across-devices,2,0,2,,2020-09-10T04:15:12.674Z,2020-09-10T05:02:26.555Z,True,2020-09-10T05:02:26.555Z,regular,False,False,,,True,False,False,,,36,0,False,briankosw,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 36503, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 19848, 'primary_group_id': None}]"
88063,Understand the usage of quantized weights from quantized model,Understand the usage of quantized weights from quantized model,understand-the-usage-of-quantized-weights-from-quantized-model,12,6,12,,2020-07-06T04:03:40.710Z,2020-09-06T13:39:46.113Z,True,2020-09-06T13:39:46.113Z,regular,False,False,,,True,False,False,,,361,2,False,111179,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 33925, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 7863, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31938, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 24032, 'primary_group_id': None}]"
94946,Can nn.quantized.FloatFunctional().cat() be used multiple times in one module?,Can nn.quantized.FloatFunctional().cat() be used multiple times in one module?,can-nn-quantized-floatfunctional-cat-be-used-multiple-times-in-one-module,3,0,3,,2020-09-02T12:35:57.466Z,2020-09-04T08:43:48.528Z,True,2020-09-04T08:43:48.528Z,regular,False,False,,,True,False,False,,,61,0,False,chuanqi305,17,False,,True,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 36243, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23504, 'primary_group_id': None}]"
94961,Permutation not working in Quantized Model,Permutation not working in Quantized Model,permutation-not-working-in-quantized-model,4,2,4,,2020-09-02T14:37:15.242Z,2020-09-03T23:54:08.620Z,True,2020-09-03T23:54:08.620Z,regular,False,False,,,True,False,False,,,73,2,False,hx89,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 5285, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 23504, 'primary_group_id': None}]"
94303,How to use quantize_per_tensor,How to use quantize_per_tensor,how-to-use-quantize-per-tensor,5,2,5,,2020-08-27T12:30:00.338Z,2020-09-02T16:05:15.259Z,True,2020-09-02T16:05:15.259Z,regular,False,False,,,True,False,False,,,90,0,False,aprasad,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 36019, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 19099, 'primary_group_id': None}]"
83294,GPU support for quantization,GPU support for quantization,gpu-support-for-quantization,5,2,5,,2020-05-29T00:01:55.162Z,2020-09-01T12:39:05.712Z,True,2020-09-01T12:39:05.712Z,regular,False,False,,,True,False,False,,,130,3,False,KevinPD66,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 29439, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 36203, 'primary_group_id': None}]"
94144,FwFM Quantization,FwFM Quantization,fwfm-quantization,5,1,5,,2020-08-26T08:11:43.197Z,2020-08-28T16:44:04.200Z,True,2020-08-28T16:44:04.200Z,regular,False,False,,,True,False,False,,,79,2,False,Vasiliy_Kuznetsov,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 35961, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 3534, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 31938, 'primary_group_id': None}]"
93844,Incorrect results after loading saved quantized model,Incorrect results after loading saved quantized model,incorrect-results-after-loading-saved-quantized-model,3,0,3,,2020-08-24T02:42:16.082Z,2020-08-28T16:40:36.737Z,True,2020-08-28T16:40:36.737Z,regular,False,False,,,True,False,False,,,84,1,False,Vasiliy_Kuznetsov,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 7477, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 31938, 'primary_group_id': None}]"
90990,Performance drop when quantizing Efficientnet,Performance drop when quantizing Efficientnet,performance-drop-when-quantizing-efficientnet,14,9,14,,2020-07-29T16:46:29.722Z,2020-08-27T11:37:34.682Z,True,2020-08-27T11:37:34.682Z,regular,False,False,,,True,False,False,,,293,2,False,Tomek,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 34925, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23504, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31164, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 35219, 'primary_group_id': None}]"
93601,Qnnpack accuracy very poor on unet model,Qnnpack accuracy very poor on unet model,qnnpack-accuracy-very-poor-on-unet-model,6,3,6,,2020-08-21T08:07:14.122Z,2020-08-25T01:42:48.839Z,True,2020-08-25T02:45:50.287Z,regular,False,False,,,True,False,False,,,116,0,False,amitdedhia,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 28932, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}]"
91609,Quantisation aware training LSTM with pack_padded_sequences?,Quantisation aware training LSTM with pack_padded_sequences?,quantisation-aware-training-lstm-with-pack-padded-sequences,3,0,3,,2020-08-04T13:03:19.538Z,2020-08-25T00:22:51.341Z,True,2020-08-25T00:22:51.341Z,regular,False,False,,,True,False,False,,,85,0,False,supriyar,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 35138, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 24320, 'primary_group_id': None}]"
93514,Custom quantized Linear or Conv2d layer,Custom quantized Linear or Conv2d layer,custom-quantized-linear-or-conv2d-layer,3,1,3,,2020-08-20T16:16:46.563Z,2020-08-22T13:39:39.589Z,True,2020-08-22T13:39:39.589Z,regular,False,False,,,True,False,False,,,69,1,False,martinferianc,17,False,,True,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 25262, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}]"
91849,Initializing QAT with pre-trained quantization parameters,Initializing QAT with pre-trained quantization parameters,initializing-qat-with-pre-trained-quantization-parameters,3,1,3,,2020-08-06T11:56:03.965Z,2020-08-22T00:22:04.141Z,True,2020-08-22T00:22:04.141Z,regular,False,False,,,True,False,False,,,85,0,False,jkosaian,17,False,,True,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 35217, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}]"
88975,"RuntimeError: Could not run 'aten::native_batch_norm' with arguments from the 'QuantizedCPUTensorId' backend. 'aten::native_batch_norm' is only available for these backends: [CPUTensorId, MkldnnCPUTensorId, VariableTensorId]","RuntimeError: Could not run &lsquo;aten::native_batch_norm&rsquo; with arguments from the &lsquo;QuantizedCPUTensorId&rsquo; backend. &lsquo;aten::native_batch_norm&rsquo; is only available for these backends: [CPUTensorId, MkldnnCPUTensorId, VariableTensorId]",runtimeerror-could-not-run-aten-native-batch-norm-with-arguments-from-the-quantizedcputensorid-backend-aten-native-batch-norm-is-only-available-for-these-backends-cputensorid-mkldnncputensorid-variabletensorid,18,14,18,,2020-07-13T10:27:11.281Z,2020-08-21T22:57:29.826Z,True,2020-08-21T22:57:29.826Z,regular,False,False,,,True,False,False,,,390,1,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 7863, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31330, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31938, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
91686,Quantizing Transformer Architecture Below 8-bit (post training quantization),Quantizing Transformer Architecture Below 8-bit (post training quantization),quantizing-transformer-architecture-below-8-bit-post-training-quantization,5,3,5,,2020-08-05T07:14:01.024Z,2020-08-21T22:54:43.028Z,True,2020-08-21T22:54:43.028Z,regular,False,False,,,True,False,False,,,148,1,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 11592, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 616, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
93585,Static Quantization of nn.ConstantPad2d,Static Quantization of nn.ConstantPad2d,static-quantization-of-nn-constantpad2d,2,0,2,,2020-08-21T05:06:02.557Z,2020-08-21T22:34:11.695Z,True,2020-08-21T22:34:11.695Z,regular,False,False,,,True,False,False,,,78,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 7477, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
88098,Reduction in performance of quantized bert model,Reduction in performance of quantized bert model,reduction-in-performance-of-quantized-bert-model,10,6,10,,2020-07-06T11:29:53.288Z,2020-08-21T22:24:12.117Z,True,2020-08-21T22:24:12.117Z,regular,False,False,,,True,False,False,,,228,1,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 22807, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31938, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 34925, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
93318,Calculate_qparams should not be called for NoopObserver,Calculate_qparams should not be called for NoopObserver,calculate-qparams-should-not-be-called-for-noopobserver,2,0,2,,2020-08-19T04:55:48.181Z,2020-08-21T21:57:08.373Z,True,2020-08-21T21:57:08.373Z,regular,False,False,,,True,False,False,,,42,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 19983, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
59531,Dynamic Quantization not reducing model size,Dynamic Quantization not reducing model size,dynamic-quantization-not-reducing-model-size,8,4,8,,2019-10-30T03:19:17.107Z,2020-08-19T07:23:32.108Z,True,2020-08-19T07:23:32.108Z,regular,False,False,,,True,False,False,,,782,6,False,deepak_mangla,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23738, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23263, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 32537, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 7477, 'primary_group_id': None}]"
91673,Convert floating point 32 bit of input and pretrained weight to 8bit,Convert floating point 32 bit of input and pretrained weight to 8bit,convert-floating-point-32-bit-of-input-and-pretrained-weight-to-8bit,2,0,2,,2020-08-05T05:46:28.565Z,2020-08-12T18:51:49.175Z,True,2020-08-12T19:00:25.905Z,regular,False,False,,,True,False,False,,,106,0,False,Zafar,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 33711, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 18122, 'primary_group_id': None}]"
90019,Simple quantized model doesn't export to ONNX,Simple quantized model doesn&rsquo;t export to ONNX,simple-quantized-model-doesnt-export-to-onnx,8,5,8,,2020-07-21T11:12:10.116Z,2020-08-12T17:38:19.346Z,True,2020-08-12T17:38:19.346Z,regular,False,False,,,True,False,False,,,246,1,False,jackm321,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 34277, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 35472, 'primary_group_id': None}]"
92150,Layer wise quantization,Layer wise quantization,layer-wise-quantization,3,1,3,,2020-08-09T08:52:26.999Z,2020-08-12T16:38:24.128Z,True,2020-08-12T16:38:24.128Z,regular,False,False,,,True,False,False,,,77,3,False,jerryzh168,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 35324, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
88514,Quantization/QAT causing jit.script to fail,Quantization/QAT causing jit.script to fail,quantization-qat-causing-jit-script-to-fail,12,11,13,,2020-07-09T07:27:51.326Z,2020-08-12T03:13:28.152Z,True,2020-08-12T03:13:28.152Z,regular,False,False,,,True,False,False,,,238,2,False,kekpirat,17,False,,True,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 33968, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}]"
90954,Slow quantization,Slow quantization,slow-quantization,7,4,7,,2020-07-29T10:56:04.905Z,2020-08-04T01:02:38.339Z,True,2020-08-04T01:02:38.339Z,regular,False,False,,,True,False,False,,,252,1,False,dskhudia,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 22145, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 19099, 'primary_group_id': None}]"
84588,[Nightly] Packed params no longer returned via state_dict() method,[Nightly] Packed params no longer returned via state_dict() method,nightly-packed-params-no-longer-returned-via-state-dict-method,8,3,8,,2020-06-08T04:08:23.381Z,2020-08-03T23:10:11.855Z,True,2020-08-03T23:10:11.855Z,regular,False,False,,,True,False,False,,,176,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 26617, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
90948,How to freeze the FakeQuantize zero_point during train,How to freeze the FakeQuantize zero_point during train,how-to-freeze-the-fakequantize-zero-point-during-train,4,0,4,,2020-07-29T09:53:31.588Z,2020-08-03T15:51:02.899Z,True,2020-08-03T15:51:02.899Z,regular,False,False,,,True,False,False,,,111,2,False,supriyar,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 34908, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 24320, 'primary_group_id': None}]"
91114,Not able to run quantized model on android,Not able to run quantized model on android,not-able-to-run-quantized-model-on-android,2,0,2,,2020-07-30T14:47:28.880Z,2020-07-30T18:53:50.199Z,True,2020-07-30T18:53:50.199Z,regular,False,False,,,True,False,False,,,127,0,False,dzhulgakov,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 22145, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 3598, 'primary_group_id': None}]"
59754,Onnx export failed int8 model,Onnx export failed int8 model,onnx-export-failed-int8-model,18,11,18,,2019-11-01T08:30:51.477Z,2020-07-30T18:27:07.005Z,True,2020-07-30T18:27:07.005Z,regular,False,False,,,True,False,False,,,907,1,False,supriyar,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23919, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 26670, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 27222, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 34277, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 24320, 'primary_group_id': None}]"
82244,[ONNX] Quantized fused Conv2d won't trace,[ONNX] Quantized fused Conv2d won&rsquo;t trace,onnx-quantized-fused-conv2d-wont-trace,19,12,19,,2020-05-20T21:28:02.355Z,2020-07-30T15:50:03.464Z,True,2020-07-30T15:50:03.464Z,regular,False,False,,,True,False,False,,,475,2,False,jerryzh168,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23886, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 25755, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31330, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
89465,nn.MultiheadAttention fails after quantization,nn.MultiheadAttention fails after quantization,nn-multiheadattention-fails-after-quantization,7,6,8,,2020-07-16T15:54:30.444Z,2020-07-29T16:02:58.099Z,True,2020-07-29T16:02:58.099Z,regular,False,False,,,True,False,False,,,137,1,False,skurzhanskyi,17,False,,True,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 34286, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31938, 'primary_group_id': None}]"
90788,Variation of results,Variation of results,variation-of-results,2,0,2,,2020-07-28T07:56:35.775Z,2020-07-28T17:00:44.040Z,True,2020-07-28T17:00:44.040Z,regular,False,False,,,True,False,False,,,62,0,False,dskhudia,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 22068, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 19099, 'primary_group_id': None}]"
77399,"Error in inference phase, after loading quantized model","Error in inference phase, after loading quantized model",error-in-inference-phase-after-loading-quantized-model,5,2,5,,2020-04-19T07:47:38.377Z,2020-07-27T03:01:57.998Z,True,2020-07-27T03:01:57.998Z,regular,False,False,,,True,False,False,,,171,0,False,khaidoan25,17,False,,True,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 30228, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 34330, 'primary_group_id': None}]"
90445,Bottleneck on data loading,Bottleneck on data loading,bottleneck-on-data-loading,2,0,2,,2020-07-24T17:27:41.777Z,2020-07-26T08:54:53.577Z,True,2020-07-26T08:54:53.577Z,regular,False,False,,,True,False,False,,,81,0,False,ptrblck,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 34742, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 3534, 'primary_group_id': None}]"
90458,Quantized model inference error related to Mish activation function,Quantized model inference error related to Mish activation function,quantized-model-inference-error-related-to-mish-activation-function,3,0,3,,2020-07-24T20:19:21.022Z,2020-07-24T23:35:20.976Z,True,2020-07-24T23:35:20.976Z,regular,False,False,,,True,False,False,,,99,1,False,Anouar_LAOUICHI,17,False,,True,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 32763, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31938, 'primary_group_id': None}]"
67158,The packing format of quantized parameters after jitting,The packing format of quantized parameters after jitting,the-packing-format-of-quantized-parameters-after-jitting,5,1,5,,2020-01-20T09:47:01.813Z,2020-07-22T19:28:52.852Z,True,2020-07-22T19:28:52.852Z,regular,False,False,,,True,False,False,,,297,2,False,k.osama,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 26617, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 28734, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 30754, 'primary_group_id': None}]"
89086,"_combine_histograms histogram_with_output_range = torch.zeros((Nbins * downsample_rate), device=orig_hist.device) RuntimeError: Trying to create tensor with negative dimension -4398046511104: [-4398046511104]","_combine_histograms histogram_with_output_range = torch.zeros((Nbins * downsample_rate), device=orig_hist.device) RuntimeError: Trying to create tensor with negative dimension -4398046511104: [-4398046511104]",combine-histograms-histogram-with-output-range-torch-zeros-nbins-downsample-rate-device-orig-hist-device-runtimeerror-trying-to-create-tensor-with-negative-dimension-4398046511104-4398046511104,9,5,9,,2020-07-14T04:29:34.877Z,2020-07-22T06:10:34.370Z,True,2020-07-22T07:36:41.252Z,regular,False,False,,,True,False,False,,,177,2,False,Shisho_Sama,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 7863, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 211, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}]"
76884,ONNX export of quantized model,ONNX export of quantized model,onnx-export-of-quantized-model,15,9,15,,2020-04-15T15:14:40.744Z,2020-07-22T01:03:14.778Z,True,2020-07-22T01:03:14.778Z,regular,False,False,,,True,False,False,,,1212,6,False,RicCu,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23886, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 9625, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23263, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 34586, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 3404, 'primary_group_id': None}]"
89501,Quantized model not provide performance improvements,Quantized model not provide performance improvements,quantized-model-not-provide-performance-improvements,4,1,4,,2020-07-16T21:00:58.401Z,2020-07-21T14:13:14.543Z,True,2020-07-21T14:13:14.543Z,regular,False,False,,,True,False,False,,,105,0,False,fel88,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 34413, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31938, 'primary_group_id': None}]"
84855,Converting quantized models from PyTorch to ONNX,Converting quantized models from PyTorch to ONNX,converting-quantized-models-from-pytorch-to-onnx,5,1,5,,2020-06-10T07:39:38.299Z,2020-07-21T02:40:16.166Z,True,2020-07-21T02:40:16.166Z,regular,False,False,,,True,False,False,,,565,1,False,Joseph_Konan,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 32700, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31330, 'primary_group_id': None}]"
89042,Loading Quantized Model from State_Dict with Version==None,Loading Quantized Model from State_Dict with Version==None,loading-quantized-model-from-state-dict-with-version-none,3,0,3,,2020-07-13T19:59:52.515Z,2020-07-20T16:45:30.805Z,True,2020-07-20T16:45:30.805Z,regular,False,False,,,True,False,False,,,97,2,False,salimmj,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 34225, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31938, 'primary_group_id': None}]"
88553,Network pruning error,Network pruning error,network-pruning-error,13,10,13,,2020-07-09T11:57:47.483Z,2020-07-18T15:34:00.015Z,True,2020-07-18T15:34:00.015Z,regular,False,False,,,True,False,False,,,140,6,False,Michela,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 13802, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 3335, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 25637, 'primary_group_id': None}]"
75607,Extending Quantization-Aware Training,Extending Quantization-Aware Training,extending-quantization-aware-training,5,2,5,,2020-04-06T20:01:48.433Z,2020-07-17T04:39:53.777Z,True,2020-07-17T04:39:53.777Z,regular,False,False,,,True,False,False,,,232,0,False,111179,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 29603, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 24032, 'primary_group_id': None}]"
84700,Output tensor type is lost after serializing and loading back a quantized model,Output tensor type is lost after serializing and loading back a quantized model,output-tensor-type-is-lost-after-serializing-and-loading-back-a-quantized-model,6,1,6,,2020-06-09T01:13:22.765Z,2020-07-16T20:28:46.321Z,True,2020-07-16T20:28:46.321Z,regular,False,False,,,True,False,False,,,103,0,False,Zafar,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 26617, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 18122, 'primary_group_id': None}]"
86805,Static quantizing and batch norm error (could not run aten::native_batch_norm with args from QuantCPUTensorid backend'),Static quantizing and batch norm error (could not run aten::native_batch_norm with args from QuantCPUTensorid backend&rsquo;),static-quantizing-and-batch-norm-error-could-not-run-aten-native-batch-norm-with-args-from-quantcputensorid-backend,5,2,5,,2020-06-25T00:53:41.407Z,2020-07-16T03:14:15.792Z,True,2020-07-16T03:14:15.792Z,regular,False,False,,,True,False,False,,,142,3,False,blueskywwc,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 14429, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23504, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 31330, 'primary_group_id': None}]"
88234,Backward prop per Batch of data or backward prop after one epoch,Backward prop per Batch of data or backward prop after one epoch,backward-prop-per-batch-of-data-or-backward-prop-after-one-epoch,5,3,5,,2020-07-07T13:11:02.459Z,2020-07-15T10:41:49.053Z,True,2020-07-15T10:41:49.053Z,regular,False,False,,,True,False,False,,,100,0,False,Henry_Chibueze,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 33986, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 3534, 'primary_group_id': None}]"
89103,"Prediction , objective function and optimization in Python - AI","Prediction , objective function and optimization in Python - AI",prediction-objective-function-and-optimization-in-python-ai,2,0,2,,2020-07-14T06:57:55.124Z,2020-07-15T09:35:53.579Z,True,2020-07-15T09:35:53.579Z,regular,False,False,,,True,False,False,,,43,0,False,ptrblck,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 34274, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 3534, 'primary_group_id': None}]"
89154,Is it planned to support nn.Embeddings quantization?,Is it planned to support nn.Embeddings quantization?,is-it-planned-to-support-nn-embeddings-quantization,2,0,2,,2020-07-14T13:19:44.747Z,2020-07-14T17:01:06.935Z,True,2020-07-14T17:01:06.935Z,regular,False,False,,,True,False,False,,,59,1,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 34286, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
89080,How can I incorporate PReLU in a quantized model?,How can I incorporate PReLU in a quantized model?,how-can-i-incorporate-prelu-in-a-quantized-model,4,2,4,,2020-07-14T02:40:07.361Z,2020-07-14T12:06:01.463Z,True,2020-07-14T12:22:49.204Z,regular,False,False,,,True,False,False,,,119,1,False,Shisho_Sama,17,False,,True,"[{'extras': 'latest single', 'description': 'Original Poster, Most Recent Poster', 'user_id': 7863, 'primary_group_id': None}]"
88486,QuantStub/DeQuantStubs for QAT confusion,QuantStub/DeQuantStubs for QAT confusion,quantstub-dequantstubs-for-qat-confusion,3,0,3,,2020-07-09T03:57:31.577Z,2020-07-09T21:43:23.413Z,True,2020-07-09T21:43:23.413Z,regular,False,False,,,True,False,False,,,117,0,False,Vasiliy_Kuznetsov,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 33968, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 31938, 'primary_group_id': None}]"
64213,Loading of Quantized Model,Loading of Quantized Model,loading-of-quantized-model,5,1,6,,2019-12-16T12:25:28.112Z,2020-07-09T10:22:17.844Z,True,2020-07-09T10:22:17.844Z,regular,False,False,,,True,False,False,,,588,1,False,Giang_Dang,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 24354, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23263, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 33925, 'primary_group_id': None}]"
87531,The accuracy after int8 is higher than before quantization,The accuracy after int8 is higher than before quantization,the-accuracy-after-int8-is-higher-than-before-quantization,6,2,6,,2020-07-01T03:51:52.845Z,2020-07-09T03:34:28.823Z,True,2020-07-09T03:34:28.823Z,regular,False,False,,,True,False,False,,,129,1,False,blueskywwc,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 31330, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31938, 'primary_group_id': None}]"
88190,Quantization.convert after QAT pickling issue,Quantization.convert after QAT pickling issue,quantization-convert-after-qat-pickling-issue,3,1,3,,2020-07-07T06:43:57.585Z,2020-07-08T03:47:11.943Z,True,2020-07-08T03:47:11.943Z,regular,False,False,,,True,False,False,,,92,0,False,kekpirat,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 33968, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31938, 'primary_group_id': None}]"
66106,Quantization awareness training multi-gpu suport?,Quantization awareness training multi-gpu suport?,quantization-awareness-training-multi-gpu-suport,18,13,19,,2020-01-08T14:47:59.411Z,2020-07-08T02:01:01.469Z,True,2020-07-08T02:01:01.469Z,regular,False,False,,,True,False,False,,,676,1,False,Vasiliy_Kuznetsov,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 10229, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 19099, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 30138, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23263, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 31938, 'primary_group_id': None}]"
86708,No Difference in Model size of BERT fine-tuned with amp and without amp,No Difference in Model size of BERT fine-tuned with amp and without amp,no-difference-in-model-size-of-bert-fine-tuned-with-amp-and-without-amp,9,6,9,,2020-06-24T11:32:19.006Z,2020-07-07T08:37:13.322Z,True,2020-07-07T08:37:13.322Z,regular,False,False,,,True,False,False,,,137,0,False,Ramesh_Kumar,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 22807, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23504, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 3534, 'primary_group_id': None}]"
87319,Quantization not Decreasing Model Size (Static and QAT),Quantization not Decreasing Model Size (Static and QAT),quantization-not-decreasing-model-size-static-and-qat,8,4,10,,2020-06-29T15:50:42.522Z,2020-07-06T21:17:35.907Z,True,2020-07-06T21:17:35.907Z,regular,False,False,,,True,False,False,,,225,2,False,Vasiliy_Kuznetsov,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23738, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 31938, 'primary_group_id': None}]"
87807,How to convert a 32-bit operation to a 4-bit or 8-bit operation on cpu?,How to convert a 32-bit operation to a 4-bit or 8-bit operation on cpu?,how-to-convert-a-32-bit-operation-to-a-4-bit-or-8-bit-operation-on-cpu,2,0,2,,2020-07-03T07:51:14.765Z,2020-07-06T18:03:50.336Z,True,2020-07-06T18:03:50.336Z,regular,False,False,,,True,False,False,,,76,0,False,Vasiliy_Kuznetsov,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 33797, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 31938, 'primary_group_id': None}]"
74895,Quantize the CRNN model,Quantize the CRNN model,quantize-the-crnn-model,6,3,6,,2020-03-31T11:14:31.204Z,2020-07-04T02:01:36.819Z,True,2020-07-04T02:01:36.819Z,regular,False,False,,,True,False,False,,,161,0,False,THU-cui,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23372, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 11431, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23504, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 33804, 'primary_group_id': None}]"
87901,Export fp16 model to ONNX,Export fp16 model to ONNX,export-fp16-model-to-onnx,1,0,1,,2020-07-04T01:59:18.547Z,2020-07-04T01:59:18.603Z,True,2020-07-04T01:59:18.603Z,regular,False,False,,,True,False,False,,,70,0,False,Hiperdyne19012,17,False,,False,"[{'extras': 'latest single', 'description': 'Original Poster, Most Recent Poster', 'user_id': 33167, 'primary_group_id': None}]"
87395,"Int8 quantization of the resnet18 model, the results of each quantization are inconsistent","Int8 quantization of the resnet18 model, the results of each quantization are inconsistent",int8-quantization-of-the-resnet18-model-the-results-of-each-quantization-are-inconsistent,1,0,1,,2020-06-30T07:03:56.639Z,2020-06-30T07:03:56.701Z,True,2020-07-01T02:40:37.857Z,regular,False,False,,,True,False,False,,,94,0,False,blueskywwc,17,False,,False,"[{'extras': 'latest single', 'description': 'Original Poster, Most Recent Poster', 'user_id': 31330, 'primary_group_id': None}]"
87004,INT8 quantized model is much slower than fp32 model on CPU,INT8 quantized model is much slower than fp32 model on CPU,int8-quantized-model-is-much-slower-than-fp32-model-on-cpu,12,6,12,,2020-06-26T09:09:08.950Z,2020-07-01T02:14:31.837Z,True,2020-07-01T02:14:31.837Z,regular,False,False,,,True,False,False,,,340,0,False,Jungmo_Ahn,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 15952, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23372, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31938, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 33739, 'primary_group_id': None}]"
87405,Resnet18 model has multiple quantized results that are inconsistent,Resnet18 model has multiple quantized results that are inconsistent,resnet18-model-has-multiple-quantized-results-that-are-inconsistent,3,1,3,,2020-06-30T07:34:58.721Z,2020-07-01T02:08:47.000Z,True,2020-07-01T02:08:47.000Z,regular,False,False,,,True,False,False,,,107,0,False,blueskywwc,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 31330, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31938, 'primary_group_id': None}]"
59966,Quantization Error During Concat -- RuntimeError: Didn't find kernel to dispatch to for operator 'aten::_cat',Quantization Error During Concat &ndash; RuntimeError: Didn&rsquo;t find kernel to dispatch to for operator &lsquo;aten::_cat&rsquo;,quantization-error-during-concat-runtimeerror-didnt-find-kernel-to-dispatch-to-for-operator-aten-cat,31,17,31,,2019-11-04T16:32:57.677Z,2020-06-28T22:13:02.157Z,True,2020-06-29T16:12:29.919Z,regular,False,False,,,True,False,False,,,1332,7,False,Raghav_Gurbaxani,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 23738, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 19099, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23263, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23504, 'primary_group_id': None}]"
60008,Quantized model consists of ReLU6,Quantized model consists of ReLU6,quantized-model-consists-of-relu6,6,2,6,,2019-11-05T02:29:35.257Z,2020-06-29T00:31:40.809Z,True,2020-06-29T00:31:40.809Z,regular,False,False,,,True,False,False,,,436,2,False,Raghav_Gurbaxani,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 24011, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23653, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23263, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 23738, 'primary_group_id': None}]"
86928,Can quantizing models enable you to have bigger batch sizes during inference?,Can quantizing models enable you to have bigger batch sizes during inference?,can-quantizing-models-enable-you-to-have-bigger-batch-sizes-during-inference,2,0,2,,2020-06-25T17:31:47.484Z,2020-06-26T01:03:14.964Z,True,2020-06-26T01:03:14.964Z,regular,False,False,,,True,False,False,,,66,0,False,supriyar,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 6124, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 24320, 'primary_group_id': None}]"
86637,Slow inference on quantized MobileNetV3,Slow inference on quantized MobileNetV3,slow-inference-on-quantized-mobilenetv3,7,3,7,https://discuss.pytorch.org/uploads/default/optimized/3X/f/d/fd35d1fe452d9f531963a6c22d53f54288481cf1_2_1024x499.jpeg,2020-06-24T01:49:39.365Z,2020-06-25T16:58:11.514Z,True,2020-06-25T19:51:40.285Z,regular,False,False,,,True,False,False,,,197,1,False,singularity,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 33459, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23504, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}]"
86768,Convert FP32 model in torchvision.models to INT8 model,Convert FP32 model in torchvision.models to INT8 model,convert-fp32-model-in-torchvision-models-to-int8-model,9,4,9,,2020-06-24T17:38:26.438Z,2020-06-25T18:38:52.426Z,True,2020-06-25T18:38:52.426Z,regular,False,False,,,True,False,False,,,302,1,False,Jungmo_Ahn,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 15952, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23504, 'primary_group_id': None}]"
86042,Unable to quantize the model due to RuntimeError,Unable to quantize the model due to RuntimeError,unable-to-quantize-the-model-due-to-runtimeerror,5,2,5,,2020-06-19T09:08:00.985Z,2020-06-25T16:21:41.468Z,True,2020-06-25T16:21:41.468Z,regular,False,False,,,True,False,False,,,92,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 10401, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
86606,Printing Quantized Model Weights,Printing Quantized Model Weights,printing-quantized-model-weights,2,0,2,,2020-06-23T19:36:47.166Z,2020-06-24T23:34:34.290Z,True,2020-06-24T23:34:34.290Z,regular,False,False,,,True,False,False,,,159,0,False,hx89,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 32700, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 23504, 'primary_group_id': None}]"
86530,Can quantized model be exported and used?,Can quantized model be exported and used?,can-quantized-model-be-exported-and-used,4,2,4,,2020-06-23T09:37:13.922Z,2020-06-24T19:33:45.583Z,True,2020-06-24T19:33:45.583Z,regular,False,False,,,True,False,False,,,105,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 2864, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
82402,What do [De]QuantStub actually do?,What do [De]QuantStub actually do?,what-do-de-quantstub-actually-do,4,1,4,,2020-05-22T00:44:56.738Z,2020-06-23T16:55:39.045Z,True,2020-06-23T16:55:39.045Z,regular,False,False,,,True,False,False,,,429,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 30735, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
86347,Types of layers for Quantization,Types of layers for Quantization,types-of-layers-for-quantization,3,0,3,,2020-06-22T05:21:28.014Z,2020-06-23T16:32:23.998Z,True,2020-06-23T16:32:23.998Z,regular,False,False,,,True,False,False,,,82,1,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 2864, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 3534, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
85986,Is there an alternative to do batched matrix multiplication on Quantized Tensors?,Is there an alternative to do batched matrix multiplication on Quantized Tensors?,is-there-an-alternative-to-do-batched-matrix-multiplication-on-quantized-tensors,5,2,5,,2020-06-18T22:50:13.121Z,2020-06-23T16:13:34.770Z,True,2020-06-23T16:13:34.770Z,regular,False,False,,,True,False,False,,,122,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 33242, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
85477,What is the need of fusing layers in MobileNetv2?,What is the need of fusing layers in MobileNetv2?,what-is-the-need-of-fusing-layers-in-mobilenetv2,4,2,4,,2020-06-15T05:39:13.040Z,2020-06-23T16:11:30.022Z,True,2020-06-23T16:11:30.022Z,regular,False,False,,,True,False,False,,,112,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 29062, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
86358,Bilinear is slower than nearest after QAT,Bilinear is slower than nearest after QAT,bilinear-is-slower-than-nearest-after-qat,3,1,3,,2020-06-22T08:00:24.902Z,2020-06-22T11:21:24.323Z,True,2020-06-22T11:21:24.323Z,regular,False,False,,,True,False,False,,,74,1,False,KevinZ1992,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 27588, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 12783, 'primary_group_id': None}]"
74056,MobileNetV2 + SSDLite quantization results in different model definition,MobileNetV2 + SSDLite quantization results in different model definition,mobilenetv2-ssdlite-quantization-results-in-different-model-definition,10,6,10,https://discuss.pytorch.org/uploads/default/optimized/3X/0/c/0cf5b7d3f5e8543782a0a7373cd25084b4d8c502_2_1024x650.jpeg,2020-03-22T18:16:27.184Z,2020-06-20T07:42:26.476Z,True,2020-06-20T07:42:26.476Z,regular,False,False,,,True,False,False,,,352,2,False,FabianSchuetze,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 20920, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 19099, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 32246, 'primary_group_id': None}]"
85720,Dose static quantization support CUDA?,Dose static quantization support CUDA?,dose-static-quantization-support-cuda,3,1,3,,2020-06-17T03:05:34.316Z,2020-06-20T01:45:16.586Z,True,2020-06-20T01:45:16.586Z,regular,False,False,,,True,False,False,,,90,0,False,uni1,17,False,,True,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 33154, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}]"
85928,Did pytorch support int16 quantization?,Did pytorch support int16 quantization?,did-pytorch-support-int16-quantization,2,0,2,,2020-06-18T13:08:08.398Z,2020-06-19T21:33:22.823Z,True,2020-06-19T21:33:22.823Z,regular,False,False,,,True,False,False,,,88,1,False,supriyar,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 10883, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 24320, 'primary_group_id': None}]"
63964,"Pytorch1.3 Quantization for resnet50, accuracy is zero after fused_modules","Pytorch1.3 Quantization for resnet50, accuracy is zero after fused_modules",pytorch1-3-quantization-for-resnet50-accuracy-is-zero-after-fused-modules,8,6,8,,2019-12-13T11:31:08.169Z,2020-06-18T16:44:15.628Z,True,2020-06-18T16:44:15.628Z,regular,False,False,,,True,False,False,,,330,4,False,Tiru_B,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 25528, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23263, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31166, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 33196, 'primary_group_id': None}]"
85735,'aten::slow_conv_transpose2d' not support in 'QuantizedCPUTensorID',&lsquo;aten::slow_conv_transpose2d&rsquo; not support in &lsquo;QuantizedCPUTensorID&rsquo;,aten-slow-conv-transpose2d-not-support-in-quantizedcputensorid,3,0,3,,2020-06-17T04:54:18.226Z,2020-06-18T01:24:38.346Z,True,2020-06-18T01:24:38.346Z,regular,False,False,,,True,False,False,,,157,3,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 10590, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 33196, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
85133,Pytorch1.5.0/win7 64bit/ Didn't find engine for operation quantized::conv2d_prepack NoQEngine,Pytorch1.5.0/win7 64bit/ Didn&rsquo;t find engine for operation quantized::conv2d_prepack NoQEngine,pytorch1-5-0-win7-64bit-didnt-find-engine-for-operation-quantized-conv2d-prepack-noqengine,3,0,3,,2020-06-12T02:25:13.160Z,2020-06-17T03:12:21.871Z,True,2020-06-17T03:12:21.871Z,regular,False,False,,,True,False,False,,,124,0,False,peterjc123,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 10590, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 4802, 'primary_group_id': None}]"
67457,Issue with Quantization,Issue with Quantization,issue-with-quantization,3,0,3,,2020-01-23T10:53:39.689Z,2020-06-16T16:22:10.609Z,True,2020-06-16T16:22:10.609Z,regular,False,False,,,True,False,False,,,485,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 14538, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 32868, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
85494,Bug in QAT for classification?,Bug in QAT for classification?,bug-in-qat-for-classification,3,2,4,,2020-06-15T09:37:18.904Z,2020-06-16T09:04:08.716Z,True,2020-06-16T09:04:08.716Z,regular,False,False,,,True,False,False,,,81,0,False,xieydd,17,False,,False,"[{'extras': 'latest single', 'description': 'Original Poster, Most Recent Poster', 'user_id': 32868, 'primary_group_id': None}]"
85469,Dynamic + Post-training static quantization at the same time,Dynamic + Post-training static quantization at the same time,dynamic-post-training-static-quantization-at-the-same-time,2,0,2,,2020-06-15T01:02:11.556Z,2020-06-16T00:37:10.345Z,True,2020-06-16T00:37:10.345Z,regular,False,False,,,True,False,False,,,73,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 32563, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
84901,Error in QAT evaluate,Error in QAT evaluate,error-in-qat-evaluate,11,9,12,,2020-06-10T12:21:35.850Z,2020-06-15T02:08:59.208Z,True,2020-06-15T02:08:59.208Z,regular,False,False,,,True,False,False,,,204,1,False,xieydd,17,False,,True,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 32868, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31938, 'primary_group_id': None}]"
85329,Post-Training Static Quantization for Last FC layer gets rubbish results,Post-Training Static Quantization for Last FC layer gets rubbish results,post-training-static-quantization-for-last-fc-layer-gets-rubbish-results,1,0,1,,2020-06-13T12:17:36.680Z,2020-06-13T12:17:36.740Z,True,2020-06-13T12:17:36.740Z,regular,False,False,,,True,False,False,,,64,0,False,juanmanpr,17,False,,False,"[{'extras': 'latest single', 'description': 'Original Poster, Most Recent Poster', 'user_id': 4114, 'primary_group_id': None}]"
85078,How to quantize torch.zeros_like(x)?,How to quantize torch.zeros_like(x)?,how-to-quantize-torch-zeros-like-x,2,0,2,,2020-06-11T16:05:51.556Z,2020-06-11T16:25:08.718Z,True,2020-06-11T16:25:08.718Z,regular,False,False,,,True,False,False,,,128,0,False,juanmanpr,17,False,,False,"[{'extras': 'latest single', 'description': 'Original Poster, Most Recent Poster', 'user_id': 4114, 'primary_group_id': None}]"
84653,How to deploy quantized model to C++ frontend?,How to deploy quantized model to C++ frontend?,how-to-deploy-quantized-model-to-c-frontend,2,0,2,,2020-06-08T14:07:06.171Z,2020-06-10T16:56:48.362Z,True,2020-06-10T16:56:48.362Z,regular,False,False,,,True,False,False,,,81,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 30816, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
84840,Backpropagation gets slower in mixprecision,Backpropagation gets slower in mixprecision,backpropagation-gets-slower-in-mixprecision,2,0,2,https://discuss.pytorch.org/uploads/default/optimized/3X/a/4/a4eee5c5737235a1add66e5c006949d76b789071_2_1024x686.png,2020-06-10T05:21:57.756Z,2020-06-10T09:04:41.448Z,True,2020-06-10T09:04:41.448Z,regular,False,False,,,True,False,False,,,64,0,False,ptrblck,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 30681, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 3534, 'primary_group_id': None}]"
80954,"Post Quantizing conv1d, PReLU & layerNorm layers can be done?","Post Quantizing conv1d, PReLU &amp; layerNorm layers can be done?",post-quantizing-conv1d-prelu-layernorm-layers-can-be-done,18,14,18,,2020-05-13T03:15:31.034Z,2020-06-09T02:00:08.678Z,True,2020-06-09T02:00:08.678Z,regular,False,False,,,True,False,False,,,466,1,False,BOLLOJU_ARAVIND,17,False,,True,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 31501, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}]"
84515,What is the use of fused modules in quantization?,What is the use of fused modules in quantization?,what-is-the-use-of-fused-modules-in-quantization,2,0,2,,2020-06-07T11:48:09.455Z,2020-06-07T15:48:11.386Z,True,2020-06-07T15:48:11.386Z,regular,False,False,,,True,False,False,,,103,0,False,chetan_patil,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 29062, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 30439, 'primary_group_id': None}]"
80652,Question about quantization tutorial and fusing model,Question about quantization tutorial and fusing model,question-about-quantization-tutorial-and-fusing-model,6,3,6,,2020-05-11T07:36:15.266Z,2020-06-07T12:04:34.696Z,True,2020-06-07T12:04:34.696Z,regular,False,False,,,True,False,False,,,298,5,False,Midhilesh,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 31412, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23504, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 29062, 'primary_group_id': None}]"
84431,Dynamic quantization error: Mixed serialization of script and non-script modules is not supported,Dynamic quantization error: Mixed serialization of script and non-script modules is not supported,dynamic-quantization-error-mixed-serialization-of-script-and-non-script-modules-is-not-supported,2,0,2,,2020-06-06T14:56:52.549Z,2020-06-07T08:17:11.133Z,True,2020-06-07T08:17:11.133Z,regular,False,False,,,True,False,False,,,144,0,False,huoge,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 32676, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 23372, 'primary_group_id': None}]"
84144,"Tied ""conv1d"" and ""conv_transpose1d"" not geting the same result as the input",Tied &ldquo;conv1d&rdquo; and &ldquo;conv_transpose1d&rdquo; not geting the same result as the input,tied-conv1d-and-conv-transpose1d-not-geting-the-same-result-as-the-input,3,0,3,,2020-06-04T07:43:10.470Z,2020-06-04T09:21:21.125Z,True,2020-06-04T09:30:50.199Z,regular,False,False,,,True,False,False,,,68,0,False,111324,17,False,,True,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 32212, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 3534, 'primary_group_id': None}]"
83916,No performance improvement using quantization model in pytorch,No performance improvement using quantization model in pytorch,no-performance-improvement-using-quantization-model-in-pytorch,3,0,3,,2020-06-02T17:38:59.173Z,2020-06-03T03:13:38.987Z,True,2020-06-03T03:13:38.987Z,regular,False,False,,,True,False,False,,,139,0,False,BOLLOJU_ARAVIND,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 32547, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 30735, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 31501, 'primary_group_id': None}]"
83732,Accessing accumulated quantized result,Accessing accumulated quantized result,accessing-accumulated-quantized-result,2,0,2,,2020-06-01T15:51:50.988Z,2020-06-02T03:30:14.714Z,True,2020-06-02T03:30:14.714Z,regular,False,False,,,True,False,False,,,60,0,False,supriyar,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 32485, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 24320, 'primary_group_id': None}]"
83314,Quantized MaxPool2d and AdaptiveAvgPool2d,Quantized MaxPool2d and AdaptiveAvgPool2d,quantized-maxpool2d-and-adaptiveavgpool2d,2,0,2,,2020-05-29T04:10:38.268Z,2020-05-29T22:07:36.787Z,True,2020-05-29T22:07:36.787Z,regular,False,False,,,True,False,False,,,114,3,False,raghuramank100,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 31412, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 23263, 'primary_group_id': None}]"
82950,Problem about training with int8,Problem about training with int8,problem-about-training-with-int8,3,0,3,,2020-05-26T10:44:28.757Z,2020-05-28T12:51:32.869Z,True,2020-05-28T12:58:37.093Z,regular,False,False,,,True,False,False,,,182,2,False,Forwil_Yu,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 32043, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23504, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 32309, 'primary_group_id': None}]"
82566,The expanded size of the tensor must match the existing size at non-singleton dimension,The expanded size of the tensor must match the existing size at non-singleton dimension,the-expanded-size-of-the-tensor-must-match-the-existing-size-at-non-singleton-dimension,3,1,3,,2020-05-23T05:31:29.020Z,2020-05-25T04:47:32.309Z,True,2020-05-25T04:47:32.309Z,regular,False,False,,,True,False,False,,,151,0,False,ngap_wei_Tham,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 2727, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 3534, 'primary_group_id': None}]"
80343,Expending PyTorch with lower than 8-bit Quantization,Expending PyTorch with lower than 8-bit Quantization,expending-pytorch-with-lower-than-8-bit-quantization,10,8,10,,2020-05-08T15:11:40.327Z,2020-05-21T17:20:46.336Z,True,2020-05-21T17:20:46.336Z,regular,False,False,,,True,False,False,,,277,1,False,lijunzh,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 9340, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}]"
82043,Loading a dynamically quantized Transformers model,Loading a dynamically quantized Transformers model,loading-a-dynamically-quantized-transformers-model,4,2,4,,2020-05-19T19:54:49.015Z,2020-05-21T03:46:58.189Z,True,2020-05-21T03:46:58.189Z,regular,False,False,,,True,False,False,,,143,0,False,Pramodith,17,False,,True,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 6321, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}]"
80707,"RuntimeError: Could not run 'aten::thnn_conv2d_forward' with arguments from the 'QuantizedCPUTensorId' backend. 'aten::thnn_conv2d_forward' is only available for these backends: [CPUTensorId, VariableTensorId]","RuntimeError: Could not run &lsquo;aten::thnn_conv2d_forward&rsquo; with arguments from the &lsquo;QuantizedCPUTensorId&rsquo; backend. &lsquo;aten::thnn_conv2d_forward&rsquo; is only available for these backends: [CPUTensorId, VariableTensorId]",runtimeerror-could-not-run-aten-thnn-conv2d-forward-with-arguments-from-the-quantizedcputensorid-backend-aten-thnn-conv2d-forward-is-only-available-for-these-backends-cputensorid-variabletensorid,10,6,10,,2020-05-11T13:56:31.029Z,2020-05-20T18:00:53.599Z,True,2020-05-20T18:00:53.599Z,regular,False,False,,,True,False,False,,,699,0,False,supriyar,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 19968, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23504, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 31501, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 24320, 'primary_group_id': None}]"
81227,Purpose of scale and zero point for layer,Purpose of scale and zero point for layer,purpose-of-scale-and-zero-point-for-layer,4,2,4,,2020-05-14T15:47:27.631Z,2020-05-20T16:29:25.900Z,True,2020-05-20T16:29:25.900Z,regular,False,False,,,True,False,False,,,147,1,False,supriyar,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 27222, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 24320, 'primary_group_id': None}]"
82188,Quantization with custom weights in nn.Conv2d(),Quantization with custom weights in nn.Conv2d(),quantization-with-custom-weights-in-nn-conv2d,3,1,3,,2020-05-20T14:12:36.899Z,2020-05-20T15:09:21.719Z,True,2020-05-20T15:09:21.719Z,regular,False,False,,,True,False,False,,,141,0,False,louis,17,False,,True,"[{'extras': 'latest single', 'description': 'Original Poster, Most Recent Poster', 'user_id': 19373, 'primary_group_id': None}]"
80274,Quantized Conv2d bug,Quantized Conv2d bug,quantized-conv2d-bug,13,10,13,,2020-05-08T03:11:04.195Z,2020-05-18T02:16:47.106Z,True,2020-05-18T02:16:47.106Z,regular,False,False,,,True,False,False,,,358,0,False,elvindp,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 31287, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 19099, 'primary_group_id': None}]"
80576,Internal mutex in C++ quantized backend,Internal mutex in C++ quantized backend,internal-mutex-in-c-quantized-backend,6,3,6,,2020-05-10T14:41:40.917Z,2020-05-14T18:02:45.973Z,True,2020-05-14T18:02:45.973Z,regular,False,False,,,True,False,False,,,121,0,False,dskhudia,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 26737, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23504, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 19099, 'primary_group_id': None}]"
81173,How to fuse layers of any convolutional neural network?,How to fuse layers of any convolutional neural network?,how-to-fuse-layers-of-any-convolutional-neural-network,1,0,1,,2020-05-14T10:03:50.615Z,2020-05-14T10:03:50.673Z,True,2020-05-14T10:03:50.673Z,regular,False,False,,,True,False,False,,,114,0,False,studML,17,False,,False,"[{'extras': 'latest single', 'description': 'Original Poster, Most Recent Poster', 'user_id': 31166, 'primary_group_id': None}]"
77978,Fuse ConvBnReLU model error,Fuse ConvBnReLU model error,fuse-convbnrelu-model-error,3,1,3,,2020-04-23T05:25:56.169Z,2020-05-13T15:15:06.445Z,True,2020-05-13T15:15:06.445Z,regular,False,False,,,True,False,False,,,276,0,False,Yozey,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 20864, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23263, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 996, 'primary_group_id': None}]"
72137,Prepare_qat on module removes hooks,Prepare_qat on module removes hooks,prepare-qat-on-module-removes-hooks,13,11,13,,2020-03-05T12:06:53.595Z,2020-05-12T21:56:50.378Z,True,2020-05-12T21:56:50.378Z,regular,False,False,,,True,False,False,,,351,0,False,zetyquickly,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 23886, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}]"
80338,Construct quantized Tensor from int_repr(),Construct quantized Tensor from int_repr(),construct-quantized-tensor-from-int-repr,3,1,3,,2020-05-08T14:47:15.759Z,2020-05-08T18:06:12.465Z,True,2020-05-08T18:06:12.465Z,regular,False,False,,,True,False,False,,,97,1,False,jerryzh168,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 3418, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
79759,Sub-8 bit quantization,Sub-8 bit quantization,sub-8-bit-quantization,2,0,2,,2020-05-05T00:47:32.563Z,2020-05-08T18:03:07.878Z,True,2020-05-08T18:03:07.878Z,regular,False,False,,,True,False,False,,,105,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 31093, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
78505,"During QAT, how to save the float32 model without fuse module?","During QAT, how to save the float32 model without fuse module?",during-qat-how-to-save-the-float32-model-without-fuse-module,4,2,4,,2020-04-26T11:56:50.508Z,2020-05-08T17:58:29.651Z,True,2020-05-08T17:58:29.651Z,regular,False,False,,,True,False,False,,,133,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 30418, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
69512,Casting from 32b to 8 bit after accumulation in a multiplication,Casting from 32b to 8 bit after accumulation in a multiplication,casting-from-32b-to-8-bit-after-accumulation-in-a-multiplication,5,2,5,,2020-02-12T17:10:30.365Z,2020-04-29T02:56:43.081Z,True,2020-04-29T02:56:43.081Z,regular,False,False,,,True,False,False,,,200,1,False,onesnow123q,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 27222, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24263, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 30418, 'primary_group_id': None}]"
74839,Quantize activations with qinit8,Quantize activations with qinit8,quantize-activations-with-qinit8,6,4,6,,2020-03-30T20:26:47.738Z,2020-04-28T21:41:20.430Z,True,2020-04-28T21:41:20.430Z,regular,False,False,,,True,False,False,,,284,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 27041, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23504, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 30418, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
78268,How to static quantization? I have some questions after reading the tutorial,How to static quantization? I have some questions after reading the tutorial,how-to-static-quantization-i-have-some-questions-after-reading-the-tutorial,3,1,3,,2020-04-24T18:55:12.013Z,2020-04-25T09:31:26.023Z,True,2020-04-25T09:31:26.023Z,regular,False,False,,,True,False,False,,,194,0,False,Silbernitrat,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 29287, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23263, 'primary_group_id': None}]"
78009,Net in DataParallel make training aware quantization convert model acc error,Net in DataParallel make training aware quantization convert model acc error,net-in-dataparallel-make-training-aware-quantization-convert-model-acc-error,3,1,3,,2020-04-23T08:48:33.769Z,2020-04-24T01:18:55.213Z,True,2020-04-24T01:18:55.213Z,regular,False,False,,,True,False,False,,,111,0,False,dingyongchao,17,False,,True,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 20864, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}]"
77872,Per tensor symmetric quantiation,Per tensor symmetric quantiation,per-tensor-symmetric-quantiation,2,0,2,https://discuss.pytorch.org/uploads/default/original/3X/8/d/8d47912ed94e09a02158837b17bf1e28d38918a7.png,2020-04-22T14:13:30.290Z,2020-04-22T17:41:29.155Z,True,2020-04-22T17:41:29.155Z,regular,False,False,,,True,False,False,,,118,0,False,dskhudia,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 30429, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 19099, 'primary_group_id': None}]"
77122,Changing quant_max and quant_min doesn't have any effect,Changing quant_max and quant_min doesn&rsquo;t have any effect,changing-quant-max-and-quant-min-doesnt-have-any-effect,3,0,3,,2020-04-17T00:46:18.927Z,2020-04-18T01:40:11.553Z,True,2020-04-18T01:40:11.553Z,regular,False,False,,,True,False,False,,,88,0,False,raghuramank100,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 29603, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 23263, 'primary_group_id': None}]"
76528,[quantization] how to quantize model which include not support to quantize layer,[quantization] how to quantize model which include not support to quantize layer,quantization-how-to-quantize-model-which-include-not-support-to-quantize-layer,2,0,2,,2020-04-13T08:38:25.932Z,2020-04-17T20:43:38.251Z,True,2020-04-17T20:43:38.251Z,regular,False,False,,,True,False,False,,,521,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 29932, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
70605,How to use a quantized model on INT8 harware?,How to use a quantized model on INT8 harware?,how-to-use-a-quantized-model-on-int8-harware,12,11,13,,2020-02-21T16:07:13.728Z,2020-04-17T20:41:34.656Z,True,2020-04-17T20:41:34.656Z,regular,False,False,,,True,False,False,,,276,4,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 26539, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23504, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 27222, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23263, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
76671,QAT: evaluation during training,QAT: evaluation during training,qat-evaluation-during-training,2,0,2,,2020-04-14T02:15:08.042Z,2020-04-14T16:14:08.373Z,True,2020-04-14T16:14:08.373Z,regular,False,False,,,True,False,False,,,90,0,False,supriyar,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 29603, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 24320, 'primary_group_id': None}]"
75642,Quantization for conv models with custom modules,Quantization for conv models with custom modules,quantization-for-conv-models-with-custom-modules,2,0,2,,2020-04-07T03:16:25.849Z,2020-04-10T18:54:30.276Z,True,2020-04-10T18:54:30.276Z,regular,False,False,,,True,False,False,,,106,0,False,dskhudia,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 29622, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 19099, 'primary_group_id': None}]"
75805,How to see the quantized weights?,How to see the quantized weights?,how-to-see-the-quantized-weights,2,0,2,,2020-04-08T06:42:44.537Z,2020-04-10T18:51:58.424Z,True,2020-04-10T18:51:58.424Z,regular,False,False,,,True,False,False,,,158,0,False,dskhudia,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 29677, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 19099, 'primary_group_id': None}]"
75937,"Quantization-aware training conv1D, LSTM support","Quantization-aware training conv1D, LSTM support",quantization-aware-training-conv1d-lstm-support,3,1,3,,2020-04-09T00:11:59.855Z,2020-04-09T23:55:44.490Z,True,2020-04-09T23:55:44.490Z,regular,False,False,,,True,False,False,,,161,0,False,dskhudia,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 28630, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 19099, 'primary_group_id': None}]"
74224,Linear_dynamic has some problems with qnnpack,Linear_dynamic has some problems with qnnpack,linear-dynamic-has-some-problems-with-qnnpack,4,1,4,https://discuss.pytorch.org/uploads/default/optimized/3X/f/1/f19d7843b03616ae933ed2835f9d3e0a6ce1f2e5_2_1024x158.png,2020-03-24T11:52:10.215Z,2020-03-30T06:47:27.397Z,True,2020-03-30T06:47:27.397Z,regular,False,False,,,True,False,False,,,132,1,False,huoge,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 23372, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}]"
73720,Error when QAT with Dataparallel in multi-GPU,Error when QAT with Dataparallel in multi-GPU,error-when-qat-with-dataparallel-in-multi-gpu,7,3,7,,2020-03-19T07:32:33.917Z,2020-03-29T12:22:59.150Z,True,2020-03-29T12:22:59.150Z,regular,False,False,,,True,False,False,,,306,0,False,eleflea,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 29060, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24320, 'primary_group_id': None}]"
66698,Quantization of Transformer models in Fairseq,Quantization of Transformer models in Fairseq,quantization-of-transformer-models-in-fairseq,3,1,3,,2020-01-15T03:32:15.829Z,2020-03-26T04:28:47.772Z,True,2020-03-26T04:28:47.772Z,regular,False,False,,,True,False,False,,,358,0,False,gvskalyan,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 3904, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 10296, 'primary_group_id': None}]"
68016,Quantization support for 1D convolutions?,Quantization support for 1D convolutions?,quantization-support-for-1d-convolutions,4,1,4,,2020-01-29T12:31:07.735Z,2020-03-23T22:45:23.409Z,True,2020-03-23T22:45:23.409Z,regular,False,False,,,True,False,False,,,179,1,False,dskhudia,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 9815, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 19099, 'primary_group_id': None}]"
64868,How to write scale and zero_point to fp32 tensor without doing quantization?,How to write scale and zero_point to fp32 tensor without doing quantization?,how-to-write-scale-and-zero-point-to-fp32-tensor-without-doing-quantization,6,3,6,,2019-12-24T05:57:32.602Z,2020-03-19T21:03:35.650Z,True,2020-03-19T21:03:35.650Z,regular,False,False,,,True,False,False,,,289,0,False,jerryzh168,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23516, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 19099, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 18122, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
73737,RuntimeError: Didn't find engine for operation quantized::conv2d_prepack NoQEngine (operator() at /pytorch/aten/src/ATen/native/quantized/cpu/qconv_prepack.cpp:63),RuntimeError: Didn&rsquo;t find engine for operation quantized::conv2d_prepack NoQEngine (operator() at /pytorch/aten/src/ATen/native/quantized/cpu/qconv_prepack.cpp:63),runtimeerror-didnt-find-engine-for-operation-quantized-conv2d-prepack-noqengine-operator-at-pytorch-aten-src-aten-native-quantized-cpu-qconv-prepack-cpp-63,2,0,2,,2020-03-19T09:26:28.994Z,2020-03-19T20:59:16.354Z,True,2020-03-19T20:59:16.354Z,regular,False,False,,,True,False,False,,,303,1,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 20140, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
72149,How to quantize only specific layers,How to quantize only specific layers,how-to-quantize-only-specific-layers,2,0,2,,2020-03-05T14:14:10.592Z,2020-03-19T20:56:35.513Z,True,2020-03-19T20:56:35.513Z,regular,False,False,,,True,False,False,,,144,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 27629, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
71579,"I try to run quantizitzed model ,but some error happend","I try to run quantizitzed model ,but some error happend",i-try-to-run-quantizitzed-model-but-some-error-happend,14,8,14,,2020-03-01T02:27:56.955Z,2020-03-19T20:55:10.159Z,True,2020-03-19T20:55:10.159Z,regular,False,False,,,True,False,False,,,405,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 28249, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23263, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 27459, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 18122, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
72089,RuntimeError: Python builtin <built-in method apply of FunctionMeta object at 0x55dad1b31680> is currently not supported in Torchscript:,RuntimeError: Python builtin &lt;built-in method apply of FunctionMeta object at 0x55dad1b31680&gt; is currently not supported in Torchscript:,runtimeerror-python-builtin-built-in-method-apply-of-functionmeta-object-at-0x55dad1b31680-is-currently-not-supported-in-torchscript,3,1,3,,2020-03-05T02:58:37.633Z,2020-03-15T13:51:56.917Z,True,2020-03-15T13:51:56.917Z,regular,False,False,,,True,False,False,,,151,0,False,JachinMa,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 20140, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 211, 'primary_group_id': None}]"
71950,Will Pytorch support exporting quantized model?,Will Pytorch support exporting quantized model?,will-pytorch-support-exporting-quantized-model,3,0,3,https://discuss.pytorch.org/uploads/default/original/3X/c/9/c9bf81dc06953ec7635d4f1409bd945425c8bf9b.png,2020-03-04T06:45:58.013Z,2020-03-10T20:44:31.516Z,True,2020-03-10T20:44:31.516Z,regular,False,False,,,True,False,False,,,314,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 10180, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
64188,How do I save and load quantization model,How do I save and load quantization model,how-do-i-save-and-load-quantization-model,6,4,6,,2019-12-16T09:13:00.674Z,2020-03-09T09:21:21.465Z,True,2020-03-09T09:21:21.465Z,regular,False,False,,,True,False,False,,,1057,2,False,wolffadam,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 25528, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 18122, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 28642, 'primary_group_id': None}]"
72288,Pytorch model quantization for mobile device,Pytorch model quantization for mobile device,pytorch-model-quantization-for-mobile-device,2,0,2,,2020-03-06T13:15:28.433Z,2020-03-06T22:08:28.910Z,True,2020-03-06T22:08:28.910Z,regular,False,False,,,True,False,False,,,108,0,False,hx89,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 24200, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 23504, 'primary_group_id': None}]"
71047,Help needed: Specific function call causing 20X slowdown of computation,Help needed: Specific function call causing 20X slowdown of computation,help-needed-specific-function-call-causing-20x-slowdown-of-computation,4,1,4,,2020-02-25T20:18:49.296Z,2020-03-03T22:33:17.127Z,True,2020-03-03T22:33:17.127Z,regular,False,False,,,True,False,False,,,89,0,False,Zafar,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 28116, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 19099, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 18122, 'primary_group_id': None}]"
71688,Supported quantized tensor operations,Supported quantized tensor operations,supported-quantized-tensor-operations,3,0,3,,2020-03-02T08:22:37.361Z,2020-03-03T22:20:00.029Z,True,2020-03-03T22:20:00.029Z,regular,False,False,,,True,False,False,,,581,3,False,Zafar,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 28238, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 18122, 'primary_group_id': None}]"
71430,When I run a quantiztized model error happened,When I run a quantiztized model error happened,when-i-run-a-quantiztized-model-error-happened,3,0,3,,2020-02-28T12:13:53.613Z,2020-03-03T22:15:10.255Z,True,2020-03-03T22:15:10.255Z,regular,False,False,,,True,False,False,,,238,0,False,Zafar,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 28249, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 18122, 'primary_group_id': None}]"
67862,The parameters saved in the checkpoint are different from the ones in the fused model,The parameters saved in the checkpoint are different from the ones in the fused model,the-parameters-saved-in-the-checkpoint-are-different-from-the-ones-in-the-fused-model,6,3,6,,2020-01-28T05:35:14.412Z,2020-03-03T04:01:46.805Z,True,2020-03-03T04:01:46.805Z,regular,False,False,,,True,False,False,,,288,1,False,Shisho_Sama,17,False,,True,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 7863, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}]"
67456,How to extract individual weights after per channel static quantization?,How to extract individual weights after per channel static quantization?,how-to-extract-individual-weights-after-per-channel-static-quantization,2,0,2,,2020-01-23T10:47:24.356Z,2020-02-26T13:16:34.412Z,True,2020-02-26T13:16:34.412Z,regular,False,False,,,True,False,False,,,342,1,False,babak_hss,17,False,,True,"[{'extras': 'latest single', 'description': 'Original Poster, Most Recent Poster', 'user_id': 26539, 'primary_group_id': None}]"
69830,[caffe2] Post train quantization,[caffe2] Post train quantization,caffe2-post-train-quantization,2,0,2,,2020-02-15T13:59:25.353Z,2020-02-24T23:18:16.979Z,True,2020-02-24T23:18:16.979Z,regular,False,False,,,True,False,False,,,99,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23886, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
69977,Not able to load quantized model in android,Not able to load quantized model in android,not-able-to-load-quantized-model-in-android,2,0,2,,2020-02-17T00:09:38.719Z,2020-02-24T23:17:08.667Z,True,2020-02-24T23:17:08.667Z,regular,False,False,,,True,False,False,,,213,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 27725, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
66905,Current status of automatic quantization support,Current status of automatic quantization support,current-status-of-automatic-quantization-support,7,2,7,,2020-01-16T21:31:57.554Z,2020-02-21T05:23:15.912Z,True,2020-02-21T05:23:15.912Z,regular,False,False,,,True,False,False,,,293,7,False,jerryzh168,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 26617, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23263, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
68631,Decrease in the Speed of Quantization Model,Decrease in the Speed of Quantization Model,decrease-in-the-speed-of-quantization-model,4,1,4,,2020-02-04T12:11:19.502Z,2020-02-20T04:14:12.432Z,True,2020-02-20T04:14:12.432Z,regular,False,False,,,True,False,False,,,189,0,False,masahi,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 24354, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 26617, 'primary_group_id': None}]"
70211,Conv2d_unpack and conv2d_prepack behavior,Conv2d_unpack and conv2d_prepack behavior,conv2d-unpack-and-conv2d-prepack-behavior,2,0,2,,2020-02-18T17:54:32.517Z,2020-02-18T19:14:40.559Z,True,2020-02-18T19:14:40.559Z,regular,False,False,,,True,False,False,,,250,3,False,dskhudia,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 27459, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 19099, 'primary_group_id': None}]"
68717,Quantized::cat running time is slower than fp32 model,Quantized::cat running time is slower than fp32 model,quantized-cat-running-time-is-slower-than-fp32-model,4,0,4,,2020-02-05T08:48:25.156Z,2020-02-17T21:36:11.694Z,True,2020-02-17T21:36:11.694Z,regular,False,False,,,True,False,False,,,378,0,False,masahi,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 27255, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24102, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 26617, 'primary_group_id': None}]"
68096,RuntimeError: Unimplemented backend QuantizedCPU,RuntimeError: Unimplemented backend QuantizedCPU,runtimeerror-unimplemented-backend-quantizedcpu,2,0,2,,2020-01-30T07:45:12.181Z,2020-02-14T22:21:17.628Z,True,2020-02-14T22:21:17.628Z,regular,False,False,,,True,False,False,,,209,1,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 14538, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
68203,AssertionError: torch.nn.quantized.ReLU does not support inplace,AssertionError: torch.nn.quantized.ReLU does not support inplace,assertionerror-torch-nn-quantized-relu-does-not-support-inplace,2,0,2,,2020-01-31T07:14:54.719Z,2020-02-14T19:26:19.283Z,True,2020-02-14T19:26:19.283Z,regular,False,False,,,True,False,False,,,155,1,False,jerryzh168,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 14538, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
68491,Quantized convolution and NHWC layout,Quantized convolution and NHWC layout,quantized-convolution-and-nhwc-layout,3,0,3,,2020-02-03T10:13:51.200Z,2020-02-14T19:25:07.751Z,True,2020-02-14T19:25:07.751Z,regular,False,False,,,True,False,False,,,232,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 26617, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23504, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
59113,RuntimeError: No function is registered for schema aten::thnn_conv2d_forward,RuntimeError: No function is registered for schema aten::thnn_conv2d_forward,runtimeerror-no-function-is-registered-for-schema-aten-thnn-conv2d-forward,9,4,9,https://discuss.pytorch.org/uploads/default/original/3X/3/d/3d425393bb6b39623f6fc2dd5d023c06de8d067a.png,2019-10-24T10:05:32.659Z,2020-02-14T18:50:27.972Z,True,2020-02-14T18:50:27.972Z,regular,False,False,,,True,False,False,,,697,1,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23602, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 25649, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 18488, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
67734,When quantized::max_pool2d is used?,When quantized::max_pool2d is used?,when-quantized-max-pool2d-is-used,2,0,2,,2020-01-26T23:10:35.306Z,2020-02-14T18:48:32.893Z,True,2020-02-14T18:48:32.893Z,regular,False,False,,,True,False,False,,,137,1,False,jerryzh168,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 26617, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
58995,AssertionError: min nan should be less than max nan,AssertionError: min nan should be less than max nan,assertionerror-min-nan-should-be-less-than-max-nan,4,0,5,,2019-10-23T07:23:39.379Z,2020-02-14T18:33:29.574Z,True,2020-02-14T18:33:29.574Z,regular,False,False,,,True,False,False,,,415,1,False,jerryzh168,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23602, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 3534, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 27266, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
67334,Pretrained quantized models' export to ONNX fails,Pretrained quantized models&rsquo; export to ONNX fails,pretrained-quantized-models-export-to-onnx-fails,5,0,6,,2020-01-22T05:07:53.444Z,2020-02-13T20:32:51.950Z,True,2020-02-13T20:32:51.950Z,regular,False,False,,,True,False,False,,,523,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 26765, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 9785, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 27459, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
68630,8 bit quantization - modulo 256 inside convolutions?,8 bit quantization - modulo 256 inside convolutions?,8-bit-quantization-modulo-256-inside-convolutions,1,0,1,https://discuss.pytorch.org/uploads/default/optimized/3X/b/b/bb1f9949fb550514f0ebd0c462a125e5147a71b5_2_768x1024.jpeg,2020-02-04T11:56:55.927Z,2020-02-04T11:56:55.987Z,True,2020-02-05T09:58:51.257Z,regular,False,False,,,True,False,False,,,126,0,False,dassima,17,False,,False,"[{'extras': 'latest single', 'description': 'Original Poster, Most Recent Poster', 'user_id': 27222, 'primary_group_id': None}]"
68333,Creat a tensor with random number of 1 and -1,Creat a tensor with random number of 1 and -1,creat-a-tensor-with-random-number-of-1-and-1,3,1,4,,2020-02-01T11:29:24.121Z,2020-02-01T13:08:34.355Z,True,2020-02-01T13:08:34.355Z,regular,False,False,,,True,False,False,,,84,1,False,mingren200323,17,False,,True,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 27116, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 4340, 'primary_group_id': None}]"
63578,How does PyTorch implement Quantization?,How does PyTorch implement Quantization?,how-does-pytorch-implement-quantization,11,8,11,,2019-12-10T06:14:36.364Z,2020-02-01T04:54:14.838Z,True,2020-02-01T07:27:28.267Z,regular,False,False,,,True,False,False,,,899,2,False,remya,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23907, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 19099, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 18488, 'primary_group_id': None}]"
60770,Best way to quantize Transformer architecture,Best way to quantize Transformer architecture,best-way-to-quantize-transformer-architecture,3,0,3,,2019-11-12T17:54:05.754Z,2020-01-28T14:17:05.990Z,True,2020-01-28T14:17:05.990Z,regular,False,False,,,True,False,False,,,367,1,False,snakers41,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 9119, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24578, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 9815, 'primary_group_id': None}]"
66413,Can't load model after dynamic quantization,Can&rsquo;t load model after dynamic quantization,cant-load-model-after-dynamic-quantization,7,1,7,,2020-01-11T22:50:55.903Z,2020-01-23T15:20:48.322Z,True,2020-01-23T15:20:48.322Z,regular,False,False,,,True,False,False,,,434,0,False,JeffO,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 26432, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 3534, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 19099, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 26498, 'primary_group_id': None}]"
67295,Exception: must run observer before calling calculate_qparams!,Exception: must run observer before calling calculate_qparams!,exception-must-run-observer-before-calling-calculate-qparams,2,1,2,,2020-01-21T18:09:17.098Z,2020-01-21T23:00:27.523Z,True,2020-01-21T23:00:27.523Z,regular,False,False,,,True,False,False,,,268,0,False,hx89,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 25536, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 23504, 'primary_group_id': None}]"
66722,Cannot quantize nn.Conv2d with dynamic Quantization,Cannot quantize nn.Conv2d with dynamic Quantization,cannot-quantize-nn-conv2d-with-dynamic-quantization,2,0,2,,2020-01-15T10:04:59.231Z,2020-01-17T18:23:54.200Z,True,2020-01-17T18:23:54.200Z,regular,False,False,,,True,False,False,,,359,2,False,raghuramank100,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 26539, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 23263, 'primary_group_id': None}]"
65872,How to set quantization aware training scaling factors?,How to set quantization aware training scaling factors?,how-to-set-quantization-aware-training-scaling-factors,3,0,3,,2020-01-06T05:58:48.554Z,2020-01-13T19:57:37.059Z,True,2020-01-13T19:57:37.059Z,regular,False,False,,,True,False,False,,,177,0,False,dskhudia,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 26250, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 10229, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 19099, 'primary_group_id': None}]"
63804,No module named 'torchvision.models.quantization',No module named &lsquo;torchvision.models.quantization&rsquo;,no-module-named-torchvision-models-quantization,5,2,5,,2019-12-12T02:09:52.797Z,2019-12-19T04:26:02.256Z,True,2019-12-19T04:26:02.256Z,regular,False,False,,,True,False,False,,,795,0,False,raghuramank100,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 18345, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24578, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 23263, 'primary_group_id': None}]"
64231,Object detection quantization,Object detection quantization,object-detection-quantization,2,0,2,,2019-12-16T15:44:28.938Z,2019-12-18T00:18:11.658Z,True,2019-12-18T00:18:11.658Z,regular,False,False,,,True,False,False,,,1244,1,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 19388, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
63931,Steps to Create Quantized Model,Steps to Create Quantized Model,steps-to-create-quantized-model,4,2,4,,2019-12-13T05:56:22.555Z,2019-12-16T19:47:02.441Z,True,2019-12-16T19:47:02.441Z,regular,False,False,,,True,False,False,,,653,0,False,raghuramank100,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 24354, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 23263, 'primary_group_id': None}]"
63613,Generic static quantization,Generic static quantization,generic-static-quantization,5,2,5,,2019-12-10T10:21:31.333Z,2019-12-14T00:44:02.682Z,True,2019-12-14T00:44:02.682Z,regular,False,False,,,True,False,False,,,344,0,False,dskhudia,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 25397, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23263, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 19099, 'primary_group_id': None}]"
62729,Quantized Squeeze block MobilenetV3,Quantized Squeeze block MobilenetV3,quantized-squeeze-block-mobilenetv3,3,1,3,,2019-12-02T09:47:11.410Z,2019-12-04T05:57:05.685Z,True,2019-12-04T05:57:05.685Z,regular,False,False,,,True,False,False,,,341,0,False,thancaocuong,17,False,,True,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 24011, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24578, 'primary_group_id': None}]"
58539,Pytorch1.3 Quantization error in Resnet50,Pytorch1.3 Quantization error in Resnet50,pytorch1-3-quantization-error-in-resnet50,9,3,9,,2019-10-18T02:32:11.637Z,2019-12-02T18:06:55.135Z,True,2019-12-02T18:06:55.135Z,regular,False,False,,,True,False,False,,,1129,0,False,dskhudia,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 21520, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23504, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23711, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 19099, 'primary_group_id': None}]"
62324,How to difine self defined loss?,How to difine self defined loss?,how-to-difine-self-defined-loss,5,2,5,,2019-11-27T15:33:44.358Z,2019-11-27T20:02:40.564Z,True,2019-11-27T20:02:40.564Z,regular,False,False,,,True,False,False,,,141,0,False,lzh21cen,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 19763, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 18088, 'primary_group_id': None}]"
58894,"Quantization aware training, extremely slow on GPU","Quantization aware training, extremely slow on GPU",quantization-aware-training-extremely-slow-on-gpu,9,3,9,,2019-10-22T09:42:59.287Z,2019-11-27T06:40:51.493Z,True,2019-11-27T06:47:11.499Z,regular,False,False,,,True,False,False,,,1246,2,False,hx89,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 4735, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 3534, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24295, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23263, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 23504, 'primary_group_id': None}]"
60840,Scalar operation observers,Scalar operation observers,scalar-operation-observers,4,1,4,,2019-11-13T10:18:29.380Z,2019-11-23T02:15:26.042Z,True,2019-11-23T02:15:26.042Z,regular,False,False,,,True,False,False,,,166,0,False,lly-zero-one,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23653, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 24578, 'primary_group_id': None}]"
60547,Per Tensor/Channel quantization equivalents in PyTorch/Caffe2,Per Tensor/Channel quantization equivalents in PyTorch/Caffe2,per-tensor-channel-quantization-equivalents-in-pytorch-caffe2,2,0,2,,2019-11-10T16:05:24.024Z,2019-11-23T00:57:33.601Z,True,2019-11-23T00:57:33.601Z,regular,False,False,,,True,False,False,,,147,1,False,Jongsoo_Park,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 24198, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 24735, 'primary_group_id': None}]"
60542,Matrix quantization while training,Matrix quantization while training,matrix-quantization-while-training,2,0,2,,2019-11-10T14:50:15.182Z,2019-11-22T21:45:14.438Z,True,2019-11-22T21:45:14.438Z,regular,False,False,,,True,False,False,,,101,0,False,raghuramank100,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 20442, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 23263, 'primary_group_id': None}]"
61727,Static quantization error,Static quantization error,static-quantization-error,2,0,2,,2019-11-21T11:36:59.700Z,2019-11-22T06:58:25.419Z,True,2019-11-22T06:58:25.419Z,regular,False,False,,,True,False,False,,,305,1,False,lly-zero-one,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 24667, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 24578, 'primary_group_id': None}]"
60878,ConvBnReLU quantized performance,ConvBnReLU quantized performance,convbnrelu-quantized-performance,5,2,5,https://discuss.pytorch.org/uploads/default/original/3X/f/2/f2ba1128ddba148bcdad381aad25b6a9db1eb19c.png,2019-11-13T16:56:25.970Z,2019-11-19T22:28:43.590Z,True,2019-11-19T22:28:43.590Z,regular,False,False,,,True,False,False,,,504,0,False,Dorozhko-Anton,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 24198, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 24578, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 19099, 'primary_group_id': None}]"
60557,Quantized Conv2d gives different result from the Caffe2's Int8Conv with the same weights,Quantized Conv2d gives different result from the Caffe2&rsquo;s Int8Conv with the same weights,quantized-conv2d-gives-different-result-from-the-caffe2s-int8conv-with-the-same-weights,7,3,7,,2019-11-10T20:36:57.508Z,2019-11-13T10:15:33.367Z,True,2019-11-13T11:15:20.407Z,regular,False,False,,,True,False,False,,,476,1,False,Dorozhko-Anton,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 24198, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23263, 'primary_group_id': None}]"
60119,Test_adaptive_avg_pool2d_nhwc deadline in test_quantized.py,Test_adaptive_avg_pool2d_nhwc deadline in test_quantized.py,test-adaptive-avg-pool2d-nhwc-deadline-in-test-quantized-py,3,0,3,,2019-11-05T23:44:49.560Z,2019-11-06T17:04:58.883Z,True,2019-11-06T17:04:58.883Z,regular,False,False,,,True,False,False,,,117,0,False,dncliss,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 19581, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 616, 'primary_group_id': None}]"
60000,Very Bad Bounding Boxes After Quantization of Model,Very Bad Bounding Boxes After Quantization of Model,very-bad-bounding-boxes-after-quantization-of-model,4,1,4,https://discuss.pytorch.org/uploads/default/original/3X/c/7/c751371bae97b455047d1077fe8f926bcb825a51.jpeg,2019-11-04T23:38:05.104Z,2019-11-05T22:20:14.386Z,True,2019-11-05T22:20:14.386Z,regular,False,False,,,True,False,False,,,218,0,False,hx89,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23738, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 22867, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 23504, 'primary_group_id': None}]"
59519,"RuntimeError: No function is registered for schema aten::thnn_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor?","RuntimeError: No function is registered for schema aten::thnn_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor?",runtimeerror-no-function-is-registered-for-schema-aten-thnn-conv2d-forward-tensor-self-tensor-weight-int-2-kernel-size-tensor,5,2,5,,2019-10-29T23:29:09.108Z,2019-11-05T18:10:21.088Z,True,2019-11-05T18:10:21.088Z,regular,False,False,,,True,False,False,,,1286,2,False,banikr,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23738, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 16765, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 19088, 'primary_group_id': None}]"
59622,Static quantization returning torch.float32 parameters,Static quantization returning torch.float32 parameters,static-quantization-returning-torch-float32-parameters,4,0,4,,2019-10-30T22:09:09.450Z,2019-11-01T14:58:16.773Z,True,2019-11-01T19:03:10.187Z,regular,False,False,,,True,False,False,,,309,0,False,Paulo_Mann,17,False,,False,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 14285, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23263, 'primary_group_id': None}]"
59114,"RuntimeError: lhs of assignment must be a variable, subscript, or starred expression:","RuntimeError: lhs of assignment must be a variable, subscript, or starred expression:",runtimeerror-lhs-of-assignment-must-be-a-variable-subscript-or-starred-expression,5,3,5,https://discuss.pytorch.org/uploads/default/optimized/3X/6/0/6017a36f06a889f59a605d49f9d243a32b53c5dc_2_1024x555.png,2019-10-24T11:16:38.067Z,2019-11-01T18:07:10.252Z,True,2019-11-01T18:07:10.252Z,regular,False,False,,,True,False,False,,,286,6,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23602, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 211, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
58880,[Quantization] (Error): No function is registered for schema aten,[Quantization] (Error): No function is registered for schema aten,quantization-error-no-function-is-registered-for-schema-aten,4,2,5,,2019-10-22T07:16:49.241Z,2019-11-01T18:05:34.449Z,True,2019-11-01T18:05:34.449Z,regular,False,False,,,True,False,False,,,713,1,False,jerryzh168,17,False,,True,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23602, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 19099, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23738, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
59527,Quantize conv layer with bias,Quantize conv layer with bias,quantize-conv-layer-with-bias,2,0,2,,2019-10-30T01:58:45.061Z,2019-10-31T00:01:55.267Z,True,2019-10-31T00:01:55.267Z,regular,False,False,,,True,False,False,,,272,0,False,raghuramank100,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23836, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 23263, 'primary_group_id': None}]"
59021,Error when converting quantization aware trained model for evaluation,Error when converting quantization aware trained model for evaluation,error-when-converting-quantization-aware-trained-model-for-evaluation,5,2,5,,2019-10-23T11:57:55.928Z,2019-10-28T17:58:18.731Z,True,2019-10-28T17:58:18.731Z,regular,False,False,,,True,False,False,,,490,1,False,Zafar,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 4735, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 18122, 'primary_group_id': None}]"
58766,Where is the Dataset and model file,Where is the Dataset and model file,where-is-the-dataset-and-model-file,6,1,6,,2019-10-21T02:06:03.529Z,2019-10-27T04:54:12.034Z,True,2019-10-27T04:54:12.034Z,regular,False,False,,,True,False,False,,,217,1,False,Aspirinkb,17,False,,True,"[{'extras': 'latest', 'description': 'Original Poster, Most Recent Poster', 'user_id': 23562, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 19157, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 21770, 'primary_group_id': None}, {'extras': None, 'description': 'Frequent Poster', 'user_id': 23263, 'primary_group_id': None}]"
59013,Quantized hard sigmoid,Quantized hard sigmoid,quantized-hard-sigmoid,2,0,2,,2019-10-23T09:54:09.784Z,2019-10-23T16:56:24.579Z,True,2019-10-23T16:56:24.579Z,regular,False,False,,,True,False,False,,,743,0,False,jerryzh168,17,False,,False,"[{'extras': None, 'description': 'Original Poster', 'user_id': 23653, 'primary_group_id': None}, {'extras': 'latest', 'description': 'Most Recent Poster', 'user_id': 21770, 'primary_group_id': None}]"
