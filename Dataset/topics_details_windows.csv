id,title,created_at,reply_count,views,description,creator_link,creator_name,creator_alias,post_date,post_likes,replies,repliers_links,reply_dates,reply_likes
89244,About the windows category,2020-07-15T03:07:16.244Z,0,54,"<div class=""post"" itemprop=""articleBody""><NewLine><p>This category is focused on PyTorch on Windows related issues.</p><NewLine></div>",https://discuss.pytorch.org/u/jspisak,"(Facebook AI, Product Manager)",jspisak,"July 15, 2020,  3:08am",3 Likes,,,,
91351,Problems after installing pytorch on windows,2020-08-02T03:36:25.716Z,1,936,"<div class=""post"" itemprop=""articleBody""><NewLine><p>I have installed pytorch in a conda environment using</p><NewLine><pre><code class=""lang-auto"">conda install pytorch torchvision cudatoolkit=10.1 -c pytorch<NewLine></code></pre><NewLine><p>However after that I try doing <code>import torch</code><br/><NewLine>and I get the following error</p><NewLine><pre><code class=""lang-auto"">Microsoft Visual C++ Redistributable is not installed, this may lead to the DLL load failure.  <NewLine>It can be downloaded at https://aka.ms/vs/16/release/vc_redist.x64.exe                                 <NewLine>Traceback (most recent call last):                                                                                       <NewLine> File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;                                                                                     <NewLine>File ""C:\Users\aliag\anaconda3\envs\pytorchPractice\lib\site-packages\torch\__init__.py"", line 127, in &lt;module&gt;           <NewLine>raise err                                                                                                           <NewLine>OSError: [WinError 126] 指定されたモジュールが見つかりません。 <NewLine>Error loading ""C:\Users\aliag\anaconda3\envs\pytorchPractice\lib\site-packages\torch\lib\asmjit.dll"" <NewLine>or one of its dependencies.                                                 <NewLine>&gt;&gt;&gt; <NewLine></code></pre><NewLine><p>I would really appreciate some help to correct this problem</p><NewLine></div>",https://discuss.pytorch.org/u/KansaiUser,(David Aliaga),KansaiUser,"August 2, 2020,  3:36am",,"REPLY 1: <div class=""post"" itemprop=""articleBody""><NewLine><p>I found the solution. I had not adequately installed CUDA. When I did it again, the problem dissapears</p><NewLine></div>; <NewLine> REPLY 2: <div class=""post"" itemprop=""articleBody""><NewLine><p><a class=""mention"" href=""/u/kansaiuser"">@KansaiUser</a>, I’m having the same problem. Can you discuss in detail how you solved it?</p><NewLine></div>; <NewLine> REPLY 3: <div class=""post"" itemprop=""articleBody""><NewLine><p><em>Bumping this up</em></p><NewLine><p>Does anyone have a clear solution to this issue? I faced this when I updated from 1.5.0 to 1.6.0 and soon after that doing a fresh install in a new environment. I already have a couple of versions of Visual C++ Redistributable installed (2013 and 2017).</p><NewLine></div>; <NewLine> REPLY 4: <div class=""post"" itemprop=""articleBody""><NewLine><p>Answering my own question: the situation was set right when I installed the Redistributable that’s linked in the error message. However, I don’t understand why the existing ones didn’t work. Also, if this is an requirement that’s not available as part of a conda repository, why is this not mentioned as part of the installation steps?</p><NewLine></div>; <NewLine> ",REPLIER 1: https://discuss.pytorch.org/u/KansaiUser; <NewLine> REPLIER 2: https://discuss.pytorch.org/u/Prithvi_Shankar; <NewLine> REPLIER 3: https://discuss.pytorch.org/u/navneethc; <NewLine> REPLIER 4: https://discuss.pytorch.org/u/navneethc; <NewLine> ,"REPLY_DATE 1: August 3, 2020,  1:27am; <NewLine> REPLY_DATE 2: August 21, 2020, 11:37pm; <NewLine> REPLY_DATE 3: September 26, 2020,  3:30pm; <NewLine> REPLY_DATE 4: September 26, 2020,  5:43pm; <NewLine> ",REPLY 1 LIKES: ; <NewLine> REPLY 2 LIKES: ; <NewLine> REPLY 3 LIKES: ; <NewLine> REPLY 4 LIKES: ; <NewLine> 
95120,WSL cuda not detected,2020-09-04T02:29:58.281Z,0,55,"<div class=""post"" itemprop=""articleBody""><NewLine><p>wsl 4.19.121<br/><NewLine>ubuntu 18.04<br/><NewLine>cuda-toolkit 11.0<br/><NewLine>nvidia driver: 460.15<br/><NewLine>Pytorch: 1.6.0<br/><NewLine>Python: 3.6.8</p><NewLine><p>I’ve followed the steps in this tutorial<br/><NewLine><a class=""onebox"" href=""https://docs.nvidia.com/cuda/wsl-user-guide/index.html"" rel=""nofollow noopener"" target=""_blank"">https://docs.nvidia.com/cuda/wsl-user-guide/index.html</a></p><NewLine><p>But when I run pytorch  <code>torch.cuda.is_available()</code> , it returns False.</p><NewLine></div>",https://discuss.pytorch.org/u/acmilannesta,,acmilannesta,"September 4, 2020,  2:29am",,,,,
94976,Install problem: pytorch 1.2.0 with Cuda 10.2,2020-09-02T22:15:18.067Z,1,43,"<div class=""post"" itemprop=""articleBody""><NewLine><p>Hi,</p><NewLine><p>I’m trying to run code from the following github repository: <a href=""https://github.com/AnticipatedLearningMachine/Anticipated-Learning-Machine"" rel=""nofollow noopener"">https://github.com/AnticipatedLearningMachine/Anticipated-Learning-Machine</a></p><NewLine><p>In the requirements section at the bottom, it says that pytorch 1.2.0 and CUDA 10.2 are required. I have tried installing pytorch 1.2.0 (on Windows Anaconda) via pip, but I get a version that comes with Cuda 9.2. Can someone please help me install pytorch 1.2.0 with CUDA 10.2?</p><NewLine><p>Thanks,<br/><NewLine>Gavin.</p><NewLine></div>",https://discuss.pytorch.org/u/xen,,xen,"September 2, 2020, 10:18pm",,"REPLY 1: <div class=""post"" itemprop=""articleBody""><NewLine><p>I don’t think that the PyTorch <code>1.2.0</code> binaries and wheels were built with CUDA10.2, but with CUDA9.2 and CUDA10.0 as seen <a href=""https://pytorch.org/get-started/previous-versions/#v120"">here</a>.<br/><NewLine>If you need this config for a particular reason, you would most likely have to build PyTorch from source.</p><NewLine></div>; <NewLine> REPLY 2: <div class=""post"" itemprop=""articleBody""><NewLine><p>Great, thank you.</p><NewLine><p>Gavin.</p><NewLine></div>; <NewLine> ",REPLIER 1: https://discuss.pytorch.org/u/ptrblck; <NewLine> REPLIER 2: https://discuss.pytorch.org/u/xen; <NewLine> ,"REPLY_DATE 1: September 2, 2020, 11:02pm; <NewLine> REPLY_DATE 2: September 2, 2020, 11:04pm; <NewLine> ",REPLY 1 LIKES: ; <NewLine> REPLY 2 LIKES: ; <NewLine> 
93243,I cannot use the pytorch that was built successfully from source: (DLL) initialization routine failed. Error loading caffe2_detectron_ops_gpu.dll,2020-08-18T15:03:26.566Z,12,250,"<div class=""post"" itemprop=""articleBody""><NewLine><p>I cannot post more than two links here as a beginner, and which was definitely needed. That is why the whole issue is at <a href=""https://github.com/pytorch/pytorch/issues/43210"" rel=""nofollow noopener"">https://github.com/pytorch/pytorch/issues/43210</a> but shall be answered here.</p><NewLine></div>",https://discuss.pytorch.org/u/lorenzznerol,,lorenzznerol,"August 18, 2020,  3:03pm",,"REPLY 1: <div class=""post"" itemprop=""articleBody""><NewLine><p>The error is caused by our poor support for MSVC OpenMP in detectron. Please build with MKL so Intel OpenMP will be used. See <a href=""https://pytorch.org/docs/stable/notes/windows.html#include-optional-components"" rel=""nofollow noopener"">https://pytorch.org/docs/stable/notes/windows.html#include-optional-components</a>.</p><NewLine></div>; <NewLine> REPLY 2: <div class=""post"" itemprop=""articleBody""><NewLine><p>As for (23), please open a new issue at the corresponding repo. It is not related to PyTorch.</p><NewLine></div>; <NewLine> REPLY 3: <div class=""post"" itemprop=""articleBody""><NewLine><p>I was not sure which point you meant with 23, since I had 2 things in that (my fault). I have changed that, could you please write again which number should be a new issue: the lost packages (23) or the new issue with dtaidistance (now 24)?</p><NewLine></div>; <NewLine> REPLY 4: <div class=""post"" itemprop=""articleBody""><NewLine><p><a class=""mention"" href=""/u/peterjc123"">@peterjc123</a><br/><NewLine>I do not get along with your suggested link. Why do I have to install mkl like that, if I can simply install it with conda?</p><NewLine><p>It seems to be better to follow <a href=""https://github.com/pytorch/pytorch#from-source"" rel=""nofollow noopener"">https://github.com/pytorch/pytorch#from-source</a> and use the dependency installer there (and where mkl is included anyway?):</p><NewLine><pre><code>conda install numpy ninja pyyaml mkl mkl-include setuptools cmake cffi typing_extensions future six requests<NewLine></code></pre><NewLine><p>####</p><NewLine><p>Aside from that, there is a mistake in your stated link.</p><NewLine><blockquote><NewLine><p>REM Download MKL files</p><NewLine><pre><code class=""lang-auto"">curl https://s3.amazonaws.com/ossci-windows/mkl_2020.0.166.7z -k -O<NewLine>7z x -aoa mkl_2018.2.185.7z -omkl<NewLine></code></pre><NewLine></blockquote><NewLine><p>It works with<br/><NewLine><code>7z x -aoa mkl_2020.0.166.7z -omkl</code><br/><NewLine>since that is what the curl command is downloading as a 7z.</p><NewLine><p>Anyway, I have now succeeded in using the two commands, having now <code>C:\Users\Admin\mkl</code> with the necessary files in it, but I do not need the directory at all, since I can simply install mkl with conda, see above.</p><NewLine><p>####</p><NewLine><p>I do not know now how to install from source with MKL. Looking at your link, under <a href=""https://pytorch.org/docs/stable/notes/windows.html#installation"" rel=""nofollow noopener"">https://pytorch.org/docs/stable/notes/windows.html#installation</a>, I find:</p><NewLine><pre><code class=""lang-auto"">conda install -c peterjc123 vc vs2017_runtime<NewLine>conda install mkl_fft intel_openmp numpy mkl<NewLine></code></pre><NewLine><p>But that does not seem to help me, first, I have vs2019, then I want to install pytorch with mkl, and I find a wide range of commands that do not seem to help.</p><NewLine><p>Because <code>pip install intel-openmp</code> does not work, I use from your link:</p><NewLine><pre><code>conda install -c defaults intel-openmp -f<NewLine></code></pre><NewLine><p>Which seems to be needed for installing pytorch with mkl, as you say: “Please build with MKL so Intel OpenMP will be used.”</p><NewLine><p>Please give me a hint what I shall do next to get pytorch built with MKL, thank you.</p><NewLine></div>; <NewLine> REPLY 5: <div class=""post"" itemprop=""articleBody""><NewLine><aside class=""quote no-group"" data-post=""5"" data-topic=""93243"" data-username=""lorenzznerol""><NewLine><div class=""title""><NewLine><div class=""quote-controls""></div><NewLine><img alt="""" class=""avatar"" height=""20"" src=""https://discuss.pytorch.org/letter_avatar_proxy/v4/letter/l/ecccb3/40.png"" width=""20""/> lorenzznerol:</div><NewLine><blockquote><NewLine><p>I do not get along with your suggested link. Why do I have to install mkl like that, if I can simply install it with conda?</p><NewLine></blockquote><NewLine></aside><NewLine><p>The conda one is a runtime package, not a source package.</p><NewLine><aside class=""quote no-group"" data-post=""5"" data-topic=""93243"" data-username=""lorenzznerol""><NewLine><div class=""title""><NewLine><div class=""quote-controls""></div><NewLine><img alt="""" class=""avatar"" height=""20"" src=""https://discuss.pytorch.org/letter_avatar_proxy/v4/letter/l/ecccb3/40.png"" width=""20""/> lorenzznerol:</div><NewLine><blockquote><NewLine><p>Aside from that, there is a mistake in your stated link.</p><NewLine></blockquote><NewLine></aside><NewLine><p>Will fix.</p><NewLine><aside class=""quote no-group"" data-post=""5"" data-topic=""93243"" data-username=""lorenzznerol""><NewLine><div class=""title""><NewLine><div class=""quote-controls""></div><NewLine><img alt="""" class=""avatar"" height=""20"" src=""https://discuss.pytorch.org/letter_avatar_proxy/v4/letter/l/ecccb3/40.png"" width=""20""/> lorenzznerol:</div><NewLine><blockquote><NewLine><p>I do not know now how to install from source with MKL.</p><NewLine></blockquote><NewLine></aside><NewLine><pre><code class=""lang-auto"">## Just after doing `curl`<NewLine>set ""CMAKE_INCLUDE_PATH=%cd%\\mkl\\include""<NewLine>set ""LIB=%cd%\\mkl\\lib;%LIB%""<NewLine></code></pre><NewLine><aside class=""quote no-group"" data-post=""4"" data-topic=""93243"" data-username=""lorenzznerol""><NewLine><div class=""title""><NewLine><div class=""quote-controls""></div><NewLine><img alt="""" class=""avatar"" height=""20"" src=""https://discuss.pytorch.org/letter_avatar_proxy/v4/letter/l/ecccb3/40.png"" width=""20""/> lorenzznerol:</div><NewLine><blockquote><NewLine><p>I was not sure which point you meant with 23</p><NewLine></blockquote><NewLine></aside><NewLine><p>I mean the dtaidistance one.</p><NewLine></div>; <NewLine> REPLY 6: <div class=""post"" itemprop=""articleBody""><NewLine><p>Now I get the error:</p><NewLine><blockquote><NewLine><p>DistutilsPlatformError: Microsoft Visual C++ 14.0 is required. Get it with “Build Tools for Visual Studio”</p><NewLine></blockquote><NewLine><p>Although “MSVC v142 – VS 2019 C+±x64/x86-Buildtools” is already installed:</p><NewLine><p><div class=""lightbox-wrapper""><a class=""lightbox"" data-download-href=""https://discuss.pytorch.org/uploads/default/7100a860dfceddd1d0c61dbcc87843da9b23257a"" href=""https://discuss.pytorch.org/uploads/default/original/3X/7/1/7100a860dfceddd1d0c61dbcc87843da9b23257a.png"" title=""image""><img alt=""image"" data-base62-sha1=""g7FmwFlMEvzDXh3Ms6cBPu30z58"" data-small-upload=""https://discuss.pytorch.org/uploads/default/optimized/3X/7/1/7100a860dfceddd1d0c61dbcc87843da9b23257a_2_10x10.png"" height=""370"" src=""https://discuss.pytorch.org/uploads/default/optimized/3X/7/1/7100a860dfceddd1d0c61dbcc87843da9b23257a_2_690x370.png"" srcset=""https://discuss.pytorch.org/uploads/default/optimized/3X/7/1/7100a860dfceddd1d0c61dbcc87843da9b23257a_2_690x370.png, https://discuss.pytorch.org/uploads/default/optimized/3X/7/1/7100a860dfceddd1d0c61dbcc87843da9b23257a_2_1035x555.png 1.5x, https://discuss.pytorch.org/uploads/default/original/3X/7/1/7100a860dfceddd1d0c61dbcc87843da9b23257a.png 2x"" width=""690""/><div class=""meta""><svg aria-hidden=""true"" class=""fa d-icon d-icon-far-image svg-icon""><use xlink:href=""#far-image""></use></svg><span class=""filename"">image</span><span class=""informations"">1270×682 68 KB</span><svg aria-hidden=""true"" class=""fa d-icon d-icon-discourse-expand svg-icon""><use xlink:href=""#discourse-expand""></use></svg></div></a></div></p><NewLine><pre><code class=""lang-auto"">(dl) C:\Users\Admin\Downloads\Pytorch\pytorch&gt;set ""CMAKE_INCLUDE_PATH=C:\Users\Admin\Downloads\Pytorch\mkl\include""<NewLine><NewLine>(dl) C:\Users\Admin\Downloads\Pytorch\pytorch&gt;set ""LIB=C:\Users\Admin\Downloads\Pytorch\mkl\lib;%LIB%""<NewLine><NewLine>(dl) C:\Users\Admin\Downloads\Pytorch\pytorch&gt;set CMAKE_GENERATOR=Ninja<NewLine><NewLine>(dl) C:\Users\Admin\Downloads\Pytorch\pytorch&gt;python setup.py install --cmake<NewLine>Building wheel torch-1.7.0a0+d4c5f56<NewLine>-- Building version 1.7.0a0+d4c5f56<NewLine>Traceback (most recent call last):<NewLine>  File ""C:\Users\Admin\anaconda3\envs\dl\lib\site-packages\setuptools\msvc.py"", line 273, in _msvc14_get_vc_env<NewLine>    out = subprocess.check_output(<NewLine>  File ""C:\Users\Admin\anaconda3\envs\dl\lib\subprocess.py"", line 411, in check_output<NewLine>    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,<NewLine>  File ""C:\Users\Admin\anaconda3\envs\dl\lib\subprocess.py"", line 512, in run<NewLine>    raise CalledProcessError(retcode, process.args,<NewLine>subprocess.CalledProcessError: Command 'cmd /u /c ""C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Auxiliary\Build\vcvarsall.bat"" x64 &amp;&amp; set' returned non-zero exit status 255.<NewLine><NewLine>The above exception was the direct cause of the following exception:<NewLine><NewLine>Traceback (most recent call last):<NewLine>  File ""setup.py"", line 737, in &lt;module&gt;<NewLine>    build_deps()<NewLine>  File ""setup.py"", line 316, in build_deps<NewLine>    build_caffe2(version=version,<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\build_pytorch_libs.py"", line 52, in build_caffe2<NewLine>    my_env = _create_build_env()<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\build_pytorch_libs.py"", line 45, in _create_build_env<NewLine>    my_env = _overlay_windows_vcvars(my_env)<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\build_pytorch_libs.py"", line 14, in _overlay_windows_vcvars<NewLine>    vc_env = _get_vc_env(vc_arch)<NewLine>  File ""C:\Users\Admin\anaconda3\envs\dl\lib\site-packages\setuptools\msvc.py"", line 314, in msvc14_get_vc_env<NewLine>    return _msvc14_get_vc_env(plat_spec)<NewLine>  File ""C:\Users\Admin\anaconda3\envs\dl\lib\site-packages\setuptools\msvc.py"", line 278, in _msvc14_get_vc_env<NewLine>    raise distutils.errors.DistutilsPlatformError(<NewLine>distutils.errors.DistutilsPlatformError: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/<NewLine></code></pre><NewLine><p>Now I am running it with settings:</p><NewLine><pre><code class=""lang-auto"">set ""CMAKE_INCLUDE_PATH=C:\Users\Admin\Downloads\Pytorch\mkl\include""<NewLine>set ""LIB=C:\Users\Admin\Downloads\Pytorch\mkl\lib;%LIB%""<NewLine>set USE_NINJA=OFF<NewLine>set CMAKE_GENERATOR=Visual Studio 16 2019<NewLine></code></pre><NewLine><p>starting again with:</p><NewLine><p><code>(myenv) C:\Users\Admin\Downloads\Pytorch\pytorch&gt;python setup.py install --cmake</code></p><NewLine><p>starts with:</p><NewLine><pre><code class=""lang-auto"">(dl) C:\Users\Admin\Downloads\Pytorch\pytorch&gt;python setup.py install --cmake<NewLine>Building wheel torch-1.7.0a0+d4c5f56<NewLine>-- Building version 1.7.0a0+d4c5f56<NewLine>cmake -GVisual Studio 16 2019 -Ax64 -Thost=x64 -DBUILD_PYTHON=True -DBUILD_TEST=True -DCMAKE_BUILD_TYPE=Release -DCMAKE_GENERATOR=Visual Studio 16 2019 -DCMAKE_INCLUDE_PATH=C:\Users\Admin\Downloads\Pytorch\mkl\include -DCMAKE_INSTALL_PREFIX=C:\Users\Admin\Downloads\Pytorch\pytorch\torch -DCMAKE_PREFIX_PATH=C:\Users\Admin\anaconda3\envs\dl\Lib\site-packages -DJAVA_HOME=C:\Users\Admin\AppData\Local\Programs\AdoptOpenJDK\ -DNUMPY_INCLUDE_DIR=C:\Users\Admin\anaconda3\envs\dl\lib\site-packages\numpy\core\include -DPYTHON_EXECUTABLE=C:\Users\Admin\anaconda3\envs\dl\python.exe -DPYTHON_INCLUDE_DIR=C:\Users\Admin\anaconda3\envs\dl\include -DPYTHON_LIBRARY=C:\Users\Admin\anaconda3\envs\dl/libs/python38.lib -DTORCH_BUILD_VERSION=1.7.0a0+d4c5f56 -DUSE_NINJA=OFF -DUSE_NUMPY=True C:\Users\Admin\Downloads\Pytorch\pytorch<NewLine>-- The CXX compiler identification is MSVC 19.27.29111.0<NewLine>-- The C compiler identification is MSVC 19.27.29111.0<NewLine>-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.27.29110/bin/Hostx64/x64/cl.exe<NewLine>-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.27.29110/bin/Hostx64/x64/cl.exe - works<NewLine>-- Detecting CXX compiler ABI info<NewLine>-- Detecting CXX compiler ABI info - done<NewLine>-- Detecting CXX compile features<NewLine>-- Detecting CXX compile features - done<NewLine>-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.27.29110/bin/Hostx64/x64/cl.exe<NewLine>-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.27.29110/bin/Hostx64/x64/cl.exe - works<NewLine>-- Detecting C compiler ABI info<NewLine>-- Detecting C compiler ABI info - done<NewLine>-- Detecting C compile features<NewLine>-- Detecting C compile features - done<NewLine>-- Not forcing any particular BLAS to be found<NewLine>-- Performing Test COMPILER_WORKS<NewLine>-- Performing Test COMPILER_WORKS - Success<NewLine>-- Performing Test SUPPORT_GLIBCXX_USE_C99<NewLine>-- Performing Test SUPPORT_GLIBCXX_USE_C99 - Success<NewLine>-- Performing Test CAFFE2_EXCEPTION_PTR_SUPPORTED<NewLine>-- Performing Test CAFFE2_EXCEPTION_PTR_SUPPORTED - Success<NewLine>-- std::exception_ptr is supported.<NewLine>-- Performing Test CAFFE2_NEED_TO_TURN_OFF_DEPRECATION_WARNING<NewLine>-- Performing Test CAFFE2_NEED_TO_TURN_OFF_DEPRECATION_WARNING - Failed<NewLine>-- Performing Test CAFFE2_COMPILER_SUPPORTS_AVX2_EXTENSIONS<NewLine>-- Performing Test CAFFE2_COMPILER_SUPPORTS_AVX2_EXTENSIONS - Success<NewLine>-- Current compiler supports avx2 extension. Will build perfkernels.<NewLine>-- Performing Test CAFFE2_COMPILER_SUPPORTS_AVX512_EXTENSIONS<NewLine>-- Performing Test CAFFE2_COMPILER_SUPPORTS_AVX512_EXTENSIONS - Success<NewLine>-- Current compiler supports avx512f extension. Will build fbgemm.<NewLine>-- Performing Test COMPILER_SUPPORTS_HIDDEN_VISIBILITY<NewLine>-- Performing Test COMPILER_SUPPORTS_HIDDEN_VISIBILITY - Failed<NewLine>-- Performing Test COMPILER_SUPPORTS_HIDDEN_INLINE_VISIBILITY<NewLine>-- Performing Test COMPILER_SUPPORTS_HIDDEN_INLINE_VISIBILITY - Failed<NewLine>-- Performing Test COMPILER_SUPPORTS_RDYNAMIC<NewLine>-- Performing Test COMPILER_SUPPORTS_RDYNAMIC - Failed<NewLine>-- Building using own protobuf under third_party per request.<NewLine>-- Use custom protobuf build.<NewLine>--<NewLine>-- 3.11.4.0<NewLine>-- Looking for pthread.h<NewLine>-- Looking for pthread.h - not found<NewLine>-- Found Threads: TRUE<NewLine>-- Caffe2 protobuf include directory: $&lt;BUILD_INTERFACE:C:/Users/Admin/Downloads/Pytorch/pytorch/third_party/protobuf/src&gt;$&lt;INSTALL_INTERFACE:include&gt;<NewLine>-- Trying to find preferred BLAS backend of choice: MKL<NewLine>-- MKL_THREADING = OMP<NewLine>-- Looking for sys/types.h<NewLine>-- Looking for sys/types.h - found<NewLine>-- Looking for stdint.h<NewLine>-- Looking for stdint.h - found<NewLine>-- Looking for stddef.h<NewLine>-- Looking for stddef.h - found<NewLine>-- Check size of void*<NewLine>-- Check size of void* - done<NewLine>-- Looking for cblas_sgemm<NewLine>-- Looking for cblas_sgemm - found<NewLine>-- MKL libraries: C:/Users/Admin/Downloads/Pytorch/mkl/lib/mkl_intel_lp64.lib;C:/Users/Admin/Downloads/Pytorch/mkl/lib/mkl_intel_thread.lib;C:/Users/Admin/Downloads/Pytorch/mkl/lib/mkl_core.lib;C:/Users/Admin/Downloads/Pytorch/mkl/lib/libiomp5md.lib<NewLine>-- MKL include directory: C:/Users/Admin/Downloads/Pytorch/mkl/include<NewLine>-- MKL OpenMP type: Intel<NewLine>-- MKL OpenMP library: C:/Users/Admin/Downloads/Pytorch/mkl/lib/libiomp5md.lib<NewLine>CMake Warning at cmake/Dependencies.cmake:226 (message):<NewLine>  Target platform ""Windows"" is not supported in {Q/X}NNPACK.  Supported<NewLine>  platforms are Android, iOS, Linux, and macOS.  Turn this warning off by<NewLine>  USE_{Q/X}NNPACK=OFF.<NewLine>Call Stack (most recent call first):<NewLine>  CMakeLists.txt:472 (include)<NewLine></code></pre><NewLine><p>Almost at the bottom of the previous output we see that MKL is used. That shows me that can compile with the compiler <strong>MSVC</strong> <em>and</em> use <strong>MKL</strong> it seems. I hope that this is the way you asked me to use MKL.</p><NewLine><p>This run has now led to the same error as reported in an earlier post. It seems that I have to remove the <code>pytorch/caffe2/CMakeLists.txt</code> before start, here the error message:</p><NewLine><pre><code class=""lang-auto"">  Generating quantization/server/sigmoid_dnnlowp_op_test.py<NewLine>  Generating quantization/server/spatial_batch_norm_dnnlowp_op_test.py<NewLine>  Generating quantization/server/tanh_dnnlowp_op_test.py<NewLine>  Generating quantization/server/utils.py<NewLine>  Building Custom Rule C:/Users/Admin/Downloads/Pytorch/pytorch/caffe2/CMakeLists.txt<NewLine>Traceback (most recent call last):<NewLine>  File ""setup.py"", line 737, in &lt;module&gt;<NewLine>    build_deps()<NewLine>  File ""setup.py"", line 316, in build_deps<NewLine>    build_caffe2(version=version,<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\build_pytorch_libs.py"", line 62, in build_caffe2<NewLine>    cmake.build(my_env)<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\setup_helpers\cmake.py"", line 345, in build<NewLine>    self.run(build_args, my_env)<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\setup_helpers\cmake.py"", line 141, in run<NewLine>    check_call(command, cwd=self.build_dir, env=env)<NewLine>  File ""C:\Users\Admin\anaconda3\envs\dl\lib\subprocess.py"", line 364, in check_call<NewLine>    raise CalledProcessError(retcode, cmd)<NewLine>subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--target', 'install', '--config', 'Release', '--', '/p:CL_MPCount=4']' returned non-zero exit status 1.<NewLine></code></pre><NewLine><p>I let it run again after removing the <code>pytorch/caffe2/CMakeLists.txt</code>, which caused error:</p><NewLine><pre><code class=""lang-auto"">-- Configuring incomplete, errors occurred!<NewLine>See also ""C:/Users/Admin/Downloads/Pytorch/pytorch/build/CMakeFiles/CMakeOutput.log"".<NewLine>See also ""C:/Users/Admin/Downloads/Pytorch/pytorch/build/CMakeFiles/CMakeError.log"".<NewLine>Traceback (most recent call last):<NewLine>  File ""setup.py"", line 737, in &lt;module&gt;<NewLine>    build_deps()<NewLine>  File ""setup.py"", line 316, in build_deps<NewLine>    build_caffe2(version=version,<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\build_pytorch_libs.py"", line 54, in build_caffe2<NewLine>    cmake.generate(version,<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\setup_helpers\cmake.py"", line 329, in generate<NewLine>    self.run(args, env=my_env)<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\setup_helpers\cmake.py"", line 141, in run<NewLine>    check_call(command, cwd=self.build_dir, env=env)<NewLine>  File ""C:\Users\Admin\anaconda3\envs\dl\lib\subprocess.py"", line 364, in check_call<NewLine>    raise CalledProcessError(retcode, cmd)<NewLine>subprocess.CalledProcessError: Command '['cmake', '-GVisual Studio 16 2019', '-Ax64', '-Thost=x64', '-DBUILD_PYTHON=True', '-DBUILD_TEST=True', '-DCMAKE_BUILD_TYPE=Release', '-DCMAKE_GENERATOR=Visual Studio 16 2019', '-DCMAKE_INCLUDE_PATH=C:\\Users\\Admin\\Downloads\\Pytorch\\mkl\\include', '-DCMAKE_INSTALL_PREFIX=C:\\Users\\Admin\\Downloads\\Pytorch\\pytorch\\torch', '-DCMAKE_PREFIX_PATH=C:\\Users\\Admin\\anaconda3\\envs\\dl\\Lib\\site-packages', '-DJAVA_HOME=C:\\Users\\Admin\\AppData\\Local\\Programs\\AdoptOpenJDK\\', '-DNUMPY_INCLUDE_DIR=C:\\Users\\Admin\\anaconda3\\envs\\dl\\lib\\site-packages\\numpy\\core\\include', '-DPYTHON_EXECUTABLE=C:\\Users\\Admin\\anaconda3\\envs\\dl\\python.exe', '-DPYTHON_INCLUDE_DIR=C:\\Users\\Admin\\anaconda3\\envs\\dl\\include', '-DPYTHON_LIBRARY=C:\\Users\\Admin\\anaconda3\\envs\\dl/libs/python38.lib', '-DTORCH_BUILD_VERSION=1.7.0a0+d4c5f56', '-DUSE_NINJA=OFF', '-DUSE_NUMPY=True', 'C:\\Users\\Admin\\Downloads\\Pytorch\\pytorch']' returned non-zero exit status 1.<NewLine></code></pre><NewLine><p>Now I let it run without the directory <code>caffe2_builders</code> which I had added after the cloning from git only due to a probably outdated Youtube tutorial. The directory came from pytorch-scripts project, which is outdated. Let’s see.</p><NewLine><p>Result:</p><NewLine><pre><code class=""lang-auto"">LINK : fatal error LNK1356: Die zur vollständigen Archivierung angegebene Bibliothek ""\C:/Users/Admin/Downloads/Pytorch/pytorch/build/lib/Release/caffe2_protos.lib\.lib"" wurde nicht gefunden. [C:\Users\Admi<NewLine>n\Downloads\Pytorch\pytorch\build\caffe2\torch_cpu.vcxproj]<NewLine>Traceback (most recent call last):<NewLine>  File ""setup.py"", line 737, in &lt;module&gt;<NewLine>    build_deps()<NewLine>  File ""setup.py"", line 316, in build_deps<NewLine>    build_caffe2(version=version,<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\build_pytorch_libs.py"", line 62, in build_caffe2<NewLine>    cmake.build(my_env)<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\setup_helpers\cmake.py"", line 345, in build<NewLine>    self.run(build_args, my_env)<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\setup_helpers\cmake.py"", line 141, in run<NewLine>    check_call(command, cwd=self.build_dir, env=env)<NewLine>  File ""C:\Users\Admin\anaconda3\envs\dl\lib\subprocess.py"", line 364, in check_call<NewLine>    raise CalledProcessError(retcode, cmd)<NewLine>subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--target', 'install', '--config', 'Release', '--', '/p:CL_MPCount=4']' returned non-zero exit status 1.<NewLine></code></pre><NewLine><p>Run again with the directory caffe2_builders causes again the same error:</p><NewLine><pre><code class=""lang-auto"">LINK : fatal error LNK1356: Die zur vollständigen Archivierung angegebene Bibliothek ""\C:/Users/Admin/Downloads/Pytorch/pytorch/build/lib/Release/caffe2_protos.lib\.lib"" wurde nicht gefunden. [C:\Users\Admi<NewLine>n\Downloads\Pytorch\pytorch\build\caffe2\torch_cpu.vcxproj]<NewLine>Traceback (most recent call last):<NewLine>  File ""setup.py"", line 737, in &lt;module&gt;<NewLine>    build_deps()<NewLine>  File ""setup.py"", line 316, in build_deps<NewLine>    build_caffe2(version=version,<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\build_pytorch_libs.py"", line 62, in build_caffe2<NewLine>    cmake.build(my_env)<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\setup_helpers\cmake.py"", line 345, in build<NewLine>    self.run(build_args, my_env)<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\setup_helpers\cmake.py"", line 141, in run<NewLine>    check_call(command, cwd=self.build_dir, env=env)<NewLine>  File ""C:\Users\Admin\anaconda3\envs\dl\lib\subprocess.py"", line 364, in check_call<NewLine>    raise CalledProcessError(retcode, cmd)<NewLine>subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--target', 'install', '--config', 'Release', '--', '/p:CL_MPCount=4']' returned non-zero exit status 1.<NewLine></code></pre><NewLine><p>After this, I have done everything from the scratch again. Perhaps there were conflicts with the outdated Youtube approach that included files of the pytorch-scrypts project. It seems promising up to now, so perhaps there was simply a problem with the added outdated pytorch-scrypts files.</p><NewLine><pre><code class=""lang-auto"">(myenv) C:\Users\Admin\Downloads\Pytorch&gt;git clone https://github.com/pytorch/pytorch<NewLine>(myenv) C:\Users\Admin\Downloads\Pytorch\pytorch&gt;git submodule update --init --recursive<NewLine>(myenv) C:\Users\Admin\Downloads\Pytorch\pytorch&gt;set ""CMAKE_INCLUDE_PATH=C:\Users\Admin\Downloads\Pytorch\mkl\include""<NewLine>(myenv) C:\Users\Admin\Downloads\Pytorch\pytorch&gt;set ""LIB=C:\Users\Admin\Downloads\Pytorch\mkl\lib;%LIB%""<NewLine>(myenv) C:\Users\Admin\Downloads\Pytorch\pytorch&gt;set CMAKE_GENERATOR=Visual Studio 16 2019<NewLine>(myenv) C:\Users\Admin\Downloads\Pytorch\pytorch&gt;set USE_NINJA=OFF<NewLine>(myenv) C:\Users\Admin\Downloads\Pytorch\pytorch&gt;python setup.py install --cmake<NewLine></code></pre><NewLine><p>But I get the same error:</p><NewLine><pre><code class=""lang-auto"">  Building Custom Rule C:/Users/Admin/Downloads/Pytorch/pytorch/caffe2/CMakeLists.txt<NewLine>Traceback (most recent call last):<NewLine>  File ""setup.py"", line 737, in &lt;module&gt;<NewLine>    build_deps()<NewLine>  File ""setup.py"", line 316, in build_deps<NewLine>    build_caffe2(version=version,<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\build_pytorch_libs.py"", line 62, in build_caffe2<NewLine>    cmake.build(my_env)<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\setup_helpers\cmake.py"", line 345, in build<NewLine>    self.run(build_args, my_env)<NewLine>  File ""C:\Users\Admin\Downloads\Pytorch\pytorch\tools\setup_helpers\cmake.py"", line 141, in run<NewLine>    check_call(command, cwd=self.build_dir, env=env)<NewLine>  File ""C:\Users\Admin\anaconda3\envs\dl\lib\subprocess.py"", line 364, in check_call<NewLine>    raise CalledProcessError(retcode, cmd)<NewLine>subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--target', 'install', '--config', 'Release', '--', '/p:CL_MPCount=4']' returned non-zero exit status 1.<NewLine></code></pre><NewLine><p>I do not run any tests any more, each run takes about 7 hours. I am waiting for an idea what I should do. Thank you.</p><NewLine></div>; <NewLine> REPLY 7: <div class=""post"" itemprop=""articleBody""><NewLine><p>hello,i am build pytorch in windos c++ too.<br/><NewLine>i aslo meet this problem as same as you.<br/><NewLine><strong>LINK : fatal error LNK1356: Die zur vollständigen Archivierung angegebene Bibliothek “\C:/Users/Admin/Downloads/Pytorch/pytorch/build/lib/Release/caffe2_protos.lib.lib” wurde nicht gefunden. [C:\Users\Admi</strong><br/><NewLine><strong>n\Downloads\Pytorch\pytorch\build\caffe2\torch_cpu.vcxproj]</strong><br/><NewLine>if you solve this problem,i hope you can tell me your idea.<br/><NewLine>Thanks</p><NewLine></div>; <NewLine> REPLY 8: <div class=""post"" itemprop=""articleBody""><NewLine><p>I have stopped any tests on this after putting some days into this. I am waiting for a helping reply, good that you join me in waiting. Generally, I guess that the error is linked with the same problem that causes ninja not to work. I do not know why I cannot use ninja. Setting off ninja is just a workaround, yet there should be a better way I think, because ninja will make the install much faster. I do not want to let it run for 7 hours again and again only to have the same errors thrown.</p><NewLine><p>If you want to try something that seems promising, have a look at <a class=""inline-onebox"" href=""https://discuss.pytorch.org/t/pytorch-build-from-source-on-windows/40288/16"">PyTorch build from source on Windows</a> and further down, especially</p><NewLine><p><code>set CUDAHOSTCXX=</code></p><NewLine></div>; <NewLine> REPLY 9: <div class=""post"" itemprop=""articleBody""><NewLine><p>thanks for your reply.i will keep to test in ohther way.<br/><NewLine>i already to see that,but it’s no work for me.<br/><NewLine>thanks and keep in touch.</p><NewLine></div>; <NewLine> REPLY 10: <div class=""post"" itemprop=""articleBody""><NewLine><p>I succeed in my win10 with build ninja ,so i tell you my way but it’s may must work for you.<br/><NewLine>first,i update my source code ,and <strong>git submodule update --init --recursive</strong> to update my third_part.<br/><NewLine>and then,i set  (USE_MKLDNN=OFF)may no need  to you.<br/><NewLine><strong>python setup.py build --cmake</strong><br/><NewLine><strong>python setup.py install</strong><br/><NewLine>cuda also can use.<br/><NewLine>i hope you can succeed to build it.<br/><NewLine>good luck</p><NewLine></div>; <NewLine> REPLY 11: <div class=""post"" itemprop=""articleBody""><NewLine><p>Glad you made it, that means that it is really still possible and that I have system / environment / card specific problems.</p><NewLine><p>For example, I need to use <code>set USE_NINJA=OFF</code>, else I get this error:</p><NewLine><pre><code class=""lang-auto"">  File ""C:\Users\Admin\anaconda3\envs\dl\lib\site-packages\setuptools\msvc.py"", line 314, in msvc14_get_vc_env<NewLine>    return _msvc14_get_vc_env(plat_spec)<NewLine>  File ""C:\Users\Admin\anaconda3\envs\dl\lib\site-packages\setuptools\msvc.py"", line 278, in _msvc14_get_vc_env<NewLine>    raise distutils.errors.DistutilsPlatformError(<NewLine>distutils.errors.DistutilsPlatformError: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/<NewLine></code></pre><NewLine><p>Which is one clear difference with your settings. And in addition, I must use MKL, since else, I get “Error loading caffe2_detectron_ops_gpu.dll”, see the header of this thread - even if pytorch gets fully installed then.</p><NewLine><p>At the moment, it crashes just a minute after the start, so something else has gone wrong with the command or with the cloned pytorch directory.</p><NewLine><p><code>subprocess.CalledProcessError: Command '['cmake', '-GVisual Studio 16 2019', '-Ax64', '-Thost=x64', '-DBUILD_PYTHON=True', '-DBUILD_TEST=True', '-DCMAKE_BUILD_TYPE=Release', '-DCMAKE_GENERATOR=Visual Studio 16 2019', '-DCMAKE_INCLUDE_PATH=C:\\Users\\Admin\\Downloads\\Pytorch\\mkl\\include', '-DCMAKE_INSTALL_PREFIX=C:\\Users\\Admin\\Downloads\\Pytorch\\pytorch\\torch', '-DCMAKE_PREFIX_PATH=C:\\Users\\Admin\\anaconda3\\envs\\dl\\Lib\\site-packages', '-DJAVA_HOME=C:\\Users\\Admin\\AppData\\Local\\Programs\\AdoptOpenJDK\\', '-DNUMPY_INCLUDE_DIR=C:\\Users\\Admin\\anaconda3\\envs\\dl\\lib\\site-packages\\numpy\\core\\include', '-DPYTHON_EXECUTABLE=C:\\Users\\Admin\\anaconda3\\envs\\dl\\python.exe', '-DPYTHON_INCLUDE_DIR=C:\\Users\\Admin\\anaconda3\\envs\\dl\\include', '-DPYTHON_LIBRARY=C:\\Users\\Admin\\anaconda3\\envs\\dl/libs/python38.lib', '-DTORCH_BUILD_VERSION=1.7.0a0+4e964f3', '-DUSE_MKLDNN=OFF', '-DUSE_NINJA=OFF', '-DUSE_NUMPY=True', 'C:\\Users\\Admin\\Downloads\\Pytorch\\pytorch']' returned non-zero exit status 1.</code></p><NewLine><p>I will probably get further when I can finally use ninja, as you can do it. That should be possible. I will start some new tries as soon as I find the time.</p><NewLine></div>; <NewLine> REPLY 12: <div class=""post"" itemprop=""articleBody""><NewLine><p>I think your problem is easy to solve.because i alread install VS2019 ,so i have msvc tool to build it.<br/><NewLine>i use <strong>Native tools command prompt for vs 2019</strong> to run <code>python setup.py build --cmake</code><br/><NewLine>just keep to try again.good luck friend</p><NewLine></div>; <NewLine> REPLY 13: <div class=""post"" itemprop=""articleBody""><NewLine><p>Thanks for the motivation, it is more important than the solution after so many tries. I am surely backing your <em>friend</em> here in this weird challenge of my computer’s nerves :))).<br/><NewLine>That is understood, I also have MSVC2019 installed, and setting ninja off is using that MSVC successfully. The MSVC error appears as soon as I use ninja, which is made to improve installation speed (at the moment, with ninja set OFF, I guess it is about seven hours running time for a successful run and about three for an erroneous run). Up to now, I have installed from anaconda prompt, I will try your recommended <strong>Native tools command prompt for vs 2019</strong> as soon as I find the time, probably in a few weeks only.</p><NewLine></div>; <NewLine> ",REPLIER 1: https://discuss.pytorch.org/u/peterjc123; <NewLine> REPLIER 2: https://discuss.pytorch.org/u/peterjc123; <NewLine> REPLIER 3: https://discuss.pytorch.org/u/lorenzznerol; <NewLine> REPLIER 4: https://discuss.pytorch.org/u/lorenzznerol; <NewLine> REPLIER 5: https://discuss.pytorch.org/u/peterjc123; <NewLine> REPLIER 6: https://discuss.pytorch.org/u/lorenzznerol; <NewLine> REPLIER 7: https://discuss.pytorch.org/u/Peter-weng; <NewLine> REPLIER 8: https://discuss.pytorch.org/u/lorenzznerol; <NewLine> REPLIER 9: https://discuss.pytorch.org/u/Peter-weng; <NewLine> REPLIER 10: https://discuss.pytorch.org/u/Peter-weng; <NewLine> REPLIER 11: https://discuss.pytorch.org/u/lorenzznerol; <NewLine> REPLIER 12: https://discuss.pytorch.org/u/Peter-weng; <NewLine> REPLIER 13: https://discuss.pytorch.org/u/lorenzznerol; <NewLine> ,"REPLY_DATE 1: August 19, 2020,  1:10am; <NewLine> REPLY_DATE 2: August 19, 2020,  1:12am; <NewLine> REPLY_DATE 3: August 19, 2020,  7:46am; <NewLine> REPLY_DATE 4: August 19, 2020, 12:15pm; <NewLine> REPLY_DATE 5: August 19, 2020,  1:57pm; <NewLine> REPLY_DATE 6: August 20, 2020,  1:11pm; <NewLine> REPLY_DATE 7: August 26, 2020,  8:17am; <NewLine> REPLY_DATE 8: August 26, 2020,  9:33am; <NewLine> REPLY_DATE 9: August 26, 2020, 10:08am; <NewLine> REPLY_DATE 10: August 27, 2020,  3:55am; <NewLine> REPLY_DATE 11: August 27, 2020,  9:46pm; <NewLine> REPLY_DATE 12: August 28, 2020,  8:20am; <NewLine> REPLY_DATE 13: August 28, 2020, 10:02am; <NewLine> ",REPLY 1 LIKES: ; <NewLine> REPLY 2 LIKES: ; <NewLine> REPLY 3 LIKES: ; <NewLine> REPLY 4 LIKES: ; <NewLine> REPLY 5 LIKES: ; <NewLine> REPLY 6 LIKES: 1 Like; <NewLine> REPLY 7 LIKES: ; <NewLine> REPLY 8 LIKES: ; <NewLine> REPLY 9 LIKES: 1 Like; <NewLine> REPLY 10 LIKES: 1 Like; <NewLine> REPLY 11 LIKES: ; <NewLine> REPLY 12 LIKES: 1 Like; <NewLine> REPLY 13 LIKES: ; <NewLine> 
94002,How can I use multiple GPUs on WSL2?,2020-08-25T05:14:56.533Z,1,107,"<div class=""post"" itemprop=""articleBody""><NewLine><p>Hello,</p><NewLine><p>I try to use multiple GPUs (RTX 2080Ti *2) with torch.distributed and pytorch-lightning on WSL2 (windows subsystem for linux).<br/><NewLine>But I receiving following error:</p><NewLine><pre><code class=""lang-auto"">NCCL error in: /pytorch/torch/lib/c10d/ProcessGroupNCCL.cpp:518, unhandled system error, NCCL version 2.4.8<NewLine></code></pre><NewLine><p>I can run same process using single GPU.</p><NewLine><p>Thanks for your great help.</p><NewLine></div>",https://discuss.pytorch.org/u/Naruki_Ichihara,(Naruki Ichihara),Naruki_Ichihara,"August 25, 2020,  5:14am",,"REPLY 1: <div class=""post"" itemprop=""articleBody""><NewLine><p>Is SLI enabled? What the output of nvidia-smi?</p><NewLine></div>; <NewLine> REPLY 2: <div class=""post"" itemprop=""articleBody""><NewLine><p>Thank you for your reply.<br/><NewLine>Since I use CUDA on WSL (<a href=""https://docs.nvidia.com/cuda/wsl-user-guide/index.html#getting-started"" rel=""nofollow noopener"">https://docs.nvidia.com/cuda/wsl-user-guide/index.html#getting-started</a>), Ubuntu (on WSL) cannot use the “nvidia-smi” utility.<br/><NewLine>nvidia-smi on windows shell output following:</p><NewLine><pre><code class=""lang-auto"">+-----------------------------------------------------------------------------+<NewLine>| NVIDIA-SMI 455.41       Driver Version: 455.41       CUDA Version: 11.1     |<NewLine>|-------------------------------+----------------------+----------------------+<NewLine>| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |<NewLine>| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<NewLine>|===============================+======================+======================|<NewLine>|   0  GeForce RTX 208... WDDM  | 00000000:1A:00.0  On |                  N/A |<NewLine>| 41%   50C    P0    59W / 250W |    662MiB / 11264MiB |      0%      Default |<NewLine>+-------------------------------+----------------------+----------------------+<NewLine>|   1  GeForce RTX 208... WDDM  | 00000000:68:00.0 Off |                  N/A |<NewLine>| 27%   35C    P8    20W / 250W |    216MiB / 11264MiB |      0%      Default |<NewLine>+-------------------------------+----------------------+----------------------+<NewLine><NewLine>+-----------------------------------------------------------------------------+<NewLine>| Processes:                                                                  |<NewLine>|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |<NewLine>|        ID   ID                                                   Usage      |<NewLine></code></pre><NewLine><p>Does this output mean SLI is enabled?</p><NewLine></div>; <NewLine> ",REPLIER 1: https://discuss.pytorch.org/u/ebarsoum; <NewLine> REPLIER 2: https://discuss.pytorch.org/u/Naruki_Ichihara; <NewLine> ,"REPLY_DATE 1: August 25, 2020,  6:29am; <NewLine> REPLY_DATE 2: August 25, 2020,  7:49am; <NewLine> ",REPLY 1 LIKES: ; <NewLine> REPLY 2 LIKES: ; <NewLine> 
93697,ModuleNotFoundError: No module named &lsquo;torch&rsquo; in IDLE,2020-08-22T03:49:56.945Z,0,52,"<div class=""post"" itemprop=""articleBody""><NewLine><p>So I installed pytorch through anaconda successfully and when I try importing torch in IDLE I get this error</p><NewLine><p>I did what I found on stack exchange “print(sys.executable)”</p><NewLine><p>Conda’s result: C:\Users\readz\anaconda3\python.exe<br/><NewLine>IDLE’s result: C:\Users\readz\AppData\Local\Programs\Python\Python38-32\pythonw.exe</p><NewLine><p>Problem is there they didn’t explain what to do with this info or how to solve the problem…</p><NewLine></div>",https://discuss.pytorch.org/u/Jay,,Jay,"August 22, 2020,  3:49am",,"REPLY 1: <div class=""post"" itemprop=""articleBody""><NewLine><p>Did you install <code>IDLE</code> in the same conda environment and executed it there?<br/><NewLine>If not, could you do it, as currently <code>IDLE</code> seems to use another Python environment.</p><NewLine></div>; <NewLine> ",REPLIER 1: https://discuss.pytorch.org/u/ptrblck; <NewLine> ,"REPLY_DATE 1: August 24, 2020,  9:33am; <NewLine> ",REPLY 1 LIKES: ; <NewLine> 
93639,Detectron 2 on Windows 10,2020-08-21T14:27:06.025Z,0,63,"<div class=""post"" itemprop=""articleBody""><NewLine><p>Is their any way to install  detectron 2 on windows ?</p><NewLine></div>",https://discuss.pytorch.org/u/Heisenberg_082001,(Pranav Kushare),Heisenberg_082001,"August 21, 2020,  2:27pm",,"REPLY 1: <div class=""post"" itemprop=""articleBody""><NewLine><p>Based on this information from the <a href=""https://github.com/facebookresearch/detectron2/blob/master/INSTALL.md"">repository</a>:</p><NewLine><blockquote><NewLine><p>Although detectron2 can be installed on windows with some effort (similar to <a href=""https://github.com/facebookresearch/pytorch3d/blob/master/INSTALL.md#2-install-from-a-local-clone"">these</a>), we do not provide official support for it.<br/><NewLine>PRs that improves code compatibility on windows are welcome.</p><NewLine></blockquote><NewLine><p>it doesn’t seem that Windows is supported out of the box.</p><NewLine></div>; <NewLine> ",REPLIER 1: https://discuss.pytorch.org/u/ptrblck; <NewLine> ,"REPLY_DATE 1: August 24, 2020,  9:13am; <NewLine> ",REPLY 1 LIKES: ; <NewLine> 
93779,Can LSTM run multivariate time series?,2020-08-23T08:53:29.101Z,1,97,"<div class=""post"" itemprop=""articleBody""><NewLine><p>Hello, everyone.<br/><NewLine>I want to run Deep Learning model for multivariate time series.</p><NewLine><p>For example, below is the daily delivery amount of post office</p><NewLine><p>delivery date, post office id, delivery amount, weekday, …</p><NewLine><p>which is daily data, multivariate</p><NewLine><p>I want to predict future delivery amount using data above.</p><NewLine><p>Can I run this as deep learning model using LSTM??</p><NewLine><p>That is, can LSTM run mutlivariate time series data for prediction??</p><NewLine><p>If it is not possible, which deep learning model should I use??</p><NewLine><p>Thank you in advance and have a nice day!</p><NewLine></div>",https://discuss.pytorch.org/u/morphism,,morphism,"August 23, 2020,  9:09am",,"REPLY 1: <div class=""post"" itemprop=""articleBody""><NewLine><aside class=""quote no-group"" data-post=""1"" data-topic=""93779"" data-username=""morphism""><NewLine><div class=""title""><NewLine><div class=""quote-controls""></div><NewLine><img alt="""" class=""avatar"" height=""20"" src=""https://discuss.pytorch.org/letter_avatar_proxy/v4/letter/m/f9ae1b/40.png"" width=""20""/> morphism:</div><NewLine><blockquote><NewLine><p>Can I run this as deep learning model using LSTM??</p><NewLine></blockquote><NewLine></aside><NewLine><p>Yes you can use LSTM for time series data prediction. You can find alot of resources for that purpose.</p><NewLine><p>You can check this github repo for research papers and link for data resources.<br/><NewLine><a href=""https://github.com/Alro10/deep-learning-time-series"" rel=""nofollow noopener"">https://github.com/Alro10/deep-learning-time-series</a></p><NewLine><p>If you want to checkout for implementation you can also find that in below link.<br/><NewLine><a href=""https://github.com/zhangxu0307/time_series_forecasting_pytorch"" rel=""nofollow noopener"">https://github.com/zhangxu0307/time_series_forecasting_pytorch</a><br/><NewLine><a href=""https://github.com/KurochkinAlexey/ConvRNN"" rel=""nofollow noopener"">https://github.com/KurochkinAlexey/ConvRNN</a><br/><NewLine><a href=""https://stackoverflow.com/questions/56858924/multivariate-input-lstm-in-pytorch"" rel=""nofollow noopener"">https://stackoverflow.com/questions/56858924/multivariate-input-lstm-in-pytorch</a></p><NewLine></div>; <NewLine> REPLY 2: <div class=""post"" itemprop=""articleBody""><NewLine><p>Dear Usama:</p><NewLine><p>Thank you for your help and kindness.<br/><NewLine>I believe your advise can solve my problems.<br/><NewLine>I will read them in detail.</p><NewLine><p>Have a nice day and see you, Usama.</p><NewLine></div>; <NewLine> ",REPLIER 1: https://discuss.pytorch.org/u/Usama_Hasan; <NewLine> REPLIER 2: https://discuss.pytorch.org/u/morphism; <NewLine> ,"REPLY_DATE 1: August 23, 2020,  9:50am; <NewLine> REPLY_DATE 2: August 23, 2020, 12:03pm; <NewLine> ",REPLY 1 LIKES: ; <NewLine> REPLY 2 LIKES: ; <NewLine> 
93012,Initial Pytorch setup and another few questions,2020-08-16T17:17:57.558Z,0,81,"<div class=""post"" itemprop=""articleBody""><NewLine><p>Hi everyone .</p><NewLine><p>I’m new to Pytorch and I’m trying to figure out a few things right now .</p><NewLine><p>I have the following components :</p><NewLine><pre><code class=""lang-auto"">   ...:<NewLine>`__Python VERSION: 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]<NewLine>__pyTorch VERSION: 1.2.0+cu92<NewLine>__CUDA VERSION<NewLine>nvcc: NVIDIA (R) Cuda compiler driver<NewLine>Copyright (c) 2005-2018 NVIDIA Corporation<NewLine>Built on Tue_Jun_12_23:08:12_Central_Daylight_Time_2018<NewLine>Cuda compilation tools, release 9.2, V9.2.148<NewLine>__CUDNN VERSION: 7201<NewLine>__Number CUDA Devices: 1<NewLine>__Devices<NewLine>Active CUDA Device: GPU 0<NewLine>Available devices  1<NewLine>Current cuda device  0``<NewLine></code></pre><NewLine><p>I’m using the following hardware and software :<br/><NewLine><strong>Z440 G4</strong><br/><NewLine><strong>16GB RAM</strong><br/><NewLine><strong>NVIDIA QUADRO RTX 4000 (CUDA supported)</strong><br/><NewLine><strong>Windows server 2012r2</strong><br/><NewLine><strong>Anaconda 3.5.2 - Python 3.6.5 ( I need that specific version) .</strong></p><NewLine><ol><NewLine><li>After the installation of all the components I needed I searched for a training example just to make sure Pytorch is working . I executed the following :</li><NewLine></ol><NewLine><pre><code class=""lang-auto"">`import torch<NewLine> import torch.optim as optim<NewLine><NewLine> model = torch.nn.Linear(5, 2)<NewLine><NewLine>  Initialize optimizer<NewLine> optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)<NewLine><NewLine> print(""Model's state_dict:"")<NewLine> for param_tensor in model.state_dict():<NewLine>     print(param_tensor, ""\t"", model.state_dict()[param_tensor].size())<NewLine><NewLine> print(""Model weight:"")<NewLine> print(model.weight)<NewLine><NewLine> print(""Model bias:"")<NewLine> print(model.bias)<NewLine><NewLine> print(""---"")<NewLine> print(""Optimizer's state_dict:"")<NewLine> for var_name in optimizer.state_dict():<NewLine>     print(var_name, ""\t"", optimizer.state_dict()[var_name])``<NewLine></code></pre><NewLine><p>And got the following output</p><NewLine><pre><code class=""lang-auto"">Model's state_dict:<NewLine>weight   torch.Size([2, 5])<NewLine>bias     torch.Size([2])<NewLine>Model weight:<NewLine>Parameter containing:<NewLine>tensor([[-0.1759, -0.2537,  0.1401,  0.2342, -0.3865],<NewLine>        [-0.2142,  0.2763, -0.2919,  0.2003, -0.3242]], requires_grad=True)<NewLine>Model bias:<NewLine>Parameter containing:<NewLine>tensor([-0.0585,  0.2511], requires_grad=True)<NewLine>---<NewLine>Optimizer's state_dict:<NewLine>state    {}<NewLine>param_groups     [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [935863832152, 9358638<NewLine>31360]}]<NewLine></code></pre><NewLine><p>Next I have saved it by using :</p><NewLine><pre><code class=""lang-auto"">torch.save(model.state_dict(), ""temp.pt"")<NewLine></code></pre><NewLine><p>So far it seems OK to me . Anything else I can / Should check in addition ?</p><NewLine><p>2 . How can I check in real time that my GPU is working ? I want to make sure PYTORCH is using the GPU and not the CPU . Anything I can check ? Saved log file maybe ?</p><NewLine><p>Appreciate your help .<br/><NewLine>Please let me know if any information is needed .</p><NewLine></div>",https://discuss.pytorch.org/u/NoamAS,(Noam As),NoamAS,"August 16, 2020,  5:23pm",,"REPLY 1: <div class=""post"" itemprop=""articleBody""><NewLine><aside class=""quote no-group"" data-post=""1"" data-topic=""93012"" data-username=""NoamAS""><NewLine><div class=""title""><NewLine><div class=""quote-controls""></div><NewLine><img alt="""" class=""avatar"" height=""20"" src=""https://discuss.pytorch.org/letter_avatar_proxy/v4/letter/n/d6d6ee/40.png"" width=""20""/> NoamAS:</div><NewLine><blockquote><NewLine><p>How can I check in real time that my GPU is working ?</p><NewLine></blockquote><NewLine></aside><NewLine><p>Push your model to the device and execute a training step:</p><NewLine><pre><code class=""lang-python"">device = 'cuda'<NewLine>model.to(device)<NewLine>data = torch.randn(1, 5, device=device)<NewLine>out = model(data)<NewLine>out.mean().backward()<NewLine></code></pre><NewLine><p>If this code runs fine then your GPU is used.</p><NewLine><p>For more testing, you could execute some <a href=""https://github.com/pytorch/examples"">examples</a>.</p><NewLine></div>; <NewLine> REPLY 2: <div class=""post"" itemprop=""articleBody""><NewLine><p>Thank you for the answer .<br/><NewLine>I don’t have any ready model really so I picked up the following code instead and uncomment the GPU part to make sure the GPU will be used:</p><NewLine><pre><code class=""lang-auto"">: dtype = torch.float<NewLine>: #device = torch.device(""cpu"")<NewLine>: device = torch.device(""cuda:0"") # Uncomment this to run on GPU<NewLine>:<NewLine>: # N is batch size; D_in is input dimension;<NewLine>: # H is hidden dimension; D_out is output dimension.<NewLine>: N, D_in, H, D_out = 64, 1000, 100, 10<NewLine>:<NewLine>: # Create random input and output data<NewLine>: x = torch.randn(N, D_in, device=device, dtype=dtype)<NewLine>: y = torch.randn(N, D_out, device=device, dtype=dtype)<NewLine>:<NewLine>: # Randomly initialize weights<NewLine>: w1 = torch.randn(D_in, H, device=device, dtype=dtype)<NewLine>: w2 = torch.randn(H, D_out, device=device, dtype=dtype)<NewLine>:<NewLine>: learning_rate = 1e-6<NewLine>: for t in range(500):<NewLine>:     # Forward pass: compute predicted y<NewLine>:     h = x.mm(w1)<NewLine>:     h_relu = h.clamp(min=0)<NewLine>:     y_pred = h_relu.mm(w2)<NewLine>:<NewLine>:     # Compute and print loss<NewLine>:     loss = (y_pred - y).pow(2).sum().item()<NewLine>:     if t % 100 == 99:<NewLine>:         print(t, loss)<NewLine>:<NewLine>:     # Backprop to compute gradients of w1 and w2 with respect to loss<NewLine>:     grad_y_pred = 2.0 * (y_pred - y)<NewLine>:     grad_w2 = h_relu.t().mm(grad_y_pred)<NewLine>:     grad_h_relu = grad_y_pred.mm(w2.t())<NewLine>:     grad_h = grad_h_relu.clone()<NewLine>:     grad_h[h &lt; 0] = 0<NewLine>:     grad_w1 = x.t().mm(grad_h)<NewLine>:<NewLine>:     # Update weights using gradient descent<NewLine>:     w1 -= learning_rate * grad_w1<NewLine>:     w2 -= learning_rate * grad_w2<NewLine></code></pre><NewLine><p>Got the following:</p><NewLine><pre><code class=""lang-auto"">99 384.6168518066406<NewLine>199 2.1987862586975098<NewLine>299 0.02469571679830551<NewLine>399 0.0005685320356860757<NewLine>499 7.920750067569315e-05<NewLine></code></pre><NewLine></div>; <NewLine> ",REPLIER 1: https://discuss.pytorch.org/u/ptrblck; <NewLine> REPLIER 2: https://discuss.pytorch.org/u/NoamAS; <NewLine> ,"REPLY_DATE 1: August 18, 2020,  8:06am; <NewLine> REPLY_DATE 2: August 18, 2020,  8:50am; <NewLine> ",REPLY 1 LIKES: ; <NewLine> REPLY 2 LIKES: ; <NewLine> 
91578,Num_workers&gt;0 Windows 10 ERROR,2020-08-04T08:44:47.127Z,2,97,"<div class=""post"" itemprop=""articleBody""><NewLine><p>Hi, I am training my dataset using this code below, in linux it runs well and fast but when I try to run on windows I can only run if num-workers = 0 but that makes the process much slower. Does anyone know how I can run this code on windows with num-workers&gt; 0?</p><NewLine><pre><code class=""lang-auto"">import os<NewLine>import sys<NewLine>import logging<NewLine>import argparse<NewLine>import itertools<NewLine>import torch<NewLine><NewLine>from torch.utils.data import DataLoader, ConcatDataset<NewLine>from torch.optim.lr_scheduler import CosineAnnealingLR, MultiStepLR<NewLine><NewLine>from vision.utils.misc import str2bool, Timer, freeze_net_layers, store_labels<NewLine>from vision.ssd.ssd import MatchPrior<NewLine>from vision.ssd.vgg_ssd import create_vgg_ssd<NewLine>from vision.ssd.mobilenetv1_ssd import create_mobilenetv1_ssd<NewLine>from vision.ssd.mobilenetv1_ssd_lite import create_mobilenetv1_ssd_lite<NewLine>from vision.ssd.mobilenet_v2_ssd_lite import create_mobilenetv2_ssd_lite<NewLine>from vision.ssd.squeezenet_ssd_lite import create_squeezenet_ssd_lite<NewLine>from vision.datasets.voc_dataset import VOCDataset<NewLine>from vision.datasets.open_images import OpenImagesDataset<NewLine>from vision.nn.multibox_loss import MultiboxLoss<NewLine>from vision.ssd.config import vgg_ssd_config<NewLine>from vision.ssd.config import mobilenetv1_ssd_config<NewLine>from vision.ssd.config import squeezenet_ssd_config<NewLine>from vision.ssd.data_preprocessing import TrainAugmentation, TestTransform<NewLine><NewLine>parser = argparse.ArgumentParser(<NewLine>    description='Single Shot MultiBox Detector Training With PyTorch')<NewLine><NewLine># Params for datasets<NewLine>parser.add_argument(""--dataset-type"", default=""open_images"", type=str,<NewLine>                    help='Specify dataset type. Currently supports voc and open_images.')<NewLine>parser.add_argument('--datasets', '--data', nargs='+', default=[""data""], help='Dataset directory path')<NewLine>parser.add_argument('--balance-data', action='store_true',<NewLine>                    help=""Balance training data by down-sampling more frequent labels."")<NewLine><NewLine># Params for network<NewLine>parser.add_argument('--net', default=""mb1-ssd"",<NewLine>                    help=""The network architecture, it can be mb1-ssd, mb1-lite-ssd, mb2-ssd-lite or vgg16-ssd."")<NewLine>parser.add_argument('--freeze-base-net', action='store_true',<NewLine>                    help=""Freeze base net layers."")<NewLine>parser.add_argument('--freeze-net', action='store_true',<NewLine>                    help=""Freeze all the layers except the prediction head."")<NewLine>parser.add_argument('--mb2-width-mult', default=1.0, type=float,<NewLine>                    help='Width Multiplifier for MobilenetV2')<NewLine><NewLine># Params for loading pretrained basenet or checkpoints.<NewLine>parser.add_argument('--base-net', help='Pretrained base model')<NewLine>parser.add_argument('--pretrained-ssd', default='models/mobilenet-v1-ssd-mp-0_675.pth', type=str, help='Pre-trained base model')<NewLine>parser.add_argument('--resume', default=None, type=str,<NewLine>                    help='Checkpoint state_dict file to resume training from')<NewLine><NewLine># Params for SGD<NewLine>parser.add_argument('--lr', '--learning-rate', default=0.01, type=float,<NewLine>                    help='initial learning rate')<NewLine>parser.add_argument('--momentum', default=0.9, type=float,<NewLine>                    help='Momentum value for optim')<NewLine>parser.add_argument('--weight-decay', default=5e-4, type=float,<NewLine>                    help='Weight decay for SGD')<NewLine>parser.add_argument('--gamma', default=0.1, type=float,<NewLine>                    help='Gamma update for SGD')<NewLine>parser.add_argument('--base-net-lr', default=0.001, type=float,<NewLine>                    help='initial learning rate for base net, or None to use --lr')<NewLine>parser.add_argument('--extra-layers-lr', default=None, type=float,<NewLine>                    help='initial learning rate for the layers not in base net and prediction heads.')<NewLine><NewLine># Scheduler<NewLine>parser.add_argument('--scheduler', default=""cosine"", type=str,<NewLine>                    help=""Scheduler for SGD. It can one of multi-step and cosine"")<NewLine><NewLine># Params for Multi-step Scheduler<NewLine>parser.add_argument('--milestones', default=""80,100"", type=str,<NewLine>                    help=""milestones for MultiStepLR"")<NewLine><NewLine># Params for Cosine Annealing<NewLine>parser.add_argument('--t-max', default=100, type=float,<NewLine>                    help='T_max value for Cosine Annealing Scheduler.')<NewLine><NewLine># Train params<NewLine>parser.add_argument('--batch-size', default=4, type=int,<NewLine>                    help='Batch size for training')<NewLine>parser.add_argument('--num-epochs', default=30, type=int,<NewLine>                    help='the number epochs')<NewLine>parser.add_argument('--num-workers', default=2, type=int,<NewLine>                    help='Number of workers used in dataloading')<NewLine>parser.add_argument('--validation-epochs', default=1, type=int,<NewLine>                    help='the number epochs between running validation')<NewLine>parser.add_argument('--debug-steps', default=10, type=int,<NewLine>                    help='Set the debug log output frequency.')<NewLine>parser.add_argument('--use-cuda', default=True, type=str2bool,<NewLine>                    help='Use CUDA to train model')<NewLine>parser.add_argument('--checkpoint-folder', '--model-dir', default='models/',<NewLine>                    help='Directory for saving checkpoint models')<NewLine><NewLine>logging.basicConfig(stream=sys.stdout, level=logging.INFO,<NewLine>                    format='%(asctime)s - %(message)s', datefmt=""%Y-%m-%d %H:%M:%S"")<NewLine>                    <NewLine>args = parser.parse_args()<NewLine>DEVICE = torch.device(""cuda:0"" if torch.cuda.is_available() and args.use_cuda else ""cpu"")<NewLine><NewLine>if args.use_cuda and torch.cuda.is_available():<NewLine>    torch.backends.cudnn.benchmark = True<NewLine>    logging.info(""Using CUDA..."")<NewLine><NewLine><NewLine>def train(loader, net, criterion, optimizer, device, debug_steps=100, epoch=-1):<NewLine>    net.train(True)<NewLine>    running_loss = 0.0<NewLine>    running_regression_loss = 0.0<NewLine>    running_classification_loss = 0.0<NewLine>    for i, data in enumerate(loader):<NewLine>        images, boxes, labels = data<NewLine>        images = images.to(device)<NewLine>        boxes = boxes.to(device)<NewLine>        labels = labels.to(device)<NewLine><NewLine>        optimizer.zero_grad()<NewLine>        confidence, locations = net(images)<NewLine>        regression_loss, classification_loss = criterion(confidence, locations, labels, boxes)  # TODO CHANGE BOXES<NewLine>        loss = regression_loss + classification_loss<NewLine>        loss.backward()<NewLine>        optimizer.step()<NewLine><NewLine>        running_loss += loss.item()<NewLine>        running_regression_loss += regression_loss.item()<NewLine>        running_classification_loss += classification_loss.item()<NewLine>        if i and i % debug_steps == 0:<NewLine>            avg_loss = running_loss / debug_steps<NewLine>            avg_reg_loss = running_regression_loss / debug_steps<NewLine>            avg_clf_loss = running_classification_loss / debug_steps<NewLine>            logging.info(<NewLine>                f""Epoch: {epoch}, Step: {i}/{len(loader)}, "" +<NewLine>                f""Avg Loss: {avg_loss:.4f}, "" +<NewLine>                f""Avg Regression Loss {avg_reg_loss:.4f}, "" +<NewLine>                f""Avg Classification Loss: {avg_clf_loss:.4f}""<NewLine>            )<NewLine>            running_loss = 0.0<NewLine>            running_regression_loss = 0.0<NewLine>            running_classification_loss = 0.0<NewLine><NewLine><NewLine>def test(loader, net, criterion, device):<NewLine>    net.eval()<NewLine>    running_loss = 0.0<NewLine>    running_regression_loss = 0.0<NewLine>    running_classification_loss = 0.0<NewLine>    num = 0<NewLine>    for _, data in enumerate(loader):<NewLine>        images, boxes, labels = data<NewLine>        images = images.to(device)<NewLine>        boxes = boxes.to(device)<NewLine>        labels = labels.to(device)<NewLine>        num += 1<NewLine><NewLine>        with torch.no_grad():<NewLine>            confidence, locations = net(images)<NewLine>            regression_loss, classification_loss = criterion(confidence, locations, labels, boxes)<NewLine>            loss = regression_loss + classification_loss<NewLine><NewLine>        running_loss += loss.item()<NewLine>        running_regression_loss += regression_loss.item()<NewLine>        running_classification_loss += classification_loss.item()<NewLine>    return running_loss / num, running_regression_loss / num, running_classification_loss / num<NewLine><NewLine><NewLine>if __name__ == '__main__':<NewLine>    timer = Timer()<NewLine><NewLine>    logging.info(args)<NewLine>    <NewLine>    # make sure that the checkpoint output dir exists<NewLine>    if args.checkpoint_folder:<NewLine>        args.checkpoint_folder = os.path.expanduser(args.checkpoint_folder)<NewLine><NewLine>        if not os.path.exists(args.checkpoint_folder):<NewLine>            os.mkdir(args.checkpoint_folder)<NewLine>            <NewLine>    # select the network architecture and config     <NewLine>    if args.net == 'vgg16-ssd':<NewLine>        create_net = create_vgg_ssd<NewLine>        config = vgg_ssd_config<NewLine>    elif args.net == 'mb1-ssd':<NewLine>        create_net = create_mobilenetv1_ssd<NewLine>        config = mobilenetv1_ssd_config<NewLine>    elif args.net == 'mb1-ssd-lite':<NewLine>        create_net = create_mobilenetv1_ssd_lite<NewLine>        config = mobilenetv1_ssd_config<NewLine>    elif args.net == 'sq-ssd-lite':<NewLine>        create_net = create_squeezenet_ssd_lite<NewLine>        config = squeezenet_ssd_config<NewLine>    elif args.net == 'mb2-ssd-lite':<NewLine>        create_net = lambda num: create_mobilenetv2_ssd_lite(num, width_mult=args.mb2_width_mult)<NewLine>        config = mobilenetv1_ssd_config<NewLine>    else:<NewLine>        logging.fatal(""The net type is wrong."")<NewLine>        parser.print_help(sys.stderr)<NewLine>        sys.exit(1)<NewLine>        <NewLine>    # create data transforms for train/test/val<NewLine>    train_transform = TrainAugmentation(config.image_size, config.image_mean, config.image_std)<NewLine>    target_transform = MatchPrior(config.priors, config.center_variance,<NewLine>                                  config.size_variance, 0.5)<NewLine><NewLine>    test_transform = TestTransform(config.image_size, config.image_mean, config.image_std)<NewLine><NewLine>    # load datasets (could be multiple)<NewLine>    logging.info(""Prepare training datasets."")<NewLine>    datasets = []<NewLine>    for dataset_path in args.datasets:<NewLine>        if args.dataset_type == 'voc':<NewLine>            dataset = VOCDataset(dataset_path, transform=train_transform,<NewLine>                                 target_transform=target_transform)<NewLine>            label_file = os.path.join(args.checkpoint_folder, ""labels.txt"")<NewLine>            store_labels(label_file, dataset.class_names)<NewLine>            num_classes = len(dataset.class_names)<NewLine>        elif args.dataset_type == 'open_images':<NewLine>            dataset = OpenImagesDataset(dataset_path,<NewLine>                 transform=train_transform, target_transform=target_transform,<NewLine>                 dataset_type=""train"", balance_data=args.balance_data)<NewLine>            label_file = os.path.join(args.checkpoint_folder, ""labels.txt"")<NewLine>            store_labels(label_file, dataset.class_names)<NewLine>            logging.info(dataset)<NewLine>            num_classes = len(dataset.class_names)<NewLine><NewLine>        else:<NewLine>            raise ValueError(f""Dataset type {args.dataset_type} is not supported."")<NewLine>        datasets.append(dataset)<NewLine>        <NewLine>    # create training dataset<NewLine>    logging.info(f""Stored labels into file {label_file}."")<NewLine>    train_dataset = ConcatDataset(datasets)<NewLine>    logging.info(""Train dataset size: {}"".format(len(train_dataset)))<NewLine>    train_loader = DataLoader(train_dataset, args.batch_size,<NewLine>                              num_workers=args.num_workers,<NewLine>                              shuffle=True)<NewLine>                           <NewLine>    # create validation dataset                           <NewLine>    logging.info(""Prepare Validation datasets."")<NewLine>    if args.dataset_type == ""voc"":<NewLine>        val_dataset = VOCDataset(dataset_path, transform=test_transform,<NewLine>                                 target_transform=target_transform, is_test=True)<NewLine>    elif args.dataset_type == 'open_images':<NewLine>        val_dataset = OpenImagesDataset(dataset_path,<NewLine>                                        transform=test_transform, target_transform=target_transform,<NewLine>                                        dataset_type=""test"")<NewLine>        logging.info(val_dataset)<NewLine>    logging.info(""Validation dataset size: {}"".format(len(val_dataset)))<NewLine><NewLine>    val_loader = DataLoader(val_dataset, args.batch_size,<NewLine>                            num_workers=args.num_workers,<NewLine>                            shuffle=False)<NewLine>                            <NewLine>    # create the network<NewLine>    logging.info(""Build network."")<NewLine>    net = create_net(num_classes)<NewLine>    min_loss = -10000.0<NewLine>    last_epoch = -1<NewLine><NewLine>    # freeze certain layers (if requested)<NewLine>    base_net_lr = args.base_net_lr if args.base_net_lr is not None else args.lr<NewLine>    extra_layers_lr = args.extra_layers_lr if args.extra_layers_lr is not None else args.lr<NewLine>    <NewLine>    if args.freeze_base_net:<NewLine>        logging.info(""Freeze base net."")<NewLine>        freeze_net_layers(net.base_net)<NewLine>        params = itertools.chain(net.source_layer_add_ons.parameters(), net.extras.parameters(),<NewLine>                                 net.regression_headers.parameters(), net.classification_headers.parameters())<NewLine>        params = [<NewLine>            {'params': itertools.chain(<NewLine>                net.source_layer_add_ons.parameters(),<NewLine>                net.extras.parameters()<NewLine>            ), 'lr': extra_layers_lr},<NewLine>            {'params': itertools.chain(<NewLine>                net.regression_headers.parameters(),<NewLine>                net.classification_headers.parameters()<NewLine>            )}<NewLine>        ]<NewLine>    elif args.freeze_net:<NewLine>        freeze_net_layers(net.base_net)<NewLine>        freeze_net_layers(net.source_layer_add_ons)<NewLine>        freeze_net_layers(net.extras)<NewLine>        params = itertools.chain(net.regression_headers.parameters(), net.classification_headers.parameters())<NewLine>        logging.info(""Freeze all the layers except prediction heads."")<NewLine>    else:<NewLine>        params = [<NewLine>            {'params': net.base_net.parameters(), 'lr': base_net_lr},<NewLine>            {'params': itertools.chain(<NewLine>                net.source_layer_add_ons.parameters(),<NewLine>                net.extras.parameters()<NewLine>            ), 'lr': extra_layers_lr},<NewLine>            {'params': itertools.chain(<NewLine>                net.regression_headers.parameters(),<NewLine>                net.classification_headers.parameters()<NewLine>            )}<NewLine>        ]<NewLine><NewLine>    # load a previous model checkpoint (if requested)<NewLine>    timer.start(""Load Model"")<NewLine>    if args.resume:<NewLine>        logging.info(f""Resume from the model {args.resume}"")<NewLine>        net.load(args.resume)<NewLine>    elif args.base_net:<NewLine>        logging.info(f""Init from base net {args.base_net}"")<NewLine>        net.init_from_base_net(args.base_net)<NewLine>    elif args.pretrained_ssd:<NewLine>        logging.info(f""Init from pretrained ssd {args.pretrained_ssd}"")<NewLine>        net.init_from_pretrained_ssd(args.pretrained_ssd)<NewLine>    logging.info(f'Took {timer.end(""Load Model""):.2f} seconds to load the model.')<NewLine><NewLine>    # move the model to GPU<NewLine>    net.to(DEVICE)<NewLine><NewLine>    # define loss function and optimizer<NewLine>    criterion = MultiboxLoss(config.priors, iou_threshold=0.5, neg_pos_ratio=3,<NewLine>                             center_variance=0.1, size_variance=0.2, device=DEVICE)<NewLine>    optimizer = torch.optim.SGD(params, lr=args.lr, momentum=args.momentum,<NewLine>                                weight_decay=args.weight_decay)<NewLine>    logging.info(f""Learning rate: {args.lr}, Base net learning rate: {base_net_lr}, ""<NewLine>                 + f""Extra Layers learning rate: {extra_layers_lr}."")<NewLine><NewLine>    # set learning rate policy<NewLine>    if args.scheduler == 'multi-step':<NewLine>        logging.info(""Uses MultiStepLR scheduler."")<NewLine>        milestones = [int(v.strip()) for v in args.milestones.split("","")]<NewLine>        scheduler = MultiStepLR(optimizer, milestones=milestones,<NewLine>                                                     gamma=0.1, last_epoch=last_epoch)<NewLine>    elif args.scheduler == 'cosine':<NewLine>        logging.info(""Uses CosineAnnealingLR scheduler."")<NewLine>        scheduler = CosineAnnealingLR(optimizer, args.t_max, last_epoch=last_epoch)<NewLine>    else:<NewLine>        logging.fatal(f""Unsupported Scheduler: {args.scheduler}."")<NewLine>        parser.print_help(sys.stderr)<NewLine>        sys.exit(1)<NewLine><NewLine>    # train for the desired number of epochs<NewLine>    logging.info(f""Start training from epoch {last_epoch + 1}."")<NewLine>    <NewLine>    for epoch in range(last_epoch + 1, args.num_epochs):<NewLine>        scheduler.step()<NewLine>        train(train_loader, net, criterion, optimizer,<NewLine>              device=DEVICE, debug_steps=args.debug_steps, epoch=epoch)<NewLine>        <NewLine>        if epoch % args.validation_epochs == 0 or epoch == args.num_epochs - 1:<NewLine>            val_loss, val_regression_loss, val_classification_loss = test(val_loader, net, criterion, DEVICE)<NewLine>            logging.info(<NewLine>                f""Epoch: {epoch}, "" +<NewLine>                f""Validation Loss: {val_loss:.4f}, "" +<NewLine>                f""Validation Regression Loss {val_regression_loss:.4f}, "" +<NewLine>                f""Validation Classification Loss: {val_classification_loss:.4f}""<NewLine>            )<NewLine>            model_path = os.path.join(args.checkpoint_folder, f""{args.net}-Epoch-{epoch}-Loss-{val_loss}.pth"")<NewLine>            torch.save(net.state_dict(),model_path)<NewLine>            logging.info(f""Saved model {model_path}"")<NewLine><NewLine>    logging.info(""Task done, exiting program."")<NewLine></code></pre><NewLine></div>",https://discuss.pytorch.org/u/Sgomes14843,(Sgomes14843),Sgomes14843,"August 4, 2020,  8:44am",,"REPLY 1: <div class=""post"" itemprop=""articleBody""><NewLine><p>Based on the <a href=""https://pytorch.org/docs/stable/notes/windows.html#multiprocessing-error-without-if-clause-protection"">FAQ</a> it seems you might need to move the complete code to the if-clause protection.<br/><NewLine>Could you move the <code>torch.cuda.is_available()</code> calls into the if guard (i.e. the <code>DEVICE</code> assignment and setting <code>cudnn.benchmark</code>)?</p><NewLine><p>If that doesn’t help, could you post the error message?</p><NewLine></div>; <NewLine> REPLY 2: <div class=""post"" itemprop=""articleBody""><NewLine><p>Unfortunately it didn’t work<br/><NewLine>The error message:<br/><NewLine><div class=""lightbox-wrapper""><a class=""lightbox"" data-download-href=""https://discuss.pytorch.org/uploads/default/fc0f136559a82d297639d46c03061c4a507b2f5e"" href=""https://discuss.pytorch.org/uploads/default/original/3X/f/c/fc0f136559a82d297639d46c03061c4a507b2f5e.jpeg"" title=""Anotação 2020-08-05 155953""><img alt=""Anotação 2020-08-05 155953"" data-base62-sha1=""zXOCzR7mAtAIfxViZzRoyaKw1xY"" data-small-upload=""https://discuss.pytorch.org/uploads/default/optimized/3X/f/c/fc0f136559a82d297639d46c03061c4a507b2f5e_2_10x10.png"" height=""221"" src=""https://discuss.pytorch.org/uploads/default/optimized/3X/f/c/fc0f136559a82d297639d46c03061c4a507b2f5e_2_690x221.jpeg"" srcset=""https://discuss.pytorch.org/uploads/default/optimized/3X/f/c/fc0f136559a82d297639d46c03061c4a507b2f5e_2_690x221.jpeg, https://discuss.pytorch.org/uploads/default/optimized/3X/f/c/fc0f136559a82d297639d46c03061c4a507b2f5e_2_1035x331.jpeg 1.5x, https://discuss.pytorch.org/uploads/default/optimized/3X/f/c/fc0f136559a82d297639d46c03061c4a507b2f5e_2_1380x442.jpeg 2x"" width=""690""/><div class=""meta""><svg aria-hidden=""true"" class=""fa d-icon d-icon-far-image svg-icon""><use xlink:href=""#far-image""></use></svg><span class=""filename"">Anotação 2020-08-05 155953</span><span class=""informations"">1920×617 206 KB</span><svg aria-hidden=""true"" class=""fa d-icon d-icon-discourse-expand svg-icon""><use xlink:href=""#discourse-expand""></use></svg></div></a></div></p><NewLine></div>; <NewLine> REPLY 3: <div class=""post"" itemprop=""articleBody""><NewLine><p>Thanks for the error message.<br/><NewLine>Could you try to replace the <code>lambda</code> by a function definition, as it seems <a href=""https://docs.python.org/3/library/pickle.html#what-can-be-pickled-and-unpickled"">lambda functions cannot be pickled</a>.</p><NewLine></div>; <NewLine> ",REPLIER 1: https://discuss.pytorch.org/u/ptrblck; <NewLine> REPLIER 2: https://discuss.pytorch.org/u/Sgomes14843; <NewLine> REPLIER 3: https://discuss.pytorch.org/u/ptrblck; <NewLine> ,"REPLY_DATE 1: August 5, 2020, 10:00am; <NewLine> REPLY_DATE 2: August 5, 2020,  3:00pm; <NewLine> REPLY_DATE 3: August 5, 2020,  7:39pm; <NewLine> ",REPLY 1 LIKES: ; <NewLine> REPLY 2 LIKES: ; <NewLine> REPLY 3 LIKES: ; <NewLine> 
91099,Help with OSError caffe2_detectron_ops_gpu,2020-07-30T12:22:23.221Z,0,96,"<div class=""post"" itemprop=""articleBody""><NewLine><p>Hello. I keep getting the error</p><NewLine><blockquote><NewLine><p>OSError: [WinError 126] The specified module could not be found. Error loading “C:\Users\Username\AppData\Local\Programs\Python\Python38\lib\site-packages\torch\lib\caffe2_detectron_ops_gpu.dll” or one of its dependencies.</p><NewLine></blockquote><NewLine><p>I tried updating form cuda 10.1 to 10.2 but it didnt fix the issue. i also have cudnn installed . I uninstalled and reistalled torch multiple times with the commands found on the getting started page. Can someone help me resolve this i’ve being stuck for 2 days now</p><NewLine></div>",https://discuss.pytorch.org/u/cramberiecookies,(cramberiecookies),cramberiecookies,"July 30, 2020, 12:22pm",,"REPLY 1: <div class=""post"" itemprop=""articleBody""><NewLine><p>Problem solved cudnn64_7.dll was missing from system32 folder</p><NewLine></div>; <NewLine> ",REPLIER 1: https://discuss.pytorch.org/u/cramberiecookies; <NewLine> ,"REPLY_DATE 1: July 30, 2020,  8:52pm; <NewLine> ",REPLY 1 LIKES: ; <NewLine> 
90769,"Is building from source for windows up to date? (subprocess.CalledProcessError: Command &lsquo;[&lsquo;cmake&rsquo;, ..] returned non-zero exit status 1 error)",2020-07-28T05:11:54.348Z,1,188,"<div class=""post"" itemprop=""articleBody""><NewLine><p>Hi everyone.<br/><NewLine>I’m in the process of converting our models from Python to C++ for production. For that it seems we need to build Pytorch from source as the prebuilt libtorch doesnt come with torch.h headers and alike !<br/><NewLine>I’m on Windows 10 1803 and  have Visual Studio 2019 installed (v16.6.3). I dont have any GPUs so I didnt install CUDA! or NVTX.<br/><NewLine>I have anaconda and python 3.7 installed and all the deps are installed using the following command:</p><NewLine><pre><code class=""lang-auto"">conda install numpy ninja pyyaml mkl mkl-include setuptools cmake cffi<NewLine></code></pre><NewLine><p>I cloned Pytorch as stated in the readme :</p><NewLine><pre><code class=""lang-auto"">git clone --recursive https://github.com/pytorch/pytorch<NewLine>cd pytorch<NewLine># if you are updating an existing checkout<NewLine>git submodule sync<NewLine>git submodule update --init --recursive<NewLine></code></pre><NewLine><p>But upon executing these commands :</p><NewLine><pre><code class=""lang-auto"">:: [Optional] If you want to build with VS 2019 generator, please change the value in the next line to `Visual Studio 16 2019`.<NewLine>:: Note: This value is useless if Ninja is detected. However, you can force that by using `set USE_NINJA=OFF`.<NewLine>set CMAKE_GENERATOR=Visual Studio 16 2019<NewLine><NewLine>:: Read the content in the previous section carefully before you proceed.<NewLine>:: [Optional] If you want to override the underlying toolset used by Ninja and Visual Studio with CUDA, please run the following script block.<NewLine>:: ""Visual Studio 2017 Developer Command Prompt"" will be run automatically.<NewLine>:: Make sure you have CMake &gt;= 3.12 before you do this when you use the Visual Studio generator.<NewLine>set CMAKE_GENERATOR_TOOLSET_VERSION=14.11<NewLine>set DISTUTILS_USE_SDK=1<NewLine>for /f ""usebackq tokens=*"" %i in (`""%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe"" -version [15^,16^) -products * -latest -property installationPath`) do call ""%i\VC\Auxiliary\Build\vcvarsall.bat"" x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%<NewLine><NewLine>:: [Optional] If you want to override the cuda host compiler<NewLine>set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise\VC\Tools\MSVC\14.11.25503\bin\HostX64\x64\cl.exe<NewLine><NewLine>python setup.py install<NewLine></code></pre><NewLine><p>I face these errors:</p><NewLine><pre><code class=""lang-auto"">D:\Codes\pytorch&gt;python setup.py install<NewLine>Building wheel torch-1.7.0a0+8376284<NewLine>-- Building version 1.7.0a0+8376284<NewLine>cmake -GNinja -DBUILD_PYTHON=True -DBUILD_TEST=True -DCMAKE_BUILD_TYPE=Release -DCMAKE_GENERATOR=Visual Studio 16 2019 -DCMAKE_GENERATOR_TOOLSET_VERSION=14.11 -DCMAKE_INSTALL_PREFIX=D:\Codes\pytorch\torch -DCMAKE_PREFIX_PATH=C:\Users\User\Anaconda3\Lib\site-packages -DNUMPY_INCLUDE_DIR=C:\Users\User\Anaconda3\Lib\site-packages\numpy\core\include -DPYTHON_EXECUTABLE=C:\Users\User\Anaconda3\python.exe -DPYTHON_INCLUDE_DIR=C:\Users\User\Anaconda3\include -DPYTHON_LIBRARY=C:\Users\User\Anaconda3/libs/python37.lib -DTORCH_BUILD_VERSION=1.7.0a0+8376284 -DUSE_NUMPY=True D:\Codes\pytorch<NewLine>CMake Error: Error: generator : Ninja<NewLine>Does not match the generator used previously: Visual Studio 16 2019<NewLine>Either remove the CMakeCache.txt file and CMakeFiles directory or choose a different binary directory.<NewLine>Traceback (most recent call last):<NewLine>  File ""setup.py"", line 737, in &lt;module&gt;<NewLine>    build_deps()<NewLine>  File ""setup.py"", line 321, in build_deps<NewLine>    cmake=cmake)<NewLine>  File ""D:\Codes\pytorch\tools\build_pytorch_libs.py"", line 59, in build_caffe2<NewLine>    rerun_cmake)<NewLine>  File ""D:\Codes\pytorch\tools\setup_helpers\cmake.py"", line 329, in generate<NewLine>    self.run(args, env=my_env)<NewLine>  File ""D:\Codes\pytorch\tools\setup_helpers\cmake.py"", line 141, in run<NewLine>    check_call(command, cwd=self.build_dir, env=env)<NewLine>  File ""C:\Users\User\Anaconda3\Lib\subprocess.py"", line 347, in check_call<NewLine>    raise CalledProcessError(retcode, cmd)<NewLine>subprocess.CalledProcessError: Command '['cmake', '-GNinja', '-DBUILD_PYTHON=True', '-DBUILD_TEST=True', '-DCMAKE_BUILD_TYPE=Release', '-DCMAKE_GENERATOR=Visual Studio 16 2019', '-DCMAKE_GENERATOR_TOOLSET_VERSION=14.11', '-DCMAKE_INSTALL_PREFIX=D:\\Codes\\pytorch\\torch', '-DCMAKE_PREFIX_PATH=C:\\Users\\User\\Anaconda3\\Lib\\site-packages', '-DNUMPY_INCLUDE_DIR=C:\\Users\\User\\Anaconda3\\Lib\\site-packages\\numpy\\core\\include', '-DPYTHON_EXECUTABLE=C:\\Users\\User\\Anaconda3\\python.exe', '-DPYTHON_INCLUDE_DIR=C:\\Users\\User\\Anaconda3\\include', '-DPYTHON_LIBRARY=C:\\Users\\User\\Anaconda3/libs/python37.lib', '-DTORCH_BUILD_VERSION=1.7.0a0+8376284', '-DUSE_NUMPY=True', 'D:\\Codes\\pytorch']' returned non-zero exit status 1.<NewLine></code></pre><NewLine><p>What am I doing wrong?<br/><NewLine>Any help is greatly appreciated</p><NewLine></div>",https://discuss.pytorch.org/u/Shisho_Sama,(A curious guy here!),Shisho_Sama,"July 28, 2020,  5:18am",,"REPLY 1: <div class=""post"" itemprop=""articleBody""><NewLine><p>Looking at this <a href=""https://discuss.pytorch.org/t/pytorch-build-from-source-on-windows/40288/9"">link</a> everything built successfully! without even the need for any of these :</p><NewLine><pre><code class=""lang-auto"">:: [Optional] If you want to build with VS 2019 generator, please change the value in the next line to `Visual Studio 16 2019`.<NewLine>:: Note: This value is useless if Ninja is detected. However, you can force that by using `set USE_NINJA=OFF`.<NewLine>set CMAKE_GENERATOR=Visual Studio 16 2019<NewLine><NewLine>:: Read the content in the previous section carefully before you proceed.<NewLine>:: [Optional] If you want to override the underlying toolset used by Ninja and Visual Studio with CUDA, please run the following script block.<NewLine>:: ""Visual Studio 2017 Developer Command Prompt"" will be run automatically.<NewLine>:: Make sure you have CMake &gt;= 3.12 before you do this when you use the Visual Studio generator.<NewLine>set CMAKE_GENERATOR_TOOLSET_VERSION=14.11<NewLine>set DISTUTILS_USE_SDK=1<NewLine>for /f ""usebackq tokens=*"" %i in (`""%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe"" -version [15^,16^) -products * -latest -property installationPath`) do call ""%i\VC\Auxiliary\Build\vcvarsall.bat"" x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%<NewLine><NewLine>:: [Optional] If you want to override the cuda host compiler<NewLine>set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise\VC\Tools\MSVC\14.11.25503\bin\HostX64\x64\cl.exe<NewLine><NewLine>python setup.py install<NewLine></code></pre><NewLine><p>I just ran :</p><NewLine><pre><code class=""lang-auto"">python setup.py build --cmake<NewLine>python setup.py install<NewLine></code></pre><NewLine><p>and everything got built!<br/><NewLine>However, after building everything, I cant seem to be able to find &lt;torch/torch.h&gt; ! I read it on this issue <a href=""https://github.com/pytorch/pytorch/issues/5964#issuecomment-375698855"" rel=""nofollow noopener"">here</a> that building from source will make that but apparently this is not the case here!</p><NewLine><p>Any help is greatly appreciated</p><NewLine></div>; <NewLine> REPLY 2: <div class=""post"" itemprop=""articleBody""><NewLine><p>OK, Here are my findings.<br/><NewLine>First of all <code>include &lt;torch/torch.h&gt;</code> doesnt need building from source. its just in the a different path that is,<br/><NewLine>in include directories, one need to add both :<br/><NewLine><code>$(SolutionDir)Dependencies\libtorch-debug-latest\libtorch\include; $(SolutionDir)Dependencies\libtorch-debug-latest\libtorch\include\torch\csrc\api\include;</code><br/><NewLine>and voila you are good to go!</p><NewLine></div>; <NewLine> ",REPLIER 1: https://discuss.pytorch.org/u/Shisho_Sama; <NewLine> REPLIER 2: https://discuss.pytorch.org/u/Shisho_Sama; <NewLine> ,"REPLY_DATE 1: July 28, 2020,  7:02am; <NewLine> REPLY_DATE 2: July 28, 2020,  8:45am; <NewLine> ",REPLY 1 LIKES: ; <NewLine> REPLY 2 LIKES: ; <NewLine> 
90451,Train specific classes of dataset,2020-07-24T18:52:17.225Z,0,75,"<div class=""post"" itemprop=""articleBody""><NewLine><p>Hi. I’m new on the deep learning world, so I decided to build a model for pneumonia detection for my country. I’ve selected a well known dataset <a href=""https://www.kaggle.com/nih-chest-xrays/data"" rel=""nofollow noopener"">NIH Chest X-ray</a>. It have 14 different classes but I interested only in two classes: Consolidation and Infiltration. I’ll use Data augmentation and transfer learning for the training. Could you please give me an example how train only these 2 clases? I’m thinking about read de csv label database delete images who not have the finding label.</p><NewLine><p>Thank you in advance</p><NewLine></div>",https://discuss.pytorch.org/u/Cesar_Sotelo,(César Sotelo),Cesar_Sotelo,"July 24, 2020,  6:52pm",,"REPLY 1: <div class=""post"" itemprop=""articleBody""><NewLine><aside class=""quote no-group"" data-post=""1"" data-topic=""90451"" data-username=""Cesar_Sotelo""><NewLine><div class=""title""><NewLine><div class=""quote-controls""></div><NewLine><img alt="""" class=""avatar"" height=""20"" src=""https://discuss.pytorch.org/user_avatar/discuss.pytorch.org/cesar_sotelo/40/27091_2.png"" width=""20""/> Cesar_Sotelo:</div><NewLine><blockquote><NewLine><p>I’m thinking about read de csv label database delete images who not have the finding label.</p><NewLine></blockquote><NewLine></aside><NewLine><p>This sounds like a valid approach.<br/><NewLine>If you are not interested in training the other classes at the moment, I would either remove them or create a separate smaller dataset, which only contains the desired class samples.</p><NewLine></div>; <NewLine> ",REPLIER 1: https://discuss.pytorch.org/u/ptrblck; <NewLine> ,"REPLY_DATE 1: July 26, 2020,  8:57am; <NewLine> ",REPLY 1 LIKES: ; <NewLine> 
